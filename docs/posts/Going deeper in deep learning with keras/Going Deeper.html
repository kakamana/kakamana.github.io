<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="kakamana">
<meta name="dcterms.date" content="2023-04-05">

<title>Kakamana’s Blogs - Going Deeper</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Kakamana’s Blogs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://kakamana.github.io"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Nerdy_kakamana"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#going-deeper" id="toc-going-deeper" class="nav-link active" data-scroll-target="#going-deeper">Going Deeper</a></li>
  <li><a href="#binary-classification" id="toc-binary-classification" class="nav-link" data-scroll-target="#binary-classification">Binary Classification</a>
  <ul class="collapse">
  <li><a href="#a-binary-classification-model" id="toc-a-binary-classification-model" class="nav-link" data-scroll-target="#a-binary-classification-model">A binary classification model</a></li>
  <li><a href="#is-this-dollar-bill-fake" id="toc-is-this-dollar-bill-fake" class="nav-link" data-scroll-target="#is-this-dollar-bill-fake">Is this dollar bill fake ?</a></li>
  </ul></li>
  <li><a href="#multi-class-classification" id="toc-multi-class-classification" class="nav-link" data-scroll-target="#multi-class-classification">Multi-class classification</a>
  <ul class="collapse">
  <li><a href="#prepare-your-dataset" id="toc-prepare-your-dataset" class="nav-link" data-scroll-target="#prepare-your-dataset">Prepare your dataset</a></li>
  <li><a href="#training-on-dart-throwers" id="toc-training-on-dart-throwers" class="nav-link" data-scroll-target="#training-on-dart-throwers">Training on dart throwers</a></li>
  <li><a href="#softmax-predictions" id="toc-softmax-predictions" class="nav-link" data-scroll-target="#softmax-predictions">Softmax predictions</a></li>
  </ul></li>
  <li><a href="#multi-label-classification" id="toc-multi-label-classification" class="nav-link" data-scroll-target="#multi-label-classification">Multi-label classification</a>
  <ul class="collapse">
  <li><a href="#an-irrigation-machine" id="toc-an-irrigation-machine" class="nav-link" data-scroll-target="#an-irrigation-machine">An irrigation machine</a></li>
  <li><a href="#training-with-multiple-labels" id="toc-training-with-multiple-labels" class="nav-link" data-scroll-target="#training-with-multiple-labels">Training with multiple labels</a></li>
  </ul></li>
  <li><a href="#keras-callbacks" id="toc-keras-callbacks" class="nav-link" data-scroll-target="#keras-callbacks">Keras callbacks</a>
  <ul class="collapse">
  <li><a href="#early-stopping-your-model" id="toc-early-stopping-your-model" class="nav-link" data-scroll-target="#early-stopping-your-model">Early stopping your model</a></li>
  <li><a href="#a-combination-of-callbacks" id="toc-a-combination-of-callbacks" class="nav-link" data-scroll-target="#a-combination-of-callbacks">A combination of callbacks</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Going Deeper</h1>
  <div class="quarto-categories">
    <div class="quarto-category">python</div>
    <div class="quarto-category">datacamp</div>
    <div class="quarto-category">machine learning</div>
    <div class="quarto-category">deep learning</div>
    <div class="quarto-category">tensorflow</div>
    <div class="quarto-category">keras</div>
    <div class="quarto-category">neural network</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>kakamana </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 5, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="going-deeper" class="level1">
<h1>Going Deeper</h1>
<p>Upon completion of this chapter, you will be able to solve binary, multi-class, and multi-label problems using neural networks. All of this can be accomplished by solving problems such as detecting fake dollar bills, determining who threw which dart at a board, and building an intelligent system to water your farm. Aside from plotting model training metrics, you will also be able to stop training and save your models when they no longer improve.</p>
<p>This <strong>Going Deeper</strong> is part of [Datacamp course: Introduction to Deep Learning with Keras] There is no denying that deep learning is here to stay! A powerful innovation tool, it is used to solve complex problems arising from unstructured data. It is among the frameworks that make it easier to develop deep learning models, and it is versatile enough to build industry-ready models quickly. In this course, you will learn regression and save the earth by predicting asteroid trajectory, apply binary classification to distinguish real and fake dollar bills, learn to apply multiclass classification to decide who threw which dart at a dart board, and use neural networks to reconstruct noisy images. Additionally, you will learn how to tune your models to enhance their performance during training.</p>
<p>This is my learning experience of data science through DataCamp. These repository contributions are part of my learning journey through my graduate program masters of applied data sciences (MADS) at University Of Michigan, <a href="https://www.deeplearning.ai">DeepLearning.AI</a>, <a href="https://www.coursera.org">Coursera</a> &amp; <a href="https://www.datacamp.com">DataCamp</a>. You can find my similar articles &amp; more stories at my <a href="https://medium.com/@kamig4u">medium</a> &amp; <a href="https://www.linkedin.com/in/asadenterprisearchitect">LinkedIn</a> profile. I am available at <a href="https://www.kaggle.com/kakamana">kaggle</a> &amp; <a href="https://kakamana.github.io">github blogs</a> &amp; <a href="https://github.com/kakamana">github repos</a>. Thank you for your motivation, support &amp; valuable feedback.</p>
<p>These include projects, coursework &amp; notebook which I learned through my data science journey. They are created for reproducible &amp; future reference purpose only. All source code, slides or screenshot are intellactual property of respective content authors. If you find these contents beneficial, kindly consider learning subscription from <a href="https://www.deeplearning.ai">DeepLearning.AI Subscription</a>, <a href="https://www.coursera.org">Coursera</a>, <a href="https://www.datacamp.com">DataCamp</a></p>
<div id="cell-2" class="cell" data-execution_count="38">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img src="GoingDeeper-1.png" class="img-fluid"> <img src="GoingDeeper-2.png" class="img-fluid"></p>
</section>
<section id="binary-classification" class="level1">
<h1>Binary Classification</h1>
<p>Exploring dollar bills You will practice building classification models in Keras with the Banknote Authentication dataset.</p>
<p>Your goal is to distinguish between real and fake dollar bills. In order to do this, the dataset comes with 4 features: variance,skewness,curtosis and entropy. These features are calculated by applying mathematical operations over the dollar bill images. The labels are found in the dataframe’s class column.</p>
<p><img src="GoingDeeper-3.png" class="img-fluid"></p>
<div id="cell-5" class="cell" data-execution_count="39">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>banknotes <span class="op">=</span> pd.read_csv(<span class="st">'dataset/banknotes.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>banknotes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="39">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">variace</th>
<th data-quarto-table-cell-role="th">skewness</th>
<th data-quarto-table-cell-role="th">curtosis</th>
<th data-quarto-table-cell-role="th">entropy</th>
<th data-quarto-table-cell-role="th">class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>3.62160</td>
<td>8.6661</td>
<td>-2.8073</td>
<td>-0.44699</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4.54590</td>
<td>8.1674</td>
<td>-2.4586</td>
<td>-1.46210</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3.86600</td>
<td>-2.6383</td>
<td>1.9242</td>
<td>0.10645</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3.45660</td>
<td>9.5228</td>
<td>-4.0112</td>
<td>-3.59440</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.32924</td>
<td>-4.4552</td>
<td>4.5718</td>
<td>-0.98880</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="cell-6" class="cell" data-execution_count="40">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> banknotes.iloc[:, :<span class="dv">4</span>]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> ((X <span class="op">-</span> X.mean()) <span class="op">/</span> X.std()).to_numpy()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> banknotes[<span class="st">'class'</span>].to_numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-7" class="cell" data-execution_count="41">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>sns.pairplot(banknotes, hue<span class="op">=</span><span class="st">'class'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-8" class="cell" data-execution_count="42">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Dataset stats: </span><span class="ch">\n</span><span class="st">'</span>, banknotes.describe())</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the number of observations per class</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Observations per class: </span><span class="ch">\n</span><span class="st">'</span>, banknotes[<span class="st">'class'</span>].value_counts())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset stats: 
            variace     skewness     curtosis      entropy        class
count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000
mean      0.433735     1.922353     1.397627    -1.191657     0.444606
std       2.842763     5.869047     4.310030     2.101013     0.497103
min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000
25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000
50%       0.496180     2.319650     0.616630    -0.586650     0.000000
75%       2.821475     6.814625     3.179250     0.394810     1.000000
max       6.824800    12.951600    17.927400     2.449500     1.000000
Observations per class: 
 0    762
1    610
Name: class, dtype: int64</code></pre>
</div>
</div>
<div id="cell-9" class="cell" data-execution_count="43">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">pairplot shows that there are features for which the classes spread out noticeably. This gives us an intuition about our classes being easily separable."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
pairplot shows that there are features for which the classes spread out noticeably. This gives us an intuition about our classes being easily separable.</code></pre>
</div>
</div>
<section id="a-binary-classification-model" class="level2">
<h2 class="anchored" data-anchor-id="a-binary-classification-model">A binary classification model</h2>
<p>Now that you know what the Banknote Authentication dataset looks like, we’ll build a simple model to distinguish between real and fake bills.</p>
<p>You will perform binary classification by using a single neuron as an output. The input layer will have 4 neurons since we have 4 features in our dataset. The model’s output will be a value constrained between 0 and 1.</p>
<p>We will interpret this output number as the probability of our input variables coming from a fake dollar bill, with 1 meaning we are certain it’s a fake bill.</p>
<p><img src="GoingDeeper-4.png" class="img-fluid"></p>
<div id="cell-11" class="cell" data-execution_count="44">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the sequential model and dense layer</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a sequential model</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a dense layer</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">1</span>, input_shape<span class="op">=</span>(<span class="dv">4</span>,), activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile your model</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'sgd'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Display a summary of your model</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_7 (Dense)             (None, 1)                 5         
                                                                 
=================================================================
Total params: 5
Trainable params: 5
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
</section>
<section id="is-this-dollar-bill-fake" class="level2">
<h2 class="anchored" data-anchor-id="is-this-dollar-bill-fake">Is this dollar bill fake ?</h2>
<p>You are now ready to train your model and check how well it performs when classifying new bills!</p>
<div id="cell-13" class="cell" data-execution_count="45">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.25</span>, stratify<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-14" class="cell" data-execution_count="46">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate your model accuracy on the test set</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> model.evaluate(X_test, y_test)[<span class="dv">1</span>]</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Print accuracy</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy: '</span>, accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
33/33 [==============================] - 0s 6ms/step - loss: 1.1475 - accuracy: 0.4742
Epoch 2/20
33/33 [==============================] - 0s 4ms/step - loss: 0.9825 - accuracy: 0.4976
Epoch 3/20
33/33 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.5326
Epoch 4/20
33/33 [==============================] - 0s 4ms/step - loss: 0.7281 - accuracy: 0.5889
Epoch 5/20
33/33 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6589
Epoch 6/20
33/33 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7153
Epoch 7/20
33/33 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7862
Epoch 8/20
33/33 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.8639
Epoch 9/20
33/33 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.9086
Epoch 10/20
33/33 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.9242
Epoch 11/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.9184
Epoch 12/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.9213
Epoch 13/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.9232
Epoch 14/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.9252
Epoch 15/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.9174
Epoch 16/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.9145
Epoch 17/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.9184
Epoch 18/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.9203
Epoch 19/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.9213
Epoch 20/20
33/33 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.9232
11/11 [==============================] - 0s 6ms/step - loss: 0.3004 - accuracy: 0.9417
Accuracy:  0.941690981388092</code></pre>
</div>
</div>
</section>
</section>
<section id="multi-class-classification" class="level1">
<h1>Multi-class classification</h1>
<p>A multi-class model</p>
<p>You’re going to build a model that predicts who threw which dart only based on where that dart landed! (That is the dart’s x and y coordinates on the board.)</p>
<p>This problem is a multi-class classification problem since each dart can only be thrown by one of 4 competitors. So classes/labels are mutually exclusive, and therefore we can build a neuron with as many output as competitors and use the softmax activation function to achieve a total sum of probabilities of 1 over all competitors.</p>
<div id="cell-16" class="cell" data-execution_count="47">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>darts <span class="op">=</span> pd.read_csv(<span class="st">'dataset/darts.csv'</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>darts.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="47">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">xCoord</th>
<th data-quarto-table-cell-role="th">yCoord</th>
<th data-quarto-table-cell-role="th">competitor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.196451</td>
<td>-0.520341</td>
<td>Steve</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.476027</td>
<td>-0.306763</td>
<td>Susan</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.003175</td>
<td>-0.980736</td>
<td>Michael</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.294078</td>
<td>0.267566</td>
<td>Kate</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.051120</td>
<td>0.598946</td>
<td>Steve</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="cell-17" class="cell" data-execution_count="48">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>sns.pairplot(darts, hue<span class="op">=</span><span class="st">'competitor'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-18" class="cell" data-execution_count="49">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate a sequential model</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Add 3 dense layers of 128, 64 and 32 neurons each</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, input_shape<span class="op">=</span>(<span class="dv">2</span>,), activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a dense layer with as many neurons as competitors</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">4</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile your model using categorical_crossentropy loss</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>,</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>              optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="prepare-your-dataset" class="level2">
<h2 class="anchored" data-anchor-id="prepare-your-dataset">Prepare your dataset</h2>
<p>In the console you can check that your labels, darts.competitor are not yet in a format to be understood by your network. They contain the names of the competitors as strings. You will first turn these competitors into unique numbers,then use the to_categorical() function from tf.keras.utils to turn these numbers into their one-hot encoded representation.</p>
<p>This is useful for multi-class classification problems, since there are as many output neurons as classes and for every observation in our dataset we just want one of the neurons to be activated.</p>
<div id="cell-20" class="cell" data-execution_count="50">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.utils <span class="im">import</span> to_categorical</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform into a categorical variable</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>darts.competitor <span class="op">=</span> pd.Categorical(darts.competitor)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign a number to each category (label encoding)</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>darts.competitor <span class="op">=</span> darts.competitor.cat.codes</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the label encoded competitors</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Label encoded competitors: </span><span class="ch">\n</span><span class="st">'</span>, darts.competitor.head())</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>coordinates <span class="op">=</span> darts.drop([<span class="st">'competitor'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Use to_categorical on your labels</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>competitors <span class="op">=</span> to_categorical(darts.competitor)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Now print the one-hot encoded labels</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'One-hot encoded competitors: </span><span class="ch">\n</span><span class="st">'</span>, competitors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Label encoded competitors: 
 0    2
1    3
2    1
3    0
4    2
Name: competitor, dtype: int8
One-hot encoded competitors: 
 [[0. 0. 1. 0.]
 [0. 0. 0. 1.]
 [0. 1. 0. 0.]
 ...
 [0. 1. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 0. 1.]]</code></pre>
</div>
</div>
<div id="cell-21" class="cell" data-execution_count="51">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Each competitor is now a vector of length 4, full of zeroes except for the position representing her or himself."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Each competitor is now a vector of length 4, full of zeroes except for the position representing her or himself.</code></pre>
</div>
</div>
</section>
<section id="training-on-dart-throwers" class="level2">
<h2 class="anchored" data-anchor-id="training-on-dart-throwers">Training on dart throwers</h2>
<p>Your model is now ready, just as your dataset. It’s time to train!</p>
<p>The coordinates features and competitors labels you just transformed have been partitioned into coord_train,coord_test and competitors_train,competitors_test.</p>
<p>Let’s find out who threw which dart just by looking at the board!</p>
<div id="cell-23" class="cell" data-execution_count="52">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>coordinates <span class="op">=</span> darts[[<span class="st">'xCoord'</span>, <span class="st">'yCoord'</span>]]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>coordinates.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="52">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">xCoord</th>
<th data-quarto-table-cell-role="th">yCoord</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.196451</td>
<td>-0.520341</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.476027</td>
<td>-0.306763</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.003175</td>
<td>-0.980736</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.294078</td>
<td>0.267566</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.051120</td>
<td>0.598946</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="cell-24" class="cell" data-execution_count="53">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>coord_train, coord_test, competitors_train, competitors_test <span class="op">=</span> <span class="op">\</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    train_test_split(coordinates, competitors, test_size<span class="op">=</span><span class="fl">0.25</span>, stratify<span class="op">=</span>competitors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-25" class="cell" data-execution_count="54">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_8 (Dense)             (None, 128)               384       
                                                                 
 dense_9 (Dense)             (None, 64)                8256      
                                                                 
 dense_10 (Dense)            (None, 32)                2080      
                                                                 
 dense_11 (Dense)            (None, 4)                 132       
                                                                 
=================================================================
Total params: 10,852
Trainable params: 10,852
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div id="cell-26" class="cell" data-execution_count="55">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit your model to the training data for 200 epochs</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>model.fit(coord_train,competitors_train,epochs<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate your model accuracy on the test data</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> model.evaluate(coord_test, competitors_test)[<span class="dv">1</span>]</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print accuracy</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
19/19 [==============================] - 0s 10ms/step - loss: 1.3599 - accuracy: 0.2450
Epoch 2/200
19/19 [==============================] - 0s 8ms/step - loss: 1.3132 - accuracy: 0.3050
Epoch 3/200
19/19 [==============================] - 0s 9ms/step - loss: 1.2641 - accuracy: 0.3683
Epoch 4/200
19/19 [==============================] - 0s 9ms/step - loss: 1.2036 - accuracy: 0.4750
Epoch 5/200
19/19 [==============================] - 0s 10ms/step - loss: 1.1331 - accuracy: 0.5267
Epoch 6/200
19/19 [==============================] - 0s 9ms/step - loss: 1.0514 - accuracy: 0.5550
Epoch 7/200
19/19 [==============================] - 0s 9ms/step - loss: 0.9658 - accuracy: 0.5950
Epoch 8/200
19/19 [==============================] - 0s 9ms/step - loss: 0.9022 - accuracy: 0.6000
Epoch 9/200
19/19 [==============================] - 0s 10ms/step - loss: 0.8625 - accuracy: 0.6517
Epoch 10/200
19/19 [==============================] - 0s 9ms/step - loss: 0.8310 - accuracy: 0.6750
Epoch 11/200
19/19 [==============================] - 0s 9ms/step - loss: 0.8100 - accuracy: 0.6750
Epoch 12/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7954 - accuracy: 0.7000
Epoch 13/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7777 - accuracy: 0.6917
Epoch 14/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7549 - accuracy: 0.7450
Epoch 15/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7466 - accuracy: 0.7350
Epoch 16/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7310 - accuracy: 0.7433
Epoch 17/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7277 - accuracy: 0.7367
Epoch 18/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7172 - accuracy: 0.7483
Epoch 19/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7029 - accuracy: 0.7783
Epoch 20/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6987 - accuracy: 0.7500
Epoch 21/200
19/19 [==============================] - 0s 8ms/step - loss: 0.7010 - accuracy: 0.7733
Epoch 22/200
19/19 [==============================] - 0s 9ms/step - loss: 0.6839 - accuracy: 0.7633
Epoch 23/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6838 - accuracy: 0.7700
Epoch 24/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6779 - accuracy: 0.7750
Epoch 25/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6696 - accuracy: 0.7833
Epoch 26/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6796 - accuracy: 0.7550
Epoch 27/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6662 - accuracy: 0.7883
Epoch 28/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.7900
Epoch 29/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6569 - accuracy: 0.7850
Epoch 30/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.7917
Epoch 31/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6500 - accuracy: 0.7900
Epoch 32/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6364 - accuracy: 0.7917
Epoch 33/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6423 - accuracy: 0.7800
Epoch 34/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6388 - accuracy: 0.7900
Epoch 35/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6392 - accuracy: 0.7917
Epoch 36/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.7850
Epoch 37/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6258 - accuracy: 0.8133
Epoch 38/200
19/19 [==============================] - 0s 7ms/step - loss: 0.6271 - accuracy: 0.7900
Epoch 39/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.7933
Epoch 40/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.7800
Epoch 41/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6145 - accuracy: 0.8050
Epoch 42/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6048 - accuracy: 0.8083
Epoch 43/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6091 - accuracy: 0.7983
Epoch 44/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6095 - accuracy: 0.7817
Epoch 45/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6036 - accuracy: 0.7983
Epoch 46/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6029 - accuracy: 0.8017
Epoch 47/200
19/19 [==============================] - 0s 8ms/step - loss: 0.6009 - accuracy: 0.8033
Epoch 48/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5969 - accuracy: 0.8067
Epoch 49/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5980 - accuracy: 0.7967
Epoch 50/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5893 - accuracy: 0.8000
Epoch 51/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.8083
Epoch 52/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5883 - accuracy: 0.8100
Epoch 53/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5877 - accuracy: 0.8017
Epoch 54/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5804 - accuracy: 0.8083
Epoch 55/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5662 - accuracy: 0.8233
Epoch 56/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5884 - accuracy: 0.7950
Epoch 57/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5694 - accuracy: 0.8133
Epoch 58/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5856 - accuracy: 0.7950
Epoch 59/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5747 - accuracy: 0.8183
Epoch 60/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.8117
Epoch 61/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5763 - accuracy: 0.8017
Epoch 62/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5909 - accuracy: 0.7983
Epoch 63/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5654 - accuracy: 0.8050
Epoch 64/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5703 - accuracy: 0.8067
Epoch 65/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.8233
Epoch 66/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5604 - accuracy: 0.8017
Epoch 67/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5515 - accuracy: 0.8133
Epoch 68/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5470 - accuracy: 0.8267
Epoch 69/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.8133
Epoch 70/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5521 - accuracy: 0.8100
Epoch 71/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.8083
Epoch 72/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5737 - accuracy: 0.8017
Epoch 73/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5477 - accuracy: 0.8117
Epoch 74/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5417 - accuracy: 0.8233
Epoch 75/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5536 - accuracy: 0.8067
Epoch 76/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5645 - accuracy: 0.7917
Epoch 77/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5348 - accuracy: 0.8217
Epoch 78/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5385 - accuracy: 0.8150
Epoch 79/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.8167
Epoch 80/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5345 - accuracy: 0.8233
Epoch 81/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5356 - accuracy: 0.8183
Epoch 82/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.8200
Epoch 83/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5303 - accuracy: 0.8150
Epoch 84/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5346 - accuracy: 0.8150
Epoch 85/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.8250
Epoch 86/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.8300
Epoch 87/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5292 - accuracy: 0.8133
Epoch 88/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.8083
Epoch 89/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.8167
Epoch 90/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.8133
Epoch 91/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.8150
Epoch 92/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5334 - accuracy: 0.8167
Epoch 93/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5535 - accuracy: 0.7967
Epoch 94/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5296 - accuracy: 0.8100
Epoch 95/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.8333
Epoch 96/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.8033
Epoch 97/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5296 - accuracy: 0.8183
Epoch 98/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.8250
Epoch 99/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5164 - accuracy: 0.8117
Epoch 100/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.8300
Epoch 101/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.8133
Epoch 102/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.8250
Epoch 103/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.8250
Epoch 104/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.8250
Epoch 105/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.8133
Epoch 106/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8283
Epoch 107/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.8167
Epoch 108/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5052 - accuracy: 0.8283
Epoch 109/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.8167
Epoch 110/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.8333
Epoch 111/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5040 - accuracy: 0.8167
Epoch 112/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.8267
Epoch 113/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.8250
Epoch 114/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.8350
Epoch 115/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4995 - accuracy: 0.8350
Epoch 116/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.8083
Epoch 117/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4971 - accuracy: 0.8333
Epoch 118/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4994 - accuracy: 0.8233
Epoch 119/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5066 - accuracy: 0.8217
Epoch 120/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.8250
Epoch 121/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5034 - accuracy: 0.8200
Epoch 122/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5133 - accuracy: 0.8033
Epoch 123/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5380 - accuracy: 0.8133
Epoch 124/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5099 - accuracy: 0.8067
Epoch 125/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.8267
Epoch 126/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.8233
Epoch 127/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.8183
Epoch 128/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4963 - accuracy: 0.8217
Epoch 129/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.8233
Epoch 130/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.8300
Epoch 131/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.8200
Epoch 132/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.8233
Epoch 133/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.8300
Epoch 134/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.8300
Epoch 135/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.8250
Epoch 136/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.8300
Epoch 137/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4948 - accuracy: 0.8150
Epoch 138/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8300
Epoch 139/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.8283
Epoch 140/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.8217
Epoch 141/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.8283
Epoch 142/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4829 - accuracy: 0.8300
Epoch 143/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.8267
Epoch 144/200
19/19 [==============================] - 0s 9ms/step - loss: 0.5142 - accuracy: 0.8050
Epoch 145/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.8350
Epoch 146/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.8267
Epoch 147/200
19/19 [==============================] - 0s 9ms/step - loss: 0.4880 - accuracy: 0.8300
Epoch 148/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8183
Epoch 149/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.8150
Epoch 150/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.8200
Epoch 151/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.8183
Epoch 152/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4977 - accuracy: 0.8167
Epoch 153/200
19/19 [==============================] - 0s 8ms/step - loss: 0.5129 - accuracy: 0.8067
Epoch 154/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.8350
Epoch 155/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.8333
Epoch 156/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.8300
Epoch 157/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.8350
Epoch 158/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4678 - accuracy: 0.8283
Epoch 159/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.8267
Epoch 160/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.8333
Epoch 161/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.8167
Epoch 162/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.8433
Epoch 163/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4675 - accuracy: 0.8283
Epoch 164/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4718 - accuracy: 0.8233
Epoch 165/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.8267
Epoch 166/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.8200
Epoch 167/200
19/19 [==============================] - 0s 9ms/step - loss: 0.4690 - accuracy: 0.8317
Epoch 168/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.8400
Epoch 169/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.8250
Epoch 170/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.8167
Epoch 171/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.8167
Epoch 172/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4881 - accuracy: 0.8150
Epoch 173/200
19/19 [==============================] - 0s 9ms/step - loss: 0.4745 - accuracy: 0.8200
Epoch 174/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.8333
Epoch 175/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.8250
Epoch 176/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.8217
Epoch 177/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.8217
Epoch 178/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.8333
Epoch 179/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.8200
Epoch 180/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4806 - accuracy: 0.8133
Epoch 181/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.8133
Epoch 182/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.8300
Epoch 183/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4657 - accuracy: 0.8250
Epoch 184/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4619 - accuracy: 0.8400
Epoch 185/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.8250
Epoch 186/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.8250
Epoch 187/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.8317
Epoch 188/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.8367
Epoch 189/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.8300
Epoch 190/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.8300
Epoch 191/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4641 - accuracy: 0.8283
Epoch 192/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.8150
Epoch 193/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8000
Epoch 194/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4632 - accuracy: 0.8317
Epoch 195/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.8167
Epoch 196/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.8350
Epoch 197/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4545 - accuracy: 0.8367
Epoch 198/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.8317
Epoch 199/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.8317
Epoch 200/200
19/19 [==============================] - 0s 8ms/step - loss: 0.4639 - accuracy: 0.8333
7/7 [==============================] - 0s 10ms/step - loss: 0.7568 - accuracy: 0.7400
Accuracy: 0.7400000095367432</code></pre>
</div>
</div>
</section>
<section id="softmax-predictions" class="level2">
<h2 class="anchored" data-anchor-id="softmax-predictions">Softmax predictions</h2>
<p>This model is generalizing well!, that’s why you got a high accuracy on the test set.</p>
<p>Since you used the softmax activation function, for every input of 2 coordinates provided to your model there’s an output vector of 4 numbers. Each of these numbers encodes the probability of a given dart being thrown by one of the 4 possible competitors.</p>
<p>When computing accuracy with the model’s .evaluate() method, your model takes the class with the highest probability as the prediction. np.argmax() can help you do this since it returns the index with the highest value in an array.</p>
<p>Use the collection of test throws stored in coords_small_test and np.argmax() to check this out!</p>
<div id="cell-28" class="cell" data-execution_count="56">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>coords_small_test <span class="op">=</span> pd.DataFrame({</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'xCoord'</span>:[<span class="fl">0.209048</span>, <span class="fl">0.082103</span>, <span class="fl">0.198165</span>, <span class="op">-</span><span class="fl">0.348660</span>, <span class="fl">0.214726</span>],</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'yCoord'</span>:[<span class="op">-</span><span class="fl">0.077398</span>, <span class="op">-</span><span class="fl">0.721407</span>, <span class="op">-</span><span class="fl">0.674646</span>, <span class="fl">0.035086</span>, <span class="fl">0.183894</span>]</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>competitors_small_test <span class="op">=</span> np.array([[<span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">1.</span>, <span class="fl">0.</span>], [<span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">1.</span>],</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>                                   [<span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">1.</span>], [<span class="fl">1.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>],</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>                                   [<span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">1.</span>, <span class="fl">0.</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-29" class="cell" data-execution_count="57">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> model.predict(coords_small_test)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Print preds vs true values</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="sc">{:45}</span><span class="st"> | </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(<span class="st">"Raw Model Predictions"</span>, <span class="st">"True labels"</span>))</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, pred <span class="kw">in</span> <span class="bu">enumerate</span>(preds):</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="sc">{}</span><span class="st"> | </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(pred, competitors_small_test[i]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 35ms/step
Raw Model Predictions                         | True labels
[0.2622551  0.02379499 0.70972663 0.00422329] | [0. 0. 1. 0.]
[0.14338753 0.0040605  0.03195374 0.82059824] | [0. 0. 0. 1.]
[0.33725557 0.00968876 0.1857851  0.46727058] | [0. 0. 0. 1.]
[0.91596746 0.01915123 0.04591938 0.01896184] | [1. 0. 0. 0.]
[0.23492725 0.02038225 0.74062115 0.00406925] | [0. 0. 1. 0.]</code></pre>
</div>
</div>
<div id="cell-30" class="cell" data-execution_count="58">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on coords_small_test</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> model.predict(coords_small_test)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print preds vs true values</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="sc">{:45}</span><span class="st"> | </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(<span class="st">'Raw Model Predictions'</span>,<span class="st">'True labels'</span>))</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,pred <span class="kw">in</span> <span class="bu">enumerate</span>(preds):</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"</span><span class="sc">{}</span><span class="st"> | </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(pred,competitors_small_test[i]))</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the position of highest probability from each pred vector</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>preds_chosen <span class="op">=</span> [np.argmax(pred) <span class="cf">for</span> pred <span class="kw">in</span> preds]</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Print preds vs true values</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="sc">{:10}</span><span class="st"> | </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(<span class="st">'Rounded Model Predictions'</span>,<span class="st">'True labels'</span>))</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,pred <span class="kw">in</span> <span class="bu">enumerate</span>(preds_chosen):</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"</span><span class="sc">{:25}</span><span class="st"> | </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(pred,competitors_small_test[i]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 9ms/step
Raw Model Predictions                         | True labels
[0.2622551  0.02379499 0.70972663 0.00422329] | [0. 0. 1. 0.]
[0.14338753 0.0040605  0.03195374 0.82059824] | [0. 0. 0. 1.]
[0.33725557 0.00968876 0.1857851  0.46727058] | [0. 0. 0. 1.]
[0.91596746 0.01915123 0.04591938 0.01896184] | [1. 0. 0. 0.]
[0.23492725 0.02038225 0.74062115 0.00406925] | [0. 0. 1. 0.]
Rounded Model Predictions | True labels
                        2 | [0. 0. 1. 0.]
                        3 | [0. 0. 0. 1.]
                        3 | [0. 0. 0. 1.]
                        0 | [1. 0. 0. 0.]
                        2 | [0. 0. 1. 0.]</code></pre>
</div>
</div>
<div id="cell-31" class="cell" data-execution_count="59">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">As you've seen you can easily interpret the softmax output. This can also help you spot those observations where your network is less certain on which class to predict, since you can see the probability distribution among classes per prediction. Let's learn how to solve new problems with neural networks!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
As you've seen you can easily interpret the softmax output. This can also help you spot those observations where your network is less certain on which class to predict, since you can see the probability distribution among classes per prediction. Let's learn how to solve new problems with neural networks!</code></pre>
</div>
</div>
</section>
</section>
<section id="multi-label-classification" class="level1">
<h1>Multi-label classification</h1>
<p><img src="GoingDeeper-5.png" class="img-fluid"> <img src="GoingDeeper-6.png" class="img-fluid"> <img src="GoingDeeper-7.png" class="img-fluid"> <img src="GoingDeeper-8.png" class="img-fluid"></p>
<section id="an-irrigation-machine" class="level2">
<h2 class="anchored" data-anchor-id="an-irrigation-machine">An irrigation machine</h2>
<p>You’re going to automate the watering of farm parcels by making an intelligent irrigation machine. Multi-label classification problems differ from multi-class problems in that each observation can be labeled with zero or more classes. So classes/labels are not mutually exclusive, you could water all, none or any combination of farm parcels based on the inputs.</p>
<p>To account for this behavior what we do is have an output layer with as many neurons as classes but this time, unlike in multi-class problems, each output neuron has a sigmoid activation function. This makes each neuron in the output layer able to output a number between 0 and 1 independently.</p>
<p><img src="GoingDeeper-9.png" class="img-fluid"></p>
<div id="cell-34" class="cell" data-execution_count="60">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>irrigation <span class="op">=</span> pd.read_csv(<span class="st">'dataset/irrigation_machine.csv'</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>irrigation.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="60">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sensor_0</th>
<th data-quarto-table-cell-role="th">sensor_1</th>
<th data-quarto-table-cell-role="th">sensor_2</th>
<th data-quarto-table-cell-role="th">sensor_3</th>
<th data-quarto-table-cell-role="th">sensor_4</th>
<th data-quarto-table-cell-role="th">sensor_5</th>
<th data-quarto-table-cell-role="th">sensor_6</th>
<th data-quarto-table-cell-role="th">sensor_7</th>
<th data-quarto-table-cell-role="th">sensor_8</th>
<th data-quarto-table-cell-role="th">sensor_9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">sensor_13</th>
<th data-quarto-table-cell-role="th">sensor_14</th>
<th data-quarto-table-cell-role="th">sensor_15</th>
<th data-quarto-table-cell-role="th">sensor_16</th>
<th data-quarto-table-cell-role="th">sensor_17</th>
<th data-quarto-table-cell-role="th">sensor_18</th>
<th data-quarto-table-cell-role="th">sensor_19</th>
<th data-quarto-table-cell-role="th">parcel_0</th>
<th data-quarto-table-cell-role="th">parcel_1</th>
<th data-quarto-table-cell-role="th">parcel_2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>2.0</td>
<td>1.0</td>
<td>7.0</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>4.0</td>
<td>0.0</td>
<td>3.0</td>
<td>...</td>
<td>8.0</td>
<td>1.0</td>
<td>0.0</td>
<td>2.0</td>
<td>1.0</td>
<td>9.0</td>
<td>2.0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>5.0</td>
<td>1.0</td>
<td>3.0</td>
<td>5.0</td>
<td>2.0</td>
<td>2.0</td>
<td>1.0</td>
<td>2.0</td>
<td>3.0</td>
<td>1.0</td>
<td>...</td>
<td>4.0</td>
<td>5.0</td>
<td>5.0</td>
<td>2.0</td>
<td>2.0</td>
<td>2.0</td>
<td>7.0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3.0</td>
<td>1.0</td>
<td>4.0</td>
<td>3.0</td>
<td>4.0</td>
<td>0.0</td>
<td>1.0</td>
<td>6.0</td>
<td>0.0</td>
<td>2.0</td>
<td>...</td>
<td>3.0</td>
<td>3.0</td>
<td>1.0</td>
<td>0.0</td>
<td>3.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2.0</td>
<td>2.0</td>
<td>4.0</td>
<td>3.0</td>
<td>5.0</td>
<td>0.0</td>
<td>3.0</td>
<td>2.0</td>
<td>2.0</td>
<td>5.0</td>
<td>...</td>
<td>4.0</td>
<td>1.0</td>
<td>1.0</td>
<td>4.0</td>
<td>1.0</td>
<td>3.0</td>
<td>2.0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4.0</td>
<td>3.0</td>
<td>3.0</td>
<td>2.0</td>
<td>5.0</td>
<td>1.0</td>
<td>3.0</td>
<td>1.0</td>
<td>1.0</td>
<td>2.0</td>
<td>...</td>
<td>1.0</td>
<td>3.0</td>
<td>2.0</td>
<td>2.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>5 rows × 23 columns</p>
</div>
</div>
</div>
</div>
<div id="cell-35" class="cell" data-execution_count="61">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a hidden layer of 64 neurons and a 20 neuron's input</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">64</span>, input_shape<span class="op">=</span>(<span class="dv">20</span>, ), activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Add an output layer of 3 neurons with sigmoid activation</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">3</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile your model with binary crossentropy loss</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>              loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_12 (Dense)            (None, 64)                1344      
                                                                 
 dense_13 (Dense)            (None, 3)                 195       
                                                                 
=================================================================
Total params: 1,539
Trainable params: 1,539
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div id="cell-36" class="cell" data-execution_count="62">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">You've already built 3 models for 3 different problems! Hopefully you're starting to get a feel for how different problems can be modeled in the neural network realm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
You've already built 3 models for 3 different problems! Hopefully you're starting to get a feel for how different problems can be modeled in the neural network realm</code></pre>
</div>
</div>
</section>
<section id="training-with-multiple-labels" class="level2">
<h2 class="anchored" data-anchor-id="training-with-multiple-labels">Training with multiple labels</h2>
<p>An output of your multi-label model could look like this: [0.76 , 0.99 , 0.66 ]. If we round up probabilities higher than 0.5, this observation will be classified as containing all 3 possible labels [1,1,1]. For this particular problem, this would mean watering all 3 parcels in your field is the right thing to do given the input sensor measurements.</p>
<p>You will now train and predict with the model you just built. sensors_train, parcels_train, sensors_test and parcels_test are already loaded for you to use. Let’s see how well your machine performs!</p>
<div id="cell-38" class="cell" data-execution_count="63">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>parcels <span class="op">=</span> irrigation[[<span class="st">'parcel_0'</span>, <span class="st">'parcel_1'</span>, <span class="st">'parcel_2'</span>]].to_numpy()</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>sensors <span class="op">=</span> irrigation.drop([<span class="st">'parcel_0'</span>, <span class="st">'parcel_1'</span>, <span class="st">'parcel_2'</span>], axis<span class="op">=</span><span class="dv">1</span>).to_numpy()</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>sensors_train, sensors_test, parcels_train, parcels_test <span class="op">=</span> <span class="op">\</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    train_test_split(sensors, parcels, test_size<span class="op">=</span><span class="fl">0.3</span>, stratify<span class="op">=</span>parcels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-39" class="cell" data-execution_count="64">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train for 100 epochs using a validation split of 0.2</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>model.fit(sensors_train, parcels_train, epochs <span class="op">=</span> <span class="dv">100</span>, validation_split <span class="op">=</span> <span class="fl">0.2</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on sensors_test and round up the predictions</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> model.predict(sensors_test)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>preds_rounded <span class="op">=</span> np.<span class="bu">round</span>(preds)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Print rounded preds</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Rounded Predictions: </span><span class="ch">\n</span><span class="st">'</span>, preds_rounded)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate your model's accuracy on the test data</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> model.evaluate(sensors_test, parcels_test)[<span class="dv">1</span>]</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Print accuracy</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/100
35/35 [==============================] - 0s 8ms/step - loss: 0.7939 - accuracy: 0.4116 - val_loss: 0.5517 - val_accuracy: 0.3321
Epoch 2/100
35/35 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.5161 - val_loss: 0.4336 - val_accuracy: 0.5964
Epoch 3/100
35/35 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.6018 - val_loss: 0.3756 - val_accuracy: 0.5786
Epoch 4/100
35/35 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.6241 - val_loss: 0.3399 - val_accuracy: 0.6179
Epoch 5/100
35/35 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.6438 - val_loss: 0.3200 - val_accuracy: 0.6143
Epoch 6/100
35/35 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.6438 - val_loss: 0.3061 - val_accuracy: 0.6286
Epoch 7/100
35/35 [==============================] - 0s 5ms/step - loss: 0.3060 - accuracy: 0.6295 - val_loss: 0.2950 - val_accuracy: 0.6500
Epoch 8/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.6554 - val_loss: 0.2871 - val_accuracy: 0.5964
Epoch 9/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2869 - accuracy: 0.6348 - val_loss: 0.2856 - val_accuracy: 0.6607
Epoch 10/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.6500 - val_loss: 0.2765 - val_accuracy: 0.6250
Epoch 11/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2731 - accuracy: 0.6402 - val_loss: 0.2762 - val_accuracy: 0.6250
Epoch 12/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2671 - accuracy: 0.6411 - val_loss: 0.2680 - val_accuracy: 0.6286
Epoch 13/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.6411 - val_loss: 0.2630 - val_accuracy: 0.6179
Epoch 14/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2568 - accuracy: 0.6339 - val_loss: 0.2600 - val_accuracy: 0.6143
Epoch 15/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.6393 - val_loss: 0.2573 - val_accuracy: 0.6286
Epoch 16/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2488 - accuracy: 0.6455 - val_loss: 0.2548 - val_accuracy: 0.5929
Epoch 17/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2443 - accuracy: 0.6375 - val_loss: 0.2529 - val_accuracy: 0.5786
Epoch 18/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2411 - accuracy: 0.6339 - val_loss: 0.2526 - val_accuracy: 0.6107
Epoch 19/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2382 - accuracy: 0.6313 - val_loss: 0.2488 - val_accuracy: 0.6286
Epoch 20/100
35/35 [==============================] - 0s 4ms/step - loss: 0.2334 - accuracy: 0.6304 - val_loss: 0.2454 - val_accuracy: 0.6357
Epoch 21/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2279 - accuracy: 0.6384 - val_loss: 0.2438 - val_accuracy: 0.6250
Epoch 22/100
35/35 [==============================] - 0s 4ms/step - loss: 0.2252 - accuracy: 0.6384 - val_loss: 0.2407 - val_accuracy: 0.5964
Epoch 23/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2222 - accuracy: 0.6384 - val_loss: 0.2404 - val_accuracy: 0.6214
Epoch 24/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2201 - accuracy: 0.6259 - val_loss: 0.2386 - val_accuracy: 0.6036
Epoch 25/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2185 - accuracy: 0.6304 - val_loss: 0.2384 - val_accuracy: 0.6071
Epoch 26/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.6295 - val_loss: 0.2359 - val_accuracy: 0.6107
Epoch 27/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2160 - accuracy: 0.6366 - val_loss: 0.2326 - val_accuracy: 0.6000
Epoch 28/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2123 - accuracy: 0.6286 - val_loss: 0.2334 - val_accuracy: 0.5750
Epoch 29/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2081 - accuracy: 0.6330 - val_loss: 0.2325 - val_accuracy: 0.5821
Epoch 30/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2078 - accuracy: 0.6250 - val_loss: 0.2312 - val_accuracy: 0.6143
Epoch 31/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2052 - accuracy: 0.6143 - val_loss: 0.2329 - val_accuracy: 0.6393
Epoch 32/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2035 - accuracy: 0.6223 - val_loss: 0.2321 - val_accuracy: 0.6071
Epoch 33/100
35/35 [==============================] - 0s 5ms/step - loss: 0.2002 - accuracy: 0.6268 - val_loss: 0.2328 - val_accuracy: 0.6357
Epoch 34/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.6268 - val_loss: 0.2296 - val_accuracy: 0.6000
Epoch 35/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.6214 - val_loss: 0.2323 - val_accuracy: 0.6179
Epoch 36/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.6196 - val_loss: 0.2288 - val_accuracy: 0.5964
Epoch 37/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1933 - accuracy: 0.6268 - val_loss: 0.2307 - val_accuracy: 0.6214
Epoch 38/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.6143 - val_loss: 0.2287 - val_accuracy: 0.6214
Epoch 39/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.6196 - val_loss: 0.2324 - val_accuracy: 0.6286
Epoch 40/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1909 - accuracy: 0.6152 - val_loss: 0.2301 - val_accuracy: 0.5571
Epoch 41/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1896 - accuracy: 0.6214 - val_loss: 0.2343 - val_accuracy: 0.6607
Epoch 42/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.6054 - val_loss: 0.2338 - val_accuracy: 0.6464
Epoch 43/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1861 - accuracy: 0.6232 - val_loss: 0.2273 - val_accuracy: 0.5679
Epoch 44/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1858 - accuracy: 0.6152 - val_loss: 0.2385 - val_accuracy: 0.6107
Epoch 45/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1822 - accuracy: 0.6143 - val_loss: 0.2301 - val_accuracy: 0.6071
Epoch 46/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1825 - accuracy: 0.6241 - val_loss: 0.2289 - val_accuracy: 0.6143
Epoch 47/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.6304 - val_loss: 0.2301 - val_accuracy: 0.5500
Epoch 48/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.6107 - val_loss: 0.2303 - val_accuracy: 0.5964
Epoch 49/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.6080 - val_loss: 0.2335 - val_accuracy: 0.6179
Epoch 50/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1780 - accuracy: 0.6107 - val_loss: 0.2308 - val_accuracy: 0.6286
Epoch 51/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1765 - accuracy: 0.6196 - val_loss: 0.2308 - val_accuracy: 0.5643
Epoch 52/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.6152 - val_loss: 0.2296 - val_accuracy: 0.5607
Epoch 53/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1730 - accuracy: 0.6062 - val_loss: 0.2311 - val_accuracy: 0.5750
Epoch 54/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.6339 - val_loss: 0.2313 - val_accuracy: 0.5857
Epoch 55/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.6107 - val_loss: 0.2333 - val_accuracy: 0.5750
Epoch 56/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.6179 - val_loss: 0.2297 - val_accuracy: 0.5714
Epoch 57/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1684 - accuracy: 0.6152 - val_loss: 0.2334 - val_accuracy: 0.6250
Epoch 58/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1673 - accuracy: 0.6232 - val_loss: 0.2295 - val_accuracy: 0.6036
Epoch 59/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.6259 - val_loss: 0.2307 - val_accuracy: 0.5821
Epoch 60/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1651 - accuracy: 0.6098 - val_loss: 0.2308 - val_accuracy: 0.5821
Epoch 61/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1642 - accuracy: 0.6241 - val_loss: 0.2318 - val_accuracy: 0.5964
Epoch 62/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1631 - accuracy: 0.6089 - val_loss: 0.2305 - val_accuracy: 0.5929
Epoch 63/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.6161 - val_loss: 0.2305 - val_accuracy: 0.5786
Epoch 64/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.6179 - val_loss: 0.2335 - val_accuracy: 0.6250
Epoch 65/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1606 - accuracy: 0.6089 - val_loss: 0.2334 - val_accuracy: 0.6536
Epoch 66/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.6170 - val_loss: 0.2373 - val_accuracy: 0.6536
Epoch 67/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.6161 - val_loss: 0.2352 - val_accuracy: 0.6321
Epoch 68/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.6205 - val_loss: 0.2387 - val_accuracy: 0.5643
Epoch 69/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1557 - accuracy: 0.6071 - val_loss: 0.2358 - val_accuracy: 0.6464
Epoch 70/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 0.6161 - val_loss: 0.2318 - val_accuracy: 0.6250
Epoch 71/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.6098 - val_loss: 0.2355 - val_accuracy: 0.5929
Epoch 72/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.6268 - val_loss: 0.2358 - val_accuracy: 0.6286
Epoch 73/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1520 - accuracy: 0.6062 - val_loss: 0.2346 - val_accuracy: 0.6464
Epoch 74/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.6241 - val_loss: 0.2350 - val_accuracy: 0.6250
Epoch 75/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.6000 - val_loss: 0.2364 - val_accuracy: 0.6143
Epoch 76/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.6259 - val_loss: 0.2356 - val_accuracy: 0.6143
Epoch 77/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.6018 - val_loss: 0.2345 - val_accuracy: 0.5786
Epoch 78/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1474 - accuracy: 0.6098 - val_loss: 0.2368 - val_accuracy: 0.6179
Epoch 79/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.6062 - val_loss: 0.2413 - val_accuracy: 0.6214
Epoch 80/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1459 - accuracy: 0.6018 - val_loss: 0.2380 - val_accuracy: 0.6357
Epoch 81/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.6143 - val_loss: 0.2399 - val_accuracy: 0.6214
Epoch 82/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.6098 - val_loss: 0.2361 - val_accuracy: 0.6179
Epoch 83/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.6071 - val_loss: 0.2368 - val_accuracy: 0.6071
Epoch 84/100
35/35 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.6187 - val_loss: 0.2387 - val_accuracy: 0.6214
Epoch 85/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1412 - accuracy: 0.6062 - val_loss: 0.2451 - val_accuracy: 0.6607
Epoch 86/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 0.6009 - val_loss: 0.2404 - val_accuracy: 0.6464
Epoch 87/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1410 - accuracy: 0.6125 - val_loss: 0.2404 - val_accuracy: 0.6357
Epoch 88/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1370 - accuracy: 0.6152 - val_loss: 0.2447 - val_accuracy: 0.6321
Epoch 89/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1382 - accuracy: 0.6036 - val_loss: 0.2412 - val_accuracy: 0.5750
Epoch 90/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1393 - accuracy: 0.6036 - val_loss: 0.2391 - val_accuracy: 0.5714
Epoch 91/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.6268 - val_loss: 0.2399 - val_accuracy: 0.6214
Epoch 92/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.5946 - val_loss: 0.2423 - val_accuracy: 0.6250
Epoch 93/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1343 - accuracy: 0.6036 - val_loss: 0.2414 - val_accuracy: 0.6107
Epoch 94/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1350 - accuracy: 0.6098 - val_loss: 0.2430 - val_accuracy: 0.6357
Epoch 95/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.6062 - val_loss: 0.2439 - val_accuracy: 0.6071
Epoch 96/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1323 - accuracy: 0.6259 - val_loss: 0.2464 - val_accuracy: 0.5964
Epoch 97/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1319 - accuracy: 0.5911 - val_loss: 0.2457 - val_accuracy: 0.6393
Epoch 98/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.6089 - val_loss: 0.2481 - val_accuracy: 0.6714
Epoch 99/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.5955 - val_loss: 0.2474 - val_accuracy: 0.6607
Epoch 100/100
35/35 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.6116 - val_loss: 0.2520 - val_accuracy: 0.6679
19/19 [==============================] - 0s 1ms/step
Rounded Predictions: 
 [[1. 0. 0.]
 [1. 0. 0.]
 [0. 0. 0.]
 ...
 [1. 1. 1.]
 [0. 0. 0.]
 [1. 1. 0.]]
19/19 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.6550
Accuracy: 0.6549999713897705</code></pre>
</div>
</div>
<div id="cell-40" class="cell" data-execution_count="65">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">You can see how the validation_split argument is useful for evaluating how your model performs as it trains. Let's move on and improve your model training by using callbacks!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
You can see how the validation_split argument is useful for evaluating how your model performs as it trains. Let's move on and improve your model training by using callbacks!</code></pre>
</div>
</div>
</section>
</section>
<section id="keras-callbacks" class="level1">
<h1>Keras callbacks</h1>
<p>History EarlyStopping ModelCheckpoint The history callback The history callback is returned by default every time you train a model with the .fit() method. To access these metrics you can access the history dictionary parameter inside the returned h_callback object with the corresponding keys.</p>
<p>The irrigation machine model you built in the previous lesson is loaded for you to train, along with its features and labels now loaded as X_train, y_train, X_test, y_test. This time you will store the model’s history callback and use the validation_data parameter as it trains.</p>
<p>Let’s see the behind the scenes of our training!</p>
<div id="cell-42" class="cell" data-execution_count="66">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_accuracy(acc,val_acc):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot training &amp; validation accuracy values</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    plt.figure()<span class="op">;</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(acc)<span class="op">;</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(val_acc)<span class="op">;</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Model accuracy'</span>)<span class="op">;</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Accuracy'</span>)<span class="op">;</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)<span class="op">;</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    plt.legend([<span class="st">'Train'</span>, <span class="st">'Test'</span>], loc<span class="op">=</span><span class="st">'upper left'</span>)<span class="op">;</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(loss,val_loss):</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    plt.figure()<span class="op">;</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    plt.plot(loss)<span class="op">;</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    plt.plot(val_loss)<span class="op">;</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Model loss'</span>)<span class="op">;</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Loss'</span>)<span class="op">;</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)<span class="op">;</span></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>    plt.legend([<span class="st">'Train'</span>, <span class="st">'Test'</span>], loc<span class="op">=</span><span class="st">'upper right'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-43" class="cell" data-execution_count="67">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> sensors_train, parcels_train</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>X_test, y_test <span class="op">=</span> sensors_test, parcels_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-44" class="cell" data-execution_count="68">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>h_callback <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">50</span>, validation_data<span class="op">=</span>(X_test, y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
44/44 [==============================] - 1s 8ms/step - loss: 0.1578 - accuracy: 0.6136 - val_loss: 0.2384 - val_accuracy: 0.6133
Epoch 2/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1524 - accuracy: 0.5950 - val_loss: 0.2345 - val_accuracy: 0.6483
Epoch 3/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 0.6407 - val_loss: 0.2459 - val_accuracy: 0.6133
Epoch 4/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1485 - accuracy: 0.6014 - val_loss: 0.2327 - val_accuracy: 0.5850
Epoch 5/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1459 - accuracy: 0.6143 - val_loss: 0.2406 - val_accuracy: 0.6083
Epoch 6/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1449 - accuracy: 0.6064 - val_loss: 0.2363 - val_accuracy: 0.6533
Epoch 7/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1443 - accuracy: 0.6164 - val_loss: 0.2390 - val_accuracy: 0.6417
Epoch 8/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1448 - accuracy: 0.6071 - val_loss: 0.2356 - val_accuracy: 0.5900
Epoch 9/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.6064 - val_loss: 0.2375 - val_accuracy: 0.5900
Epoch 10/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1400 - accuracy: 0.6107 - val_loss: 0.2380 - val_accuracy: 0.5700
Epoch 11/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1415 - accuracy: 0.6071 - val_loss: 0.2446 - val_accuracy: 0.5850
Epoch 12/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1412 - accuracy: 0.5929 - val_loss: 0.2361 - val_accuracy: 0.5817
Epoch 13/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1390 - accuracy: 0.5986 - val_loss: 0.2386 - val_accuracy: 0.5517
Epoch 14/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1397 - accuracy: 0.6043 - val_loss: 0.2456 - val_accuracy: 0.6417
Epoch 15/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.6057 - val_loss: 0.2421 - val_accuracy: 0.6217
Epoch 16/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1350 - accuracy: 0.5950 - val_loss: 0.2440 - val_accuracy: 0.5983
Epoch 17/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1356 - accuracy: 0.6107 - val_loss: 0.2399 - val_accuracy: 0.6167
Epoch 18/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.6043 - val_loss: 0.2436 - val_accuracy: 0.5967
Epoch 19/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1340 - accuracy: 0.6114 - val_loss: 0.2413 - val_accuracy: 0.5950
Epoch 20/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.5879 - val_loss: 0.2498 - val_accuracy: 0.6217
Epoch 21/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1325 - accuracy: 0.6157 - val_loss: 0.2434 - val_accuracy: 0.6183
Epoch 22/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1305 - accuracy: 0.6043 - val_loss: 0.2470 - val_accuracy: 0.6367
Epoch 23/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1308 - accuracy: 0.6021 - val_loss: 0.2518 - val_accuracy: 0.6150
Epoch 24/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.6021 - val_loss: 0.2425 - val_accuracy: 0.5433
Epoch 25/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.5900 - val_loss: 0.2450 - val_accuracy: 0.6300
Epoch 26/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.6029 - val_loss: 0.2505 - val_accuracy: 0.6350
Epoch 27/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.5993 - val_loss: 0.2532 - val_accuracy: 0.6583
Epoch 28/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1269 - accuracy: 0.6086 - val_loss: 0.2482 - val_accuracy: 0.6067
Epoch 29/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.5979 - val_loss: 0.2447 - val_accuracy: 0.5650
Epoch 30/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.6007 - val_loss: 0.2456 - val_accuracy: 0.5817
Epoch 31/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.5850 - val_loss: 0.2487 - val_accuracy: 0.5817
Epoch 32/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.6007 - val_loss: 0.2488 - val_accuracy: 0.6000
Epoch 33/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.6071 - val_loss: 0.2502 - val_accuracy: 0.5350
Epoch 34/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1217 - accuracy: 0.5829 - val_loss: 0.2500 - val_accuracy: 0.5900
Epoch 35/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1226 - accuracy: 0.6093 - val_loss: 0.2521 - val_accuracy: 0.5917
Epoch 36/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.5986 - val_loss: 0.2532 - val_accuracy: 0.6267
Epoch 37/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.5714 - val_loss: 0.2529 - val_accuracy: 0.6517
Epoch 38/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.6186 - val_loss: 0.2551 - val_accuracy: 0.6200
Epoch 39/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.5929 - val_loss: 0.2499 - val_accuracy: 0.5883
Epoch 40/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.5936 - val_loss: 0.2532 - val_accuracy: 0.6167
Epoch 41/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.6086 - val_loss: 0.2544 - val_accuracy: 0.6133
Epoch 42/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.5929 - val_loss: 0.2622 - val_accuracy: 0.6250
Epoch 43/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.5971 - val_loss: 0.2545 - val_accuracy: 0.6000
Epoch 44/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.5921 - val_loss: 0.2676 - val_accuracy: 0.5567
Epoch 45/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.6057 - val_loss: 0.2600 - val_accuracy: 0.5950
Epoch 46/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.5907 - val_loss: 0.2559 - val_accuracy: 0.5817
Epoch 47/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.5921 - val_loss: 0.2591 - val_accuracy: 0.6350
Epoch 48/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1148 - accuracy: 0.5929 - val_loss: 0.2577 - val_accuracy: 0.5933
Epoch 49/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.5943 - val_loss: 0.2586 - val_accuracy: 0.5517
Epoch 50/50
44/44 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.5964 - val_loss: 0.2620 - val_accuracy: 0.6150</code></pre>
</div>
</div>
<div id="cell-45" class="cell" data-execution_count="69">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>plot_loss(h_callback.history[<span class="st">'loss'</span>], h_callback.history[<span class="st">'val_loss'</span>])</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot train vs test accuracy during training</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>plot_accuracy(h_callback.history[<span class="st">'accuracy'</span>], h_callback.history[<span class="st">'val_accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="early-stopping-your-model" class="level2">
<h2 class="anchored" data-anchor-id="early-stopping-your-model">Early stopping your model</h2>
<p>The early stopping callback is useful since it allows for you to stop the model training if it no longer improves after a given number of epochs. To make use of this functionality you need to pass the callback inside a list to the model’s callback parameter in the .fit() method.</p>
<p>The model you built to detect fake dollar bills is loaded for you to train, this time with early stopping. X_train, y_train, X_test and y_test are also available for you to use.</p>
<div id="cell-47" class="cell" data-execution_count="70">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> banknotes.iloc[:, :<span class="dv">4</span>]</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> ((X <span class="op">-</span> X.mean()) <span class="op">/</span> X.std()).to_numpy()</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> banknotes[<span class="st">'class'</span>].to_numpy()</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.25</span>, stratify<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-48" class="cell" data-execution_count="71">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a dense layer</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">1</span>, input_shape<span class="op">=</span>(<span class="dv">4</span>, ), activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile your model</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'sgd'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-49" class="cell" data-execution_count="72">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the early stopping callback</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a callback to monitor val_accuracy</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>monitor_val_acc <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'val_accuracy'</span>, patience<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Train your model using the early stopping callback</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">1000</span>, validation_data<span class="op">=</span>(X_test, y_test),</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>          callbacks<span class="op">=</span>[monitor_val_acc])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1000
33/33 [==============================] - 1s 10ms/step - loss: 1.5896 - accuracy: 0.2624 - val_loss: 1.5037 - val_accuracy: 0.2741
Epoch 2/1000
33/33 [==============================] - 0s 5ms/step - loss: 1.3869 - accuracy: 0.2779 - val_loss: 1.3122 - val_accuracy: 0.2828
Epoch 3/1000
33/33 [==============================] - 0s 5ms/step - loss: 1.2060 - accuracy: 0.2974 - val_loss: 1.1436 - val_accuracy: 0.3120
Epoch 4/1000
33/33 [==============================] - 0s 5ms/step - loss: 1.0495 - accuracy: 0.3120 - val_loss: 0.9972 - val_accuracy: 0.3411
Epoch 5/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.9165 - accuracy: 0.3537 - val_loss: 0.8734 - val_accuracy: 0.3936
Epoch 6/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.8060 - accuracy: 0.4344 - val_loss: 0.7715 - val_accuracy: 0.5102
Epoch 7/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.7162 - accuracy: 0.5355 - val_loss: 0.6890 - val_accuracy: 0.6093
Epoch 8/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6647 - val_loss: 0.6231 - val_accuracy: 0.7289
Epoch 9/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.8154 - val_loss: 0.5720 - val_accuracy: 0.8484
Epoch 10/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.8785 - val_loss: 0.5312 - val_accuracy: 0.9009
Epoch 11/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.9223 - val_loss: 0.4972 - val_accuracy: 0.9242
Epoch 12/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.9339 - val_loss: 0.4699 - val_accuracy: 0.9504
Epoch 13/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.9368 - val_loss: 0.4468 - val_accuracy: 0.9534
Epoch 14/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.9368 - val_loss: 0.4271 - val_accuracy: 0.9417
Epoch 15/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.9339 - val_loss: 0.4098 - val_accuracy: 0.9417
Epoch 16/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.9291 - val_loss: 0.3951 - val_accuracy: 0.9388
Epoch 17/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.9291 - val_loss: 0.3822 - val_accuracy: 0.9388
Epoch 18/1000
33/33 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.9291 - val_loss: 0.3706 - val_accuracy: 0.9359</code></pre>
</div>
</div>
</section>
<section id="a-combination-of-callbacks" class="level2">
<h2 class="anchored" data-anchor-id="a-combination-of-callbacks">A combination of callbacks</h2>
<p>Deep learning models can take a long time to train, especially when you move to deeper architectures and bigger datasets. Saving your model every time it improves as well as stopping it when it no longer does allows you to worry less about choosing the number of epochs to train for. You can also restore a saved model anytime and resume training where you left it.</p>
<p>Use the EarlyStopping() and the ModelCheckpoint() callbacks so that you can go eat a jar of cookies while you leave your computer to work!</p>
<div id="cell-51" class="cell" data-execution_count="74">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> ModelCheckpoint</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Early stop on validation accuracy</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>monitor_val_acc <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'val_accuracy'</span>, patience<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the best model as best_banknote_model.hdf5</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>modelCheckpoint <span class="op">=</span> ModelCheckpoint(<span class="st">'./best_banknote_model.hdf5'</span>, save_best_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit your model for a stupid amount of epochs</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>h_callback <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>                       epochs<span class="op">=</span><span class="dv">1000000000000</span>,</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>                       callbacks<span class="op">=</span>[monitor_val_acc, modelCheckpoint],</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>                       validation_data<span class="op">=</span>(X_test, y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/1000000000000
33/33 [==============================] - 0s 6ms/step - loss: 0.3041 - accuracy: 0.9242 - val_loss: 0.3002 - val_accuracy: 0.9388
Epoch 2/1000000000000
33/33 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.9232 - val_loss: 0.2946 - val_accuracy: 0.9388
Epoch 3/1000000000000
33/33 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.9261 - val_loss: 0.2894 - val_accuracy: 0.9359
Epoch 4/1000000000000
33/33 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.9252 - val_loss: 0.2844 - val_accuracy: 0.9388</code></pre>
</div>
</div>
<div id="cell-52" class="cell" data-execution_count="75">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls <span class="op">|</span> grep best_banknote<span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>best_banknote_model.hdf5</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="kakamana/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>