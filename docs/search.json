[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Muhammad Asad Kamran is passionate\nMuhammad Asad Kamran has more than 15 years of experience in Software Engineering profession. Having strong hands on for architect, development, consultation & team building/managing experience of enterprise application & their integration with business critical applications, which includes SharePoint/Project Server, Asp.Net MVC & Biztalk complex applications.\nBeing a certified PMP & Prince 2 practitioner, Asad has been managing & mentoring mission critical team which delivered successful & award wining projects worth millions for clients in Middle East, Europe including Telco Operators, Oil & Gas clients, ministries, Insurance giant & multinational Attorney giants. Having numerous success stories of working with key stakeholders to develop architectural framework that aligns strategy, processes, and IT assets with business goals.\nExcellent communication, presentation, and organizational skills. Involved in successful Digital Transformation & Integration projects which provides G2G, G2B, B2B, B2C & G2C e-commerce & Digital services. His core competencies are Collaboration, Messaging, Enterprise solution architecture, Digitization transformation, project management, Agile methodologies & Data analytics."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nUniversity Of Michigan | Michigan, USA Masters in applied data science (MADS) | May 2022 - April 2024\nComsats Institute Of Information Technology | Lahore, Pakistan Bachelors Of Computer Science (Software Engineering) | 2002 - 2005"
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\n\n\nDec 31, 2022\n\n\n0 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\nDec 28, 2022\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kamana’s Blogs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2022\n\n\nHarlow Malloc\n\n\n0 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 28, 2022\n\n\nTristan O’Malley\n\n\n0 min\n\n\n\n\n\n\n  \n\n\n\n\nRandom Numbers and Probability\n\n\n\n\n\n\n\npython\n\n\ndatacamp\n\n\nstatistics\n\n\ndistribution\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2022\n\n\nkakamana\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Of Statistics\n\n\n\n\n\n\n\npython\n\n\ndatacamp\n\n\nstatistics\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2022\n\n\nkakamana\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/Random numbers and probability/Random numbers and probability.html",
    "href": "posts/Random numbers and probability/Random numbers and probability.html",
    "title": "Random Numbers and Probability",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\nRandom Numbers and Probability\nThis Random Numbers and Probability is part of Datacamp course: Introduction to Statistic in Python\nHere we’ll explore how to generate random samples and measure chance using probability.We will work with real-world sales data to calculate the probability of a salesperson being successful. Finally, we will try to use the binomial distribution to model events with binary outcomes.\nThis is my learning experience of data science through DataCamp\n\nMeasuring chance\n\\[ P(\\text{event}) = \\frac{\\text{# ways event can happen}}{\\text{total # of possible outcomes}} \\]\nSampling with replacement vs sampling without replacement\nsampling without replacement, in which a subset of the observations are selected randomly, and once an observation is selected it cannot be selected again. sampling with replacement, in which a subset of observations are selected randomly, and an observation may be selected more than once\n\n\nCalculating probabilities\nYou’re in charge of the sales team, and it’s time for performance reviews, starting with Amir. As part of the review, you want to randomly select a few of the deals that he’s worked on over the past year so that you can look at them more deeply. Before you start selecting deals, you’ll first figure out what the chances are of selecting certain deals.\nRecall that the probability of an event can be calculated by\n\\[ P(\\text{event}) = \\frac{\\text{# ways event can happen}}{\\text{total # of possible outcomes}} \\]\n\n\nCode\namir_deals = pd.read_csv('amir_deals.csv', index_col=0)\namir_deals.head()\n\n\n\n\n\n\n  \n    \n      \n      product\n      client\n      status\n      amount\n      num_users\n    \n  \n  \n    \n      1\n      Product F\n      Current\n      Won\n      7389.52\n      19\n    \n    \n      2\n      Product C\n      New\n      Won\n      4493.01\n      43\n    \n    \n      3\n      Product B\n      New\n      Won\n      5738.09\n      87\n    \n    \n      4\n      Product I\n      Current\n      Won\n      2591.24\n      83\n    \n    \n      5\n      Product E\n      Current\n      Won\n      6622.97\n      17\n    \n  \n\n\n\n\n\n\nCode\ncounts = amir_deals['product'].value_counts()\nprint(counts)\n\n# Calculate probability of picking a deal with each product\nprobs = counts / len(amir_deals['product'])\nprint(probs)\n\n\nProduct B    62\nProduct D    40\nProduct A    23\nProduct C    15\nProduct F    11\nProduct H     8\nProduct I     7\nProduct E     5\nProduct N     3\nProduct G     2\nProduct J     2\nName: product, dtype: int64\nProduct B    0.348315\nProduct D    0.224719\nProduct A    0.129213\nProduct C    0.084270\nProduct F    0.061798\nProduct H    0.044944\nProduct I    0.039326\nProduct E    0.028090\nProduct N    0.016854\nProduct G    0.011236\nProduct J    0.011236\nName: product, dtype: float64\n\n\n\n\nSampling deals\nIn the previous exercise, you counted the deals Amir worked on. Now it’s time to randomly pick five deals so that you can reach out to each customer and ask if they were satisfied with the service they received. You’ll try doing this both with and without replacement.\nAdditionally, you want to make sure this is done randomly and that it can be reproduced in case you get asked how you chose the deals, so you’ll need to set the random seed before sampling from the deals.\n\n\nCode\n# Set random seed\nnp.random.seed(24)\n\n# Sample 5 deals without replacement\nsample_without_replacement = amir_deals.sample(5,replace=False)\nprint(sample_without_replacement)\n\n\n       product   client status   amount  num_users\n128  Product B  Current    Won  2070.25          7\n149  Product D  Current    Won  3485.48         52\n78   Product B  Current    Won  6252.30         27\n105  Product D  Current    Won  4110.98         39\n167  Product C      New   Lost  3779.86         11\n\n\n\n\nCode\n# Set random seed\nnp.random.seed(24)\n\n# Sample 5 deals with replacement\nsample_with_replacement = amir_deals.sample(5,replace=True)\nprint(sample_with_replacement)\n\n\n       product   client status   amount  num_users\n163  Product D  Current    Won  6755.66         59\n132  Product B  Current    Won  6872.29         25\n88   Product C  Current    Won  3579.63          3\n146  Product A  Current    Won  4682.94         63\n146  Product A  Current    Won  4682.94         63\n\n\n\n\nDiscrete distributions\n\nProbability distribution\n\nDescribe probability of each possible outcome in a scenario\nExpected value: mean of probability distribution\n\nLaw of large number (LLN): as size of sample increases, sample mean will approach expected value.\n\n\n\nCreating a probability distribution\nRestaurant management wants to optimize seating space based on the size of the groups that come most often to a new restaurant. One night, 10 groups of people are waiting to be seated at the restaurant, but instead of being called in the order they arrived, they will be called randomly. This exercise examines the probability of picking groups of different sizes.\nRemember that expected value can be calculated by multiplying each possible outcome with its corresponding probability and taking the sum\n\n\nCode\nrestaurant_groups = pd.read_csv('restaurant_groups.csv')\nrestaurant_groups.head()\n\n\n\n\n\n\n  \n    \n      \n      group_id\n      group_size\n    \n  \n  \n    \n      0\n      A\n      2\n    \n    \n      1\n      B\n      4\n    \n    \n      2\n      C\n      6\n    \n    \n      3\n      D\n      2\n    \n    \n      4\n      E\n      2\n    \n  \n\n\n\n\n\n\nCode\n# Create a histogram of restaurant_groups and show plot\nrestaurant_groups['group_size'].hist(bins=[2, 3, 4, 5, 6])\n\n\n<AxesSubplot:>\n\n\n\n\n\n\n\nCode\n# Create probability distribution\nsize_dist = restaurant_groups['group_size'].value_counts() / restaurant_groups.shape[0]\n# Reset index and rename columns\nsize_dist = size_dist.reset_index()\nsize_dist.columns = ['group_size', 'prob']\nprint(size_dist)\n\n# Expected value\nexpected_value = np.sum(size_dist['group_size'] * size_dist['prob'])\nprint(expected_value)\n\n# Subset groups of size 4 or more\ngroups_4_or_more = size_dist[size_dist['group_size'] >=4]\n\n# Sum the probabilities of groups_4_or_more\nprob_4_or_more = groups_4_or_more['prob'].sum()\nprint(prob_4_or_more)\n\n\n   group_size  prob\n0           2   0.6\n1           4   0.2\n2           6   0.1\n3           3   0.1\n2.9000000000000004\n0.30000000000000004\n\n\n\n\nContinuous distributions\nData back-ups\nYour company’s sales software backs itself up automatically, but no one knows exactly when the back-ups take place. It is known, however, that back-ups occur every 30 minutes. Amir updates the client data after sales meetings at random times. When will his newly-entered data be backed up? Answer Amir’s questions using your new knowledge of continuous uniform distributions\n\n\nCode\nfrom scipy.stats import uniform\n\n# Min and max wait times for back-up that happens every 30 min\nmin_time = 0\nmax_time = 30\n\n# Calculate probability of waiting less than 5 mins\nprob_less_than_5 = uniform.cdf(5, min_time, max_time)\nprint(prob_less_than_5)\n\n# Calculate probability of waiting more than 5 mins\nprob_greater_than_5 = 1 - uniform.cdf(5, min_time, max_time)\nprint(prob_greater_than_5)\n\n# Calculate probability of waiting 10-20 mins\nprob_between_10_and_20 = uniform.cdf(20, min_time, max_time) - \\\n                        uniform.cdf(10, min_time, max_time)\nprint(prob_between_10_and_20)\n\n\n0.16666666666666666\n0.8333333333333334\n0.3333333333333333\n\n\n\n\nSimulating wait times\nTo give Amir a better idea of how long he’ll have to wait, you’ll simulate Amir waiting 1000 times and create a histogram to show him what he should expect. Recall from the last exercise that his minimum wait time is 0 minutes and his maximum wait time is 30 minutes.\n\n\nCode\nnp.random.seed(334)\n\n# Generates 1000 wait times between 0 and 30 mins\nwait_times = uniform.rvs(min_time, max_time, 1000)\nprint(wait_times[:10])\n\n# Create a histogram of simulated times and show plot\nplt.hist(wait_times);\nprint (\"Unless Amir figures out exactly what time each backup happens, he won't be able to time his data entry so it gets backed up sooner, but it looks like he'll wait about 15 minutes on average\\n\")\n\n\n[ 7.144097    0.97455866  3.72802787  5.11644319  8.70602482 24.69140099\n 23.98012075  3.19592668 25.1985306  17.89048629]\nUnless Amir figures out exactly what time each backup happens, he won't be able to time his data entry so it gets backed up sooner, but it looks like he'll wait about 15 minutes on average\n\n\n\n\n\n\n\n\nThe binomial distribution\n\nBinomial distribution\n\nProbability distribution of number of successes in a sequence of independent trials\nDescribed by n and p\n\nn: total number of trials\np: probability of success\n\nExpected value: n * p\nIndependence: The binomial distribution is a probability distribution of number of successes in a sequence of independent trials\n\n\n\n\nSimulating sales deals\nAssume that Amir usually works on 3 deals per week, and overall, he wins 30% of deals he works on. Each deal has a binary outcome: it’s either lost, or won, so you can model his sales deals with a binomial distribution. In this exercise, you’ll help Amir simulate a year’s worth of his deals so he can better understand his performance.\n\n\nCode\n# Import binom from scipy.stats\nfrom scipy.stats import binom\n\n# Set random seed to 10\nnp.random.seed(10)\n\n# Simulate a single deal\nprint(binom.rvs(1, 0.3, size=1))\n\n# Simulate 1 week of 3 deals\nprint(binom.rvs(3,0.3,size=1))\n\n# Simulate 52 weeks of 3 deals\ndeals = binom.rvs(3,0.3,size=52)\n\n# Print mean deals won per week\nprint(np.mean(deals))\n\nprint('\\nIn this simulated year, Amir won 0.83 deals on average each week')\n\n\n[1]\n[0]\n0.8461538461538461\n\nIn this simulated year, Amir won 0.83 deals on average each week\n\n\n\n\nCalculating binomial probabilities\nJust as in the last exercise, assume that Amir wins 30% of deals. He wants to get an idea of how likely he is to close a certain number of deals each week. In this exercise, you’ll calculate what the chances are of him closing different numbers of deals using the binomial distribution.\n\n\nCode\n# Probability of closing 3 out of 3 deals\nprob_3 = binom.pmf(3,3,0.3)\nprint(prob_3)\n\n# Probability of closing <= 1 deal out of 3 deals\nprob_less_than_or_equal_1 = binom.cdf(1,3,0.3)\nprint(prob_less_than_or_equal_1)\n\n# Probability of closing > 1 deal out of 3 deals\nprob_greater_than_1 =1- binom.cdf(1,3,0.3)\nprint(prob_greater_than_1)\n\nprint(\"\\nAmir has about a 22% chance of closing more than one deal in a week.\")\n\n\n0.026999999999999996\n0.784\n0.21599999999999997\n\nAmir has about a 22% chance of closing more than one deal in a week.\n\n\n\n\nHow many sales will be won?\nNow Amir wants to know how many deals he can expect to close each week if his win rate changes. Luckily, you can use your binomial distribution knowledge to help him calculate the expected value in different situations. Recall from the video that the expected value of a binomial distribution can be calculated by n*p\n\n\nCode\n# Expected number won with 30% win rate\nwon_30pct = 3 * 0.3\nprint(won_30pct)\n\n# Expected number won with 25% win rate\nwon_25pct = 3 * 0.25\nprint(won_25pct)\n\n# Expected number won with 35% win rate\nwon_35pct = 3 * 0.35\nprint(won_35pct)\n\nprint('\\nIf Amirs win rate goes up by 5%, he can expect to close more than 1 deal on average each week')\n\n\n0.8999999999999999\n0.75\n1.0499999999999998\n\nIf Amirs win rate goes up by 5%, he can expect to close more than 1 deal on average each week"
  },
  {
    "objectID": "posts/Summary of statistics/Summary Of Statistics.html",
    "href": "posts/Summary of statistics/Summary Of Statistics.html",
    "title": "Summary Of Statistics",
    "section": "",
    "text": "Datacamp course: Introduction to Statistic in Python\nThe study of statistics involves collecting, analyzing, and interpreting data. You can use it to bring the future into focus and infer answers to tons of questions. How many calls will your support team receive, and how many jeans sizes should you manufacture to fit 95% of the population? Statistical skills are developed in this course, which teaches you how to calculate averages, plot relationships between numeric values, and calculate correlations. In addition, you’ll learn how to conduct a well-designed study using Python to draw your own conclusions.\nCourse Takeaways:\n\nSummary Statistics\nRandom Numbers & Probability\nMore Distributions and the Central Limit Theorem\nCorrelation and Experimental Design\n\n\n\nStatistics - what is it?\n\nStatistics is the practice and study of collecting and analyzing data\nA summary statistic is a fact about or a summary of some data\n\nHow can statistics be used?\n\nDoes a product have a high likelihood of being purchased? People are more likely to purchase the product if they are familiar with it\nIs there an alternative payment system available?\nCan you tell me how many occupants your hotel will have? In what ways can you optimize occupancy?\nTo meet the needs of 95% of the population, how many sizes of jeans should be manufactured?\nCan the same number of each size be produced?\nA/B tests: Which advertisement is more effective in motivating the purchase of a product?\n\n\n\n\nDescriptive: To describe & summarize data e.g. 25% ride bike, 35% take bus ride & 50% drive to work\nInferential : Use sample data to make inferences about a larger population e.g. what percent of people drive to work?\n\n\n\n\n\nNumeric (quantitative)\nContinuous (measured)\n\nairplance speed\ntime spent waiting\n\nDiscrete (counted)\n\nnumber of devices\nnumber of people\n\nCategorical (qualitative)\nNominal (unordered)\n\nsingle / married\ncountry of residence\n\nOrdinal (ordered) agree, disagree, strongly diagree\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\n\n\n\n\nCode\nfood_consumption=pd.read_csv('food_consumption.csv')\n\n\n\n\nCode\n# Filter for Belgium\nbe_consumption = food_consumption[food_consumption['country']=='Belgium']\n\n# Filter for USA\nusa_consumption = food_consumption[food_consumption['country']=='USA']\n\n# Calculate mean and median consumption in Belgium\nprint(np.mean(be_consumption['consumption']))\nprint(np.median(be_consumption['consumption']))\n\n# Calculate mean and median consumption in USA\nprint(np.mean(usa_consumption['consumption']))\nprint(np.median(usa_consumption['consumption']))\n\n\n42.13272727272727\n12.59\n44.650000000000006\n14.58\n\n\n\n\nCode\n# Subset for Belgium and USA only\nbe_and_usa = food_consumption[(food_consumption['country']=='Belgium') | (food_consumption['country']=='USA')]\n\n# Group by country, select consumption column, and compute mean and median\nprint(be_and_usa.groupby('country')['consumption'].agg([np.mean,np.median]))\n\n\n              mean  median\ncountry                   \nBelgium  42.132727   12.59\nUSA      44.650000   14.58\n\n\nMean vs Median\n\n\nCode\n# Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n# Subset for food_category equals rice\nrice_consumption = food_consumption[food_consumption['food_category']=='rice']\n\n# Histogram of co2_emission for rice and show plot\nplt.hist(rice_consumption['co2_emission'])\nplt.show()\n\n\n\n\n\n\n\nCode\n# Calculate mean and median of co2_emission with .agg()\nprint(rice_consumption['co2_emission'].agg([np.mean,np.median]))\n\n\nmean      37.591615\nmedian    15.200000\nName: co2_emission, dtype: float64\n\n\n\n\n\n\nVariance: Average distance from each data point to the data’s mean\nStandard Deviation\n\n\n\nCode\n# Calculate the quartiles of co2_emission\nprint(np.quantile(food_consumption['co2_emission'],np.linspace(0,1,5)))\n\n# Calculate the quintiles of co2_emission\nprint(np.quantile(food_consumption['co2_emission'],np.linspace(0,1,6)))\n\n# Calculate the deciles of co2_emission\nprint(np.quantile(food_consumption['co2_emission'],np.linspace(0,1,11)))\n\n\n[   0.        5.21     16.53     62.5975 1712.    ]\n[   0.       3.54    11.026   25.59    99.978 1712.   ]\n[0.00000e+00 6.68000e-01 3.54000e+00 7.04000e+00 1.10260e+01 1.65300e+01\n 2.55900e+01 4.42710e+01 9.99780e+01 2.03629e+02 1.71200e+03]\n\n\n\n\n\nA variable’s variance and standard deviation are two of the most common ways to measure its spread, and you will practice calculating them in this exercise. Spread informs expectations. In other words, if a salesperson sells a mean of 20 products a day, but has a standard deviation of 10, they might sell 40 products one day, and one or two the next. Predictions require information like this.\n\n\nCode\n# Print variance and sd of co2_emission for each food_category\nprint(food_consumption.groupby('food_category')['co2_emission'].agg([np.var,np.std]))\n\n# Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n# Create histogram of co2_emission for food_category 'beef'\nplt.hist(food_consumption[food_consumption['food_category']=='beef']['co2_emission'])\n# Show plot\nplt.show()\n\n# Create histogram of co2_emission for food_category 'eggs'\nplt.hist(food_consumption[food_consumption['food_category']=='eggs']['co2_emission'])\n# Show plot\nplt.show()\n\n\n                        var         std\nfood_category                          \nbeef           88748.408132  297.906710\ndairy          17671.891985  132.935669\neggs              21.371819    4.622966\nfish             921.637349   30.358481\nlamb_goat      16475.518363  128.356996\nnuts              35.639652    5.969895\npork            3094.963537   55.632396\npoultry          245.026801   15.653332\nrice            2281.376243   47.763754\nsoybeans           0.879882    0.938020\nwheat             71.023937    8.427570\n\n\n\n\n\n\n\n\nFinding outliers using IQR\nOutliers can have big effects on statistics like mean, as well as statistics that rely on the mean, such as variance and standard deviation. Interquartile range, or IQR, is another way of measuring spread that’s less influenced by outliers. IQR is also often used to find outliers. If a value is less than Q1−1.5×IQRQ1−1.5×IQR or greater than Q3+1.5×IQRQ3+1.5×IQR, it’s considered an outlier.\n\n\nCode\n# Calculate total co2_emission per country: emissions_by_country\nemissions_by_country = food_consumption.groupby('country')['co2_emission'].sum()\n\nprint(emissions_by_country)\n\n\ncountry\nAlbania      1777.85\nAlgeria       707.88\nAngola        412.99\nArgentina    2172.40\nArmenia      1109.93\n              ...   \nUruguay      1634.91\nVenezuela    1104.10\nVietnam       641.51\nZambia        225.30\nZimbabwe      350.33\nName: co2_emission, Length: 130, dtype: float64\n\n\n\n\nCode\n# Calculate total co2_emission per country: emissions_by_country\nemissions_by_country = food_consumption.groupby('country')['co2_emission'].sum()\n\n# Compute the first and third quantiles and IQR of emissions_by_country\nq1 = np.quantile(emissions_by_country, 0.25)\nq3 = np.quantile(emissions_by_country, 0.75)\niqr = q3 - q1\n\n# Calculate the lower and upper cutoffs for outliers\nlower = q1 - 1.5 * iqr\nupper = q3 + 1.5 * iqr\n\n# Subset emissions_by_country to find outliers\noutliers = emissions_by_country[(emissions_by_country > upper) | (emissions_by_country < lower)]\nprint(outliers)\n\n\ncountry\nArgentina    2172.4\nName: co2_emission, dtype: float64\n\n\n\n\n\n\nIn this chapter, you’ll learn how to generate random samples and measure chance using probability. You’ll work with real-world sales data to calculate the probability of a salesperson being successful. Finally, you’ll use the binomial distribution to model events with binary outcomes"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]