{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Regression - machine learning with PySpark\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "author: \"kakamana\"\n",
    "date: \"2023-04-10\"\n",
    "categories: [python, datacamp, machine learning, pyspark, regression]\n",
    "image: \"regression.png\"\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression\n",
    "\n",
    "Next, you will learn how to create linear regression models. In addition, you will learn how to augment your data with new predictors as well as how to select only the most relevant predictors.\n",
    "\n",
    "This **Regression** is part of [Datacamp course: Machine Learning with PySpark] Spark is a powerful, general-purpose tool for working with large data sets. Spark transparently distributes compute tasks across a cluster. By doing this, operations are fast, but you can also focus on the analysis rather than worry about technical details. This course will teach you how to get data into Spark, and then dive into three fundamental Spark Machine Learning algorithms: Linear Regression, Logistic Regression/Classifiers, and creating pipelines. You will analyze a large dataset of flight delays and spam text messages along the way. With this background, you will be able to harness the power of Spark and apply it to your own Machine Learning projects.\n",
    "\n",
    "This is my learning experience of data science through DataCamp. These repository contributions are part of my learning journey through my graduate program masters of applied data sciences (MADS) at University Of Michigan, [DeepLearning.AI], [Coursera] & [DataCamp]. You can find my similar articles & more stories at my [medium] & [LinkedIn] profile. I am available at [kaggle] & [github blogs] & [github repos]. Thank you for your motivation, support & valuable feedback.\n",
    "\n",
    "These include projects, coursework & notebook which I learned through my data science journey. They are created for reproducible & future reference purpose only. All source code, slides or screenshot are intellactual property of respective content authors. If you find these contents beneficial, kindly consider learning subscription from [DeepLearning.AI Subscription], [Coursera], [DataCamp]\n",
    "\n",
    "\n",
    "\n",
    "[DeepLearning.AI]: https://www.deeplearning.ai\n",
    "[DeepLearning.AI Subscription]: https://www.deeplearning.ai\n",
    "[Coursera]: https://www.coursera.org\n",
    "[DataCamp]: https://www.datacamp.com\n",
    "[medium]: https://medium.com/@kamig4u\n",
    "[LinkedIn]: https://www.linkedin.com/in/asadenterprisearchitect\n",
    "[kaggle]: https://www.kaggle.com/kakamana\n",
    "[github blogs]: https://kakamana.github.io\n",
    "[github repos]: https://github.com/kakamana\n",
    "[Datacamp course: Machine Learning with PySpark]: (https://app.datacamp.com/learn/courses/machine-learning-with-pyspark)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-10T23:56:47.114365Z",
     "end_time": "2023-04-10T23:56:47.118591Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One-Hot Encoding\n",
    "## Encoding flight origin\n",
    "The org column in the flights data is a categorical variable giving the airport from which a flight departs.\n",
    "\n",
    "* ORD — O'Hare International Airport (Chicago)\n",
    "* SFO — San Francisco International Airport\n",
    "* JFK — John F Kennedy International Airport (New York)\n",
    "* LGA — La Guardia Airport (New York)\n",
    "* SMF — Sacramento\n",
    "* SJC — San Jose\n",
    "* TUS — Tucson International Airport\n",
    "* OGG — Kahului (Hawaii)\n",
    "Obviously this is only a small subset of airports. Nevertheless, since this is a categorical variable, it needs to be one-hot encoded before it can be used in a regression model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 275000 records.\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- mon: integer (nullable = true)\n",
      " |-- dom: integer (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- mile: integer (nullable = true)\n",
      " |-- depart: double (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- delay: integer (nullable = true)\n",
      "\n",
      "None\n",
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master('local[*]').appName('flights').getOrCreate()\n",
    "\n",
    "# Read data from CSV file\n",
    "flights = spark.read.csv('dataset/flights-larger.csv', sep=',', header=True, inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "\n",
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % flights.count())\n",
    "\n",
    "# View the first five records\n",
    "flights.show(5)\n",
    "\n",
    "# Check column data types\n",
    "print(flights.printSchema())\n",
    "print(flights.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-10T23:58:12.307127Z",
     "end_time": "2023-04-10T23:58:12.976268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|org_idx|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|    0.0|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|    0.0|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|    0.0|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|    2.0|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|    5.0|\n",
      "|  3| 28|  1|     B6|   377|LGA|1076| 13.33|     182|   70|    3.0|\n",
      "|  5| 28|  6|     B6|   904|ORD| 740|  9.58|     130|   47|    0.0|\n",
      "|  1| 19|  2|     UA|   820|SFO| 679| 12.75|     123|  135|    1.0|\n",
      "|  8|  5|  5|     US|  2175|LGA| 214|  13.0|      71|  -10|    3.0|\n",
      "|  5| 27|  5|     AA|  1240|ORD|1197| 14.42|     195|  -11|    0.0|\n",
      "|  8| 20|  6|     B6|   119|JFK|1182| 14.67|     198|   20|    2.0|\n",
      "|  2|  3|  1|     AA|  1881|JFK|1090| 15.92|     200|   -9|    2.0|\n",
      "|  8| 26|  5|     B6|    35|JFK|1028| 20.58|     193|  102|    2.0|\n",
      "|  4|  9|  5|     AA|   336|ORD| 733|  20.5|     125|   32|    0.0|\n",
      "|  3|  8|  2|     UA|   678|ORD| 733| 10.95|     129|   55|    0.0|\n",
      "|  8| 10|  3|     OH|  6347|LGA| 292| 11.75|     102|    8|    3.0|\n",
      "|  8| 14|  0|     UA|   624|ORD| 612| 17.92|     109|   57|    0.0|\n",
      "|  4|  8|  4|     OH|  5585|JFK| 301| 13.25|      88|   23|    2.0|\n",
      "|  1| 14|  4|     UA|  1524|SFO| 414| 14.87|      91|   27|    1.0|\n",
      "|  1|  2|  6|     AA|  1341|ORD|1846|   7.5|     275|   26|    0.0|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "flights = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights).transform(flights)\n",
    "\n",
    "flights.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-10T23:58:55.115000Z",
     "end_time": "2023-04-10T23:58:55.944351Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------+\n",
      "|org|org_idx|    org_dummy|\n",
      "+---+-------+-------------+\n",
      "|ORD|    0.0|(7,[0],[1.0])|\n",
      "|SFO|    1.0|(7,[1],[1.0])|\n",
      "|JFK|    2.0|(7,[2],[1.0])|\n",
      "|LGA|    3.0|(7,[3],[1.0])|\n",
      "|SMF|    4.0|(7,[4],[1.0])|\n",
      "|SJC|    5.0|(7,[5],[1.0])|\n",
      "|TUS|    6.0|(7,[6],[1.0])|\n",
      "|OGG|    7.0|    (7,[],[])|\n",
      "+---+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the one hot encoder class\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "# Create an instance of the one hot encoder\n",
    "onehot = OneHotEncoder(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
    "\n",
    "# Apply the one hot encoder to the flights data\n",
    "onehot = onehot.fit(flights)\n",
    "flights_onehot = onehot.transform(flights)\n",
    "\n",
    "# Check the results\n",
    "flights_onehot.select('org', 'org_idx', 'org_dummy').distinct().sort('org_idx').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:00:42.882462Z",
     "end_time": "2023-04-11T00:00:43.551351Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression\n",
    "## Flight duration model - Just distance\n",
    "In this exercise you'll build a regression model to predict flight duration (the duration column).\n",
    "\n",
    "For the moment you'll keep the model simple, including only the distance of the flight (the km column) as a predictor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+-------------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|org_idx|    org_dummy|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+-------------+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|    0.0|(7,[0],[1.0])|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|    0.0|(7,[0],[1.0])|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|    0.0|(7,[0],[1.0])|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|    2.0|(7,[2],[1.0])|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|    5.0|(7,[5],[1.0])|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_onehot.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:01:57.619502Z",
     "end_time": "2023-04-11T00:01:57.684595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|org_idx|    org_dummy|    km|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27|    0.0|(7,[0],[1.0])| 253.0|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null|    0.0|(7,[0],[1.0])| 750.0|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|    0.0|(7,[0],[1.0])|1188.0|\n",
      "|  2| 14|  5|     B6|   199|JFK| 21.17|     365|   60|    2.0|(7,[2],[1.0])|3618.0|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 12.92|      85|   22|    5.0|(7,[5],[1.0])| 621.0|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "# Convert 'mile' to 'km' and drop 'mile' column\n",
    "flights_onehot = flights_onehot.withColumn('km', round(flights_onehot.mile * 1.60934, 0)).drop('mile')\n",
    "\n",
    "flights_onehot.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:19:16.985770Z",
     "end_time": "2023-04-11T00:19:17.081133Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+--------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|org_idx|    org_dummy|    km|features|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+--------+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27|    0.0|(7,[0],[1.0])| 253.0| [253.0]|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null|    0.0|(7,[0],[1.0])| 750.0| [750.0]|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|    0.0|(7,[0],[1.0])|1188.0|[1188.0]|\n",
      "|  2| 14|  5|     B6|   199|JFK| 21.17|     365|   60|    2.0|(7,[2],[1.0])|3618.0|[3618.0]|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 12.92|      85|   22|    5.0|(7,[5],[1.0])| 621.0| [621.0]|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=['km'], outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights = assembler.transform(flights_onehot)\n",
    "\n",
    "flights.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:19:54.674255Z",
     "end_time": "2023-04-11T00:19:54.774950Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:20:50.728428Z",
     "end_time": "2023-04-11T00:20:50.737430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:21:01 WARN Instrumentation: [30b8ecc7] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/04/11 00:21:01 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "23/04/11 00:21:01 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/11 00:21:01 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:21:01 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|duration|prediction       |\n",
      "+--------+-----------------+\n",
      "|210     |222.625095554037 |\n",
      "|150     |133.6118925209612|\n",
      "|125     |133.6118925209612|\n",
      "|120     |133.6118925209612|\n",
      "|215     |188.4125379256779|\n",
      "+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "17.162736947467877"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(featuresCol='features', labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Create predictions for the test data and take a look at the predictions\n",
    "predictions = regression.transform(flights_test)\n",
    "predictions.select('duration', 'prediction').show(5, False)\n",
    "\n",
    "# Calculate the RMSE\n",
    "RegressionEvaluator(labelCol='duration', metricName='rmse').evaluate(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:21:01.014201Z",
     "end_time": "2023-04-11T00:21:03.880209Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Interpreting the coefficients\n",
    "\n",
    "![](regression-1.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.295923491174236\n",
      "[0.07569149917778555]\n",
      "0.07569149917778555\n",
      "792.6913940371419\n"
     ]
    }
   ],
   "source": [
    "inter = regression.intercept\n",
    "print(inter)\n",
    "\n",
    "# Coefficients\n",
    "coefs = regression.coefficients\n",
    "print(coefs)\n",
    "\n",
    "# Average minutes per km\n",
    "minutes_per_km = regression.coefficients[0]\n",
    "print(minutes_per_km)\n",
    "\n",
    "# Average speed in km per hour\n",
    "avg_speed = 60 / minutes_per_km\n",
    "print(avg_speed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:27:39.170443Z",
     "end_time": "2023-04-11T00:27:39.207671Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flight duration model - Adding origin airport\n",
    "Some airports are busier than others. Some airports are bigger than others too. Flights departing from large or busy airports are likely to spend more time taxiing or waiting for their takeoff slot. So it stands to reason that the duration of a flight might depend not only on the distance being covered but also the airport from which the flight departs.\n",
    "\n",
    "You are going to make the regression model a little more sophisticated by including the departure airport as a predictor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+--------------------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|org_idx|    org_dummy|    km|            features|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+--------------------+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27|    0.0|(7,[0],[1.0])| 253.0|(8,[0,1],[253.0,1...|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null|    0.0|(7,[0],[1.0])| 750.0|(8,[0,1],[750.0,1...|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|    0.0|(7,[0],[1.0])|1188.0|(8,[0,1],[1188.0,...|\n",
      "|  2| 14|  5|     B6|   199|JFK| 21.17|     365|   60|    2.0|(7,[2],[1.0])|3618.0|(8,[0,3],[3618.0,...|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 12.92|      85|   22|    5.0|(7,[5],[1.0])| 621.0|(8,[0,6],[621.0,1...|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy'], outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights = assembler.transform(flights_onehot)\n",
    "\n",
    "flights.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:29:20.412950Z",
     "end_time": "2023-04-11T00:29:20.528374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:30:13 WARN Instrumentation: [77102ecd] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "11.173083151870756"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(featuresCol='features', labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Create predictions for the test data\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on test data\n",
    "RegressionEvaluator(labelCol='duration', metricName='rmse').evaluate(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:30:13.399865Z",
     "end_time": "2023-04-11T00:30:15.514333Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Interpreting coefficients\n",
    "Remember that origin airport, org, has eight possible values (ORD, SFO, JFK, LGA, SMF, SJC, TUS and OGG) which have been one-hot encoded to seven dummy variables in org_dummy.\n",
    "\n",
    "The values for km and org_dummy have been assembled into features, which has eight columns with sparse representation. Column indices in features are as follows:\n",
    "\n",
    "* 0 — km\n",
    "* 1 — ORD\n",
    "* 2 — SFO\n",
    "* 3 — JFK\n",
    "* 4 — LGA\n",
    "* 5 — SMF\n",
    "* 6 — SJC and\n",
    "* 7 — TUS. Note that OGG does not appear in this list because it is the reference level for the origin airport category.\n",
    "\n",
    "In this exercise you'll be using the intercept and coefficients attributes to interpret the model.\n",
    "\n",
    "The coefficients attribute is a list, where the first element indicates how flight duration changes with flight distance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807.5223057447772\n",
      "16.204312999214938\n",
      "68.69309629682724\n",
      "62.82878681140498\n"
     ]
    }
   ],
   "source": [
    "avg_speed_hour = 60 / regression.coefficients[0]\n",
    "print(avg_speed_hour)\n",
    "\n",
    "# Averate minutes on ground at OGG\n",
    "inter = regression.intercept\n",
    "print(inter)\n",
    "\n",
    "# Average minutes on ground at JFK\n",
    "avg_ground_jfk= inter + regression.coefficients[3]\n",
    "print(avg_ground_jfk)\n",
    "\n",
    "# Average minutes on ground at LGA\n",
    "avg_ground_lga = inter + regression.coefficients[4]\n",
    "print(avg_ground_lga)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:33:22.462179Z",
     "end_time": "2023-04-11T00:33:22.478147Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bucketing & Engineering\n",
    "\n",
    "* Bucketing\n",
    "\n",
    "![](regression-2.png)\n",
    "\n",
    "## Bucketing departure time\n",
    "Time of day data are a challenge with regression models. They are also a great candidate for bucketing.\n",
    "\n",
    "In this lesson you will convert the flight departure times from numeric values between 0 (corresponding to \"00:00\") and 24 (corresponding to \"24:00\") to binned values. You'll then take those binned values and one-hot encode them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|depart|depart_bucket|\n",
      "+------+-------------+\n",
      "|  8.18|          2.0|\n",
      "|  15.5|          5.0|\n",
      "|  7.17|          2.0|\n",
      "| 21.17|          7.0|\n",
      "| 12.92|          4.0|\n",
      "+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------------+-------------+\n",
      "|depart|depart_bucket| depart_dummy|\n",
      "+------+-------------+-------------+\n",
      "|  8.18|          2.0|(7,[2],[1.0])|\n",
      "|  15.5|          5.0|(7,[5],[1.0])|\n",
      "|  7.17|          2.0|(7,[2],[1.0])|\n",
      "| 21.17|          7.0|    (7,[],[])|\n",
      "| 12.92|          4.0|(7,[4],[1.0])|\n",
      "+------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "# Create buckets at 3 hour intervals through the day\n",
    "buckets = Bucketizer(splits=[\n",
    "    3 * x for x in range(9)\n",
    "], inputCol='depart', outputCol='depart_bucket')\n",
    "\n",
    "# Bucket the departure times\n",
    "bucketed = buckets.transform(flights)\n",
    "bucketed.select('depart', 'depart_bucket').show(5)\n",
    "\n",
    "# Create a one-hot encoder\n",
    "onehot = OneHotEncoder(inputCols=['depart_bucket'], outputCols=['depart_dummy'])\n",
    "\n",
    "# One-hot encode the bucketed departure times\n",
    "flights_onehot = onehot.fit(bucketed).transform(bucketed)\n",
    "flights_onehot.select('depart', 'depart_bucket', 'depart_dummy').show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:36:28.928193Z",
     "end_time": "2023-04-11T00:36:29.122538Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flight duration model - Adding departure time\n",
    "In the previous exercise the departure time was bucketed and converted to dummy variables. Now you're going to include those dummy variables in a regression model for flight duration.\n",
    "\n",
    "The data are in flights. The km, org_dummy and depart_dummy columns have been assembled into features, where km is index 0, org_dummy runs from index 1 to 7 and depart_dummy from index 8 to 14."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+--------------------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|org_idx|    org_dummy|    km|depart_bucket| depart_dummy|            features|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+--------------------+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27|    0.0|(7,[0],[1.0])| 253.0|          2.0|(7,[2],[1.0])|(15,[0,1,10],[253...|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null|    0.0|(7,[0],[1.0])| 750.0|          5.0|(7,[5],[1.0])|(15,[0,1,13],[750...|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|    0.0|(7,[0],[1.0])|1188.0|          2.0|(7,[2],[1.0])|(15,[0,1,10],[118...|\n",
      "|  2| 14|  5|     B6|   199|JFK| 21.17|     365|   60|    2.0|(7,[2],[1.0])|3618.0|          7.0|    (7,[],[])|(15,[0,3],[3618.0...|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 12.92|      85|   22|    5.0|(7,[5],[1.0])| 621.0|          4.0|(7,[4],[1.0])|(15,[0,6,12],[621...|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'depart_dummy'], outputCol='features')\n",
    "\n",
    "flights = assembler.transform(flights_onehot.drop('features'))\n",
    "\n",
    "flights.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:38:51.651271Z",
     "end_time": "2023-04-11T00:38:51.766008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:40:59 WARN Instrumentation: [1af1202e] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.39466681440241\n",
      "-3.7075609618922467\n",
      "48.22234281706298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train with training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "RegressionEvaluator(labelCol='duration', metricName='rmse').evaluate(predictions)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 21:00 and 24:00\n",
    "avg_eve_ogg = regression.intercept\n",
    "print(avg_eve_ogg)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 00:00 and 03:00\n",
    "avg_night_ogg = regression.intercept + regression.coefficients[8]\n",
    "print(avg_night_ogg)\n",
    "\n",
    "# Average minutes on ground at JFK for flights departing between 00:00 and 03:00\n",
    "avg_night_jfk = regression.intercept + regression.coefficients[3] + regression.coefficients[8]\n",
    "print(avg_night_jfk)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:40:59.743792Z",
     "end_time": "2023-04-11T00:41:03.053817Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regularization\n",
    "\n",
    "* Feature Selection\n",
    "\n",
    "![](regression-3.png)\n",
    "\n",
    "## Flight duration model - More features!\n",
    "Let's add more features to our model. This will not necessarily result in a better model. Adding some features might improve the model. Adding other features might make it worse.\n",
    "\n",
    "More features will always make the model more complicated and difficult to interpret.\n",
    "\n",
    "These are the features you'll include in the next model:\n",
    "\n",
    "* km\n",
    "* org (origin airport, one-hot encoded, 8 levels)\n",
    "* depart (departure time, binned in 3 hour intervals, one-hot encoded, 8 levels)\n",
    "* dow (departure day of week, one-hot encoded, 7 levels) and\n",
    "* mon (departure month, one-hot encoded, 12 levels).\n",
    "\n",
    "These have been assembled into the features column, which is a sparse representation of 32 columns (remember one-hot encoding produces a number of columns which is one fewer than the number of levels)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+--------------------+-------------+---------------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|org_idx|    org_dummy|    km|depart_bucket| depart_dummy|            features|    dow_dummy|      mon_dummy|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+--------------------+-------------+---------------+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27|    0.0|(7,[0],[1.0])| 253.0|          2.0|(7,[2],[1.0])|(15,[0,1,10],[253...|(6,[1],[1.0])|(11,[10],[1.0])|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null|    0.0|(7,[0],[1.0])| 750.0|          5.0|(7,[5],[1.0])|(15,[0,1,13],[750...|(6,[1],[1.0])| (11,[1],[1.0])|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|    0.0|(7,[0],[1.0])|1188.0|          2.0|(7,[2],[1.0])|(15,[0,1,10],[118...|(6,[1],[1.0])|     (11,[],[])|\n",
      "|  2| 14|  5|     B6|   199|JFK| 21.17|     365|   60|    2.0|(7,[2],[1.0])|3618.0|          7.0|    (7,[],[])|(15,[0,3],[3618.0...|(6,[5],[1.0])| (11,[2],[1.0])|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 12.92|      85|   22|    5.0|(7,[5],[1.0])| 621.0|          4.0|(7,[4],[1.0])|(15,[0,6,12],[621...|(6,[3],[1.0])| (11,[5],[1.0])|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+--------------------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder(inputCols=['dow'], outputCols=['dow_dummy'])\n",
    "flights = onehot.fit(flights).transform(flights)\n",
    "\n",
    "onehot = OneHotEncoder(inputCols=['mon'], outputCols=['mon_dummy'])\n",
    "flights = onehot.fit(flights).transform(flights)\n",
    "\n",
    "flights.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:49:40.753171Z",
     "end_time": "2023-04-11T00:49:41.515450Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+-------------+---------------+--------------------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|org_idx|    org_dummy|    km|depart_bucket| depart_dummy|    dow_dummy|      mon_dummy|            features|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+-------------+---------------+--------------------+\n",
      "| 10| 10|  1|     OO|  5836|ORD|  8.18|      51|   27|    0.0|(7,[0],[1.0])| 253.0|          2.0|(7,[2],[1.0])|(6,[1],[1.0])|(11,[10],[1.0])|(32,[0,1,10,16,31...|\n",
      "|  1|  4|  1|     OO|  5866|ORD|  15.5|     102| null|    0.0|(7,[0],[1.0])| 750.0|          5.0|(7,[5],[1.0])|(6,[1],[1.0])| (11,[1],[1.0])|(32,[0,1,13,16,22...|\n",
      "| 11| 22|  1|     OO|  6016|ORD|  7.17|     127|  -19|    0.0|(7,[0],[1.0])|1188.0|          2.0|(7,[2],[1.0])|(6,[1],[1.0])|     (11,[],[])|(32,[0,1,10,16],[...|\n",
      "|  2| 14|  5|     B6|   199|JFK| 21.17|     365|   60|    2.0|(7,[2],[1.0])|3618.0|          7.0|    (7,[],[])|(6,[5],[1.0])| (11,[2],[1.0])|(32,[0,3,20,23],[...|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 12.92|      85|   22|    5.0|(7,[5],[1.0])| 621.0|          4.0|(7,[4],[1.0])|(6,[3],[1.0])| (11,[5],[1.0])|(32,[0,6,12,18,26...|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+-------------+------+-------------+-------------+-------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=[\n",
    "    'km', 'org_dummy', 'depart_dummy', 'dow_dummy', 'mon_dummy'\n",
    "], outputCol='features')\n",
    "\n",
    "flights = assembler.transform(flights.drop('features'))\n",
    "flights.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:50:07.408492Z",
     "end_time": "2023-04-11T00:50:07.510206Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/11 00:50:57 WARN Instrumentation: [80c1b164] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 10.724190288776182\n",
      "[0.07439617054843561,27.145340646967067,20.000499394192136,52.01213638788842,46.080034158347246,15.143439944331867,17.332120108676925,17.380424266350847,-14.90401554203675,-0.19040688562203764,3.993555504344593,7.026619199266888,4.769865793438894,8.882711940858849,8.951419052412321,-0.0918176307653956,-0.17177103162039656,-0.15924171886157698,-0.09247573867539892,-0.060677744022317515,-0.07752584272351075,-1.837930733439899,-1.8292147413424755,-2.036520611335749,-3.4324149024765247,-4.029267456901507,-3.8997326499213996,-3.9006869384654714,-3.9574770581976257,-3.856452567341345,-2.561223621449253,-0.38910636975803964]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Fit linear regressino model to training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on test data\n",
    "rmse = RegressionEvaluator(labelCol='duration', metricName='rmse').evaluate(predictions)\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:50:56.926787Z",
     "end_time": "2023-04-11T00:50:59.393683Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flight duration model - Regularization!\n",
    "In the previous exercise you added more predictors to the flight duration model. The model performed well on testing data, but with so many coefficients it was difficult to interpret.\n",
    "\n",
    "In this exercise you'll use Lasso regression (regularized with a L1 penalty) to create a more parsimonious model. Many of the coefficients in the resulting model will be set to zero. This means that only a subset of the predictors actually contribute to the model. Despite the simpler model, it still produces a good RMSE on the testing data.\n",
    "\n",
    "You'll use a specific value for the regularization strength. Later you'll learn how to find the best value using cross validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 11.6641081367996\n",
      "[0.07355344999669398,5.461850683527292,0.0,29.27697009874167,22.319695077148175,-2.1193281045010792,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.1042606455043114,1.2941633500663998,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
      "Number of coefficients equal to 0: 25\n"
     ]
    }
   ],
   "source": [
    "regression = LinearRegression(labelCol='duration', regParam=1, elasticNetParam=1).fit(flights_train)\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "rmse = RegressionEvaluator(labelCol='duration', metricName='rmse').evaluate(predictions)\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)\n",
    "\n",
    "# Number of zero coefficients\n",
    "zero_coeff = sum([beta == 0 for beta in regression.coefficients])\n",
    "print(\"Number of coefficients equal to 0:\", zero_coeff)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T00:53:10.619117Z",
     "end_time": "2023-04-11T00:53:12.697925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
