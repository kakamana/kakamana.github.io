{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Feature Engineering - Kaggle competition\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "author: \"kakamana\"\n",
    "date: \"2023-04-14\"\n",
    "categories: [python, datacamp, machine learning, deep learning]\n",
    "image: \"feature-1.png\"\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering\n",
    "\n",
    "As part of PySpark, cutting-edge machine learning routines are included, as well as utilities that can be used to create full machine learning pipelines. In this chapter, you will learn more about them.\n",
    "\n",
    "This **Feature Engineering** is part of [Datacamp course: Winning a Kaggle Competition in Python] This course will now have the opportunity to learn about different types of features. In this project, you will modify existing features and create new ones. In addition, you will take appropriate measures to address the missing data.\n",
    "\n",
    "This is my learning experience of data science through DataCamp. These repository contributions are part of my learning journey through my graduate program masters of applied data sciences (MADS) at University Of Michigan, [DeepLearning.AI], [Coursera] & [DataCamp]. You can find my similar articles & more stories at my [medium] & [LinkedIn] profile. I am available at [kaggle] & [github blogs] & [github repos]. Thank you for your motivation, support & valuable feedback.\n",
    "\n",
    "These include projects, coursework & notebook which I learned through my data science journey. They are created for reproducible & future reference purpose only. All source code, slides or screenshot are intellactual property of respective content authors. If you find these contents beneficial, kindly consider learning subscription from [DeepLearning.AI Subscription], [Coursera], [DataCamp]\n",
    "\n",
    "\n",
    "\n",
    "[DeepLearning.AI]: https://www.deeplearning.ai\n",
    "[DeepLearning.AI Subscription]: https://www.deeplearning.ai\n",
    "[Coursera]: https://www.coursera.org\n",
    "[DataCamp]: https://www.datacamp.com\n",
    "[medium]: https://medium.com/@kamig4u\n",
    "[LinkedIn]: https://www.linkedin.com/in/asadenterprisearchitect\n",
    "[kaggle]: https://www.kaggle.com/kakamana\n",
    "[github blogs]: https://kakamana.github.io\n",
    "[github repos]: https://github.com/kakamana\n",
    "[Datacamp course: Winning a Kaggle Competition in Python]: (https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (10, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:17:43.010427Z",
     "end_time": "2023-04-14T19:17:43.909939Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering\n",
    "\n",
    "![](feature-1.png)\n",
    "\n",
    "* Feature types\n",
    "* Numerical\n",
    "* Categorical\n",
    "* Datetime\n",
    "* Coordinates\n",
    "* Text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arithmetical features\n",
    "\n",
    "To practice creating new features, you will be working with a subsample from the Kaggle competition called \"House Prices: Advanced Regression Techniques\". The goal of this competition is to predict the price of the house based on its properties. It's a regression problem with Root Mean Squared Error as an evaluation metric.\n",
    "\n",
    "Your goal is to create new features and determine whether they improve your validation score. To get the validation score from 5-fold cross-validation, you're given the get_kfold_rmse() function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE before feature engineering: 36029.39\n",
      "RMSE with total area: 35073.2\n",
      "RMSE with garden area: 34413.55\n",
      "RMSE with number of bathromms: 34506.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "def get_kfold_rmse(train):\n",
    "    mse_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        train = train.fillna(0)\n",
    "        feats = [x for x in train.columns if x not in ['Id', 'SalePrice', 'RoofStyle', 'CentralAir']]\n",
    "\n",
    "        fold_train, fold_test = train.loc[train_index], train.loc[test_index]\n",
    "\n",
    "        # Fit the data and make predictions\n",
    "        # Create a Random Forest object\n",
    "        rf = RandomForestRegressor(n_estimators=10, min_samples_split=10, random_state=123)\n",
    "\n",
    "        # Train a model\n",
    "        rf.fit(X=fold_train[feats], y=fold_train['SalePrice'])\n",
    "\n",
    "        # Get predictions for the test set\n",
    "        pred = rf.predict(fold_test[feats])\n",
    "\n",
    "        fold_score = mean_squared_error(fold_test['SalePrice'], pred)\n",
    "        mse_scores.append(np.sqrt(fold_score))\n",
    "\n",
    "    return round(np.mean(mse_scores) + np.std(mse_scores), 2)\n",
    "train = pd.read_csv('dataset/house_prices_train.csv')\n",
    "test = pd.read_csv('dataset/house_prices_test.csv')\n",
    "print('RMSE before feature engineering:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the total area of the house\n",
    "train['totalArea'] = train['TotalBsmtSF'] + train['1stFlrSF'] + train['2ndFlrSF']\n",
    "\n",
    "# Look at the updated RMSE\n",
    "print('RMSE with total area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the area of the garden\n",
    "train['GardenArea'] = train['LotArea'] - train['1stFlrSF']\n",
    "print('RMSE with garden area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find total number of bathrooms\n",
    "train['TotalBath'] = train['FullBath'] + train['HalfBath']\n",
    "print('RMSE with number of bathromms:', get_kfold_rmse(train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:21:04.494425Z",
     "end_time": "2023-04-14T19:21:05.848589Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Date features\n",
    "\n",
    "You've built some basic features using numerical variables. Now, it's time to create features based on date and time. You will practice on a subsample from the Taxi Fare Prediction Kaggle competition data. The data represents information about the taxi rides and the goal is to predict the price for each ride.\n",
    "\n",
    "Your objective is to generate date features from the pickup datetime. Recall that it's better to create new features for train and test data simultaneously. After the features are created, split the data back into the train and test DataFrames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/taxi_train_chapter_4.csv')\n",
    "test = pd.read_csv('dataset/taxi_test_chapter_4.csv')\n",
    "taxi = pd.concat([train, test])\n",
    "\n",
    "# Convert pickup date to datetime object\n",
    "taxi['pickup_datetime'] = pd.to_datetime(taxi['pickup_datetime'])\n",
    "\n",
    "# Create a day of week feature\n",
    "taxi['dayofweek'] = taxi['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "# Create an hour feature\n",
    "taxi['hour'] = taxi['pickup_datetime'].dt.hour\n",
    "\n",
    "# Split back into train and test\n",
    "new_train = taxi[taxi['id'].isin(train['id'])]\n",
    "new_test = taxi[taxi['id'].isin(test['id'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:26:54.756073Z",
     "end_time": "2023-04-14T19:26:55.856759Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Categorical features\n",
    "\n",
    "## Label encoding\n",
    "\n",
    "Let's work on categorical variables encoding. You will again work with a subsample from the House Prices Kaggle competition.\n",
    "\n",
    "Your objective is to encode categorical features \"RoofStyle\" and \"CentralAir\" using label encoding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RoofStyle  RoofStyle_enc CentralAir  CentralAir_enc\n",
      "0     Gable              1          Y               1\n",
      "1     Gable              1          Y               1\n",
      "2     Gable              1          Y               1\n",
      "3     Gable              1          Y               1\n",
      "4     Gable              1          Y               1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train = pd.read_csv('dataset/house_prices_train.csv')\n",
    "test = pd.read_csv('dataset/house_prices_test.csv')\n",
    "\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Create new features\n",
    "houses['RoofStyle_enc'] = le.fit_transform(houses['RoofStyle'])\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "\n",
    "# Look at new features\n",
    "print(houses[['RoofStyle', 'RoofStyle_enc', 'CentralAir', 'CentralAir_enc']].head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:30:51.493946Z",
     "end_time": "2023-04-14T19:30:51.504082Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-Hot encoding\n",
    "\n",
    "The problem with label encoding is that it implicitly assumes that there is a ranking dependency between the categories. So, let's change the encoding method for the features \"RoofStyle\" and \"CentralAir\" to one-hot encoding. Again, the train and test DataFrames from House Prices Kaggle competition are already available in your workspace.\n",
    "\n",
    "Recall that if you're dealing with binary features (categorical features with only two categories) it is suggested to apply label encoder only.\n",
    "\n",
    "Your goal is to determine which of the mentioned features is not binary, and to apply one-hot encoding only to this one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gable      2310\n",
      "Hip         551\n",
      "Gambrel      22\n",
      "Flat         20\n",
      "Mansard      11\n",
      "Shed          5\n",
      "Name: RoofStyle, dtype: int64 \n",
      "\n",
      "Y    2723\n",
      "N     196\n",
      "Name: CentralAir, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Look at feature distributions\n",
    "print(houses['RoofStyle'].value_counts(), '\\n')\n",
    "print(houses['CentralAir'].value_counts())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:32:15.075420Z",
     "end_time": "2023-04-14T19:32:15.080126Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RoofStyle  RoofStyle_Flat  RoofStyle_Gable  RoofStyle_Gambrel  \\\n",
      "0     Gable               0                1                  0   \n",
      "1     Gable               0                1                  0   \n",
      "2     Gable               0                1                  0   \n",
      "3     Gable               0                1                  0   \n",
      "4     Gable               0                1                  0   \n",
      "\n",
      "   RoofStyle_Hip  RoofStyle_Mansard  RoofStyle_Shed  \n",
      "0              0                  0               0  \n",
      "1              0                  0               0  \n",
      "2              0                  0               0  \n",
      "3              0                  0               0  \n",
      "4              0                  0               0  \n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "\n",
    "# Create One-Hot encoded features\n",
    "ohe = pd.get_dummies(houses['RoofStyle'], prefix='RoofStyle')\n",
    "\n",
    "# Concatenate OHE features to houses\n",
    "houses = pd.concat([houses, ohe], axis=1)\n",
    "\n",
    "# Look at OHE features\n",
    "print(houses[[col for col in houses.columns if 'RoofStyle' in col]].head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:33:52.172465Z",
     "end_time": "2023-04-14T19:33:52.184544Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Target Encoding\n",
    "\n",
    "* Mean target encoding\n",
    "    1. Calculate mean on the train, apply to the test\n",
    "    2. Split train into K folds, Calculate mean on (K-1) folds, apply to the K-th fold\n",
    "    3. Add mean target encoded feature to the model\n",
    "\n",
    "## Mean target encoding\n",
    "\n",
    "First of all, you will create a function that implements mean target encoding. Remember that you need to develop the two following steps:\n",
    "\n",
    "    1. Calculate the mean on the train, apply to the test\n",
    "    2. Split train into K folds. Calculate the out-of-fold mean for each fold, apply to this particular fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def test_mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "    # Calculate global mean on the train data\n",
    "    global_mean = train[target].mean()\n",
    "\n",
    "    # Group by the categorical feature and calculate its properties\n",
    "    train_groups = train.groupby(categorical)\n",
    "    category_sum = train_groups[target].sum()\n",
    "    category_size = train_groups.size()\n",
    "\n",
    "    # Calculate smoothed mean target statistics\n",
    "    train_statistics = (category_sum + global_mean * alpha) / (category_size + alpha)\n",
    "\n",
    "    # Apply statistics to the test data and fill new categories\n",
    "    test_feature = test[categorical].map(train_statistics).fillna(global_mean)\n",
    "    return test_feature.values\n",
    "\n",
    "def train_mean_target_encoding(train, target, categorical, alpha=5):\n",
    "    # Create 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5,random_state=123, shuffle=True)\n",
    "    train_feature = pd.Series(index=train.index, dtype='float')\n",
    "\n",
    "    # For each folds split\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "\n",
    "        # Calculate out-of-fold statistics and apply to cv_test\n",
    "        cv_test_feature = test_mean_target_encoding(cv_train, cv_test, target,\n",
    "                                                    categorical, alpha)\n",
    "\n",
    "        # Save new feature for this particular fold\n",
    "        train_feature.iloc[test_index] = cv_test_feature\n",
    "    return train_feature.values\n",
    "\n",
    "def mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "    # Get the train feature\n",
    "    train_feature = train_mean_target_encoding(train, target, categorical, alpha)\n",
    "\n",
    "    # Get the test feature\n",
    "    test_feature = test_mean_target_encoding(train, test, target, categorical, alpha)\n",
    "\n",
    "    # Return new features to add to the model\n",
    "    return train_feature, test_feature"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:39:53.531889Z",
     "end_time": "2023-04-14T19:39:53.547625Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-fold cross-validation\n",
    "\n",
    "You will work with a binary classification problem on a subsample from Kaggle playground competition. The objective of this competition is to predict whether a famous basketball player Kobe Bryant scored a basket or missed a particular shot."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       game_id  shot_made_flag  game_id_enc\n",
      "4001  20201028             1.0     0.485444\n",
      "       game_id  shot_made_flag  game_id_enc\n",
      "8083  20501196             1.0     0.360977\n",
      "      game_id  shot_made_flag  game_id_enc\n",
      "399  20000280             1.0     0.327464\n",
      "       game_id  shot_made_flag  game_id_enc\n",
      "5998  20400903             1.0     0.661384\n",
      "       game_id  shot_made_flag  game_id_enc\n",
      "2606  20101164             1.0     0.295526\n"
     ]
    }
   ],
   "source": [
    "bryant_shots = pd.read_csv('dataset/bryant_shots.csv')\n",
    "\n",
    "# Create 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# For each folds split\n",
    "for train_index, test_index in kf.split(bryant_shots):\n",
    "    cv_train, cv_test = bryant_shots.iloc[train_index].copy(), bryant_shots.iloc[test_index].copy()\n",
    "\n",
    "    # Create mean target encoded feature\n",
    "    cv_train['game_id_enc'], cv_test['game_id_enc'] = mean_target_encoding(train=cv_train,\n",
    "                                                                           test=cv_test,\n",
    "                                                                           target='shot_made_flag',\n",
    "                                                                           categorical='game_id',\n",
    "                                                                           alpha=5)\n",
    "\n",
    "    # Look at the encoding\n",
    "    print(cv_train[['game_id', 'shot_made_flag', 'game_id_enc']].sample(n=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:40:57.684175Z",
     "end_time": "2023-04-14T19:40:57.733818Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Beyond binary classification\n",
    "\n",
    "Of course, binary classification is just a single special case. Target encoding could be applied to any target variable type:\n",
    "\n",
    "    * For binary classification usually mean target encoding is used\n",
    "    * For regression mean could be changed to median, quartiles, etc.\n",
    "    * For multi-class classification with N classes we create N features with target mean for each category in one vs. all fashion The mean_target_encoding() function you've created could be used for any target type specified above. Let's apply it for the regression problem on the example of House Prices Kaggle competition.\n",
    "Your goal is to encode a categorical feature \"RoofStyle\" using mean target encoding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "     RoofStyle  RoofStyle_enc\n0        Gable  171565.947836\n1          Hip  217594.645131\n98     Gambrel  164152.950424\n133       Flat  188703.563431\n362    Mansard  180775.938759\n1053      Shed  188267.663242",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RoofStyle</th>\n      <th>RoofStyle_enc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gable</td>\n      <td>171565.947836</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hip</td>\n      <td>217594.645131</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Gambrel</td>\n      <td>164152.950424</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>Flat</td>\n      <td>188703.563431</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>Mansard</td>\n      <td>180775.938759</td>\n    </tr>\n    <tr>\n      <th>1053</th>\n      <td>Shed</td>\n      <td>188267.663242</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dataset/house_prices_train.csv')\n",
    "test = pd.read_csv('dataset/house_prices_test.csv')\n",
    "\n",
    "# Create mean target encoded feature\n",
    "train['RoofStyle_enc'], test['RoofStyle_enc'] = mean_target_encoding(train=train,\n",
    "                                                                     test=test,\n",
    "                                                                     target='SalePrice',\n",
    "                                                                     categorical='RoofStyle',\n",
    "                                                                     alpha=10)\n",
    "# Look at the encoding\n",
    "test[['RoofStyle', 'RoofStyle_enc']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:43:15.354010Z",
     "end_time": "2023-04-14T19:43:15.369776Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Missing Data\n",
    "\n",
    "* Impute missing data\n",
    "    * Numerical data\n",
    "        * Mean/median imputation\n",
    "        * Constant value imputation\n",
    "    * Categorical data\n",
    "        * Most frequent category imputation\n",
    "        * New category imputation\n",
    "\n",
    "## Find missing data\n",
    "\n",
    "Let's impute missing data on a real Kaggle dataset. For this purpose, you will be using a data subsample from the Kaggle \"Two sigma connect: rental listing inquiries\" competition.\n",
    "\n",
    "Before proceeding with any imputing you need to know the number of missing values for each of the features. Moreover, if the feature has missing values, you should explore the type of this feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                 0\n",
      "bathrooms          0\n",
      "bedrooms           0\n",
      "building_id       13\n",
      "latitude           0\n",
      "longitude          0\n",
      "manager_id         0\n",
      "price             32\n",
      "interest_level     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "                        building_id   price\n0  53a5b119ba8f7b61d4e010512e0dfc85  3000.0\n1  c5c8a357cba207596b04d1afd1e4f130  5465.0\n2  c3ba40552e2120b0acfc3cb5730bb2aa  2850.0\n3  28d9ad350afeaab8027513a3e52ac8d5  3275.0\n4                               NaN  3350.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>building_id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n      <td>3000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n      <td>5465.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c3ba40552e2120b0acfc3cb5730bb2aa</td>\n      <td>2850.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28d9ad350afeaab8027513a3e52ac8d5</td>\n      <td>3275.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>3350.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twosigma = pd.read_csv('dataset/twosigma_rental_train_null.csv')\n",
    "\n",
    "# find the number of missing values in each column\n",
    "print(twosigma.isnull().sum())\n",
    "\n",
    "twosigma[['building_id', 'price']].head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:45:41.981778Z",
     "end_time": "2023-04-14T19:45:42.002608Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impute missing data\n",
    "\n",
    "You've found that \"price\" and \"building_id\" columns have missing values in the Rental Listing Inquiries dataset. So, before passing the data to the models you need to impute these values.\n",
    "\n",
    "Numerical feature \"price\" will be encoded with a mean value of non-missing prices.\n",
    "\n",
    "Imputing categorical feature \"building_id\" with the most frequent category is a bad idea, because it would mean that all the apartments with a missing \"building_id\" are located in the most popular building. The better idea is to impute it with a new category."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "id                0\nbathrooms         0\nbedrooms          0\nbuilding_id       0\nlatitude          0\nlongitude         0\nmanager_id        0\nprice             0\ninterest_level    0\ndtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create mean imputer\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Price imputation\n",
    "twosigma[['price']] = mean_imputer.fit_transform(twosigma[['price']])\n",
    "\n",
    "# Create constant inputer\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value='MISSING')\n",
    "\n",
    "# building_id imputation\n",
    "twosigma[['building_id']] = constant_imputer.fit_transform(twosigma[['building_id']])\n",
    "twosigma.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:48:38.020527Z",
     "end_time": "2023-04-14T19:48:38.034752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
