{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Cross validation in modeling\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "author: \"kakamana\"\n",
    "date: \"2023-03-22\"\n",
    "categories: [python, datacamp, machine learning, models]\n",
    "image: \"crossValidation-1.png\"\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Validation\n",
    "\n",
    "Holdout sets are an excellent starting point for model validation. It is important to note, however, that using one train and one test set is often not sufficient. When tuning model hyperparameters, cross-validation is considered the gold standard for validating model performance. The purpose of this chapter is to demonstrate how to perform cross-validation in order to validate the performance of a model.\n",
    "\n",
    "This **Cross Validation** is part of [Datacamp course: Model Validation in Python] which describe about model validation as t has never been easier to implement machine learning models than it is today. The results of running new data through a model may not be as accurate as expected without proper validation. Validation of models allows analysts to answer confidently the question, \"How good is your model?\". This question will be addressed for classification models using the complete set of tic-tac-toe endgame scenarios, and for regression models using fivethirtyeight's ultimate Halloween candy power ranking dataset. The purpose of this course is to introduce the basics of model validation, to discuss various validation techniques, and to begin to develop tools for creating high-performance and validated models.\n",
    "\n",
    "This is my learning experience of data science through DataCamp. These repository contributions are part of my learning journey through my graduate program masters of applied data sciences (MADS) at University Of Michigan, [DeepLearning.AI], [Coursera] & [DataCamp]. You can find my similar articles & more stories at my [medium] & [LinkedIn] profile. I am available at [kaggle] & [github blogs] & [github repos]. Thank you for your motivation, support & valuable feedback.\n",
    "\n",
    "These include projects, coursework & notebook which I learned through my data science journey. They are created for reproducible & future reference purpose only. All source code, slides or screenshot are intellactual property of respective content authors. If you find these contents beneficial, kindly consider learning subscription from [DeepLearning.AI Subscription], [Coursera], [DataCamp]\n",
    "\n",
    "\n",
    "\n",
    "[DeepLearning.AI]: https://www.deeplearning.ai\n",
    "[DeepLearning.AI Subscription]: https://www.deeplearning.ai\n",
    "[Coursera]: https://www.coursera.org\n",
    "[DataCamp]: https://www.datacamp.com\n",
    "[medium]: https://medium.com/@kamig4u\n",
    "[LinkedIn]: https://www.linkedin.com/in/asadenterprisearchitect\n",
    "[kaggle]: https://www.kaggle.com/kakamana\n",
    "[github blogs]: https://kakamana.github.io\n",
    "[github repos]: https://github.com/kakamana\n",
    "[Datacamp course: Model Validation in Python]: (https://app.datacamp.com/learn/courses/model-validation-in-python)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The problems with holdout sets\n",
    "## Two samples\n",
    "\n",
    "After building several classification models based on the tic_tac_toe dataset, you realize that some models do not generalize as well as others. You have created training and testing splits just as you have been taught, so you are curious why your validation process is not working.\n",
    "\n",
    "After trying a different training, test split, you noticed differing accuracies for your machine learning model. Before getting too frustrated with the varying results, you have decided to see what else could be going on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n0        x          x         x           x             o            o   \n1        x          x         x           x             o            o   \n2        x          x         x           x             o            o   \n3        x          x         x           x             o            o   \n4        x          x         x           x             o            o   \n\n  Bottom-Left Bottom-Middle Bottom-Right     Class  \n0           x             o            o  positive  \n1           o             x            o  positive  \n2           o             o            x  positive  \n3           o             b            b  positive  \n4           b             o            b  positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Top-Left</th>\n      <th>Top-Middle</th>\n      <th>Top-Right</th>\n      <th>Middle-Left</th>\n      <th>Middle-Middle</th>\n      <th>Middle-Right</th>\n      <th>Bottom-Left</th>\n      <th>Bottom-Middle</th>\n      <th>Bottom-Right</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>o</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>b</td>\n      <td>b</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>b</td>\n      <td>o</td>\n      <td>b</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_tac_toe = pd.read_csv('dataset/tic-tac-toe.csv')\n",
    "tic_tac_toe.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Create two different samples of 200 observations\n",
    "sample1 = tic_tac_toe.sample(200, random_state=1111)\n",
    "sample2 = tic_tac_toe.sample(200, random_state=1171)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# Print the number of common observations\n",
    "print(len([index for index in sample1.index if index in sample2.index]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    134\n",
      "negative     66\n",
      "Name: Class, dtype: int64\n",
      "positive    123\n",
      "negative     77\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Notice that there are a varying number of positive observations for both sample test sets. Sometimes creating a single test holdout sample is not enough to achieve the high levels of model validation you want. You need to use something more robust.\n"
     ]
    }
   ],
   "source": [
    "# Print the number of observations in the Class column for both samples\n",
    "print(sample1['Class'].value_counts())\n",
    "print(sample2['Class'].value_counts())\n",
    "print(\"\\nNotice that there are a varying number of positive observations for both sample test sets. Sometimes creating a single test holdout sample is not enough to achieve the high levels of model validation you want. You need to use something more robust.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## scikit-learn's KFold()\n",
    "\n",
    "You just finished running a colleagues code that creates a random forest model and calculates an out-of-sample accuracy. You noticed that your colleague's code did not have a random state, and the errors you found were completely different than the errors your colleague reported.\n",
    "\n",
    "To get a better estimate for how accurate this random forest model will be on new data, you have decided to generate some indices to use for KFold cross-validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n0      100 Grand          1       0        1               0       0   \n1   3 Musketeers          1       0        0               0       1   \n2       One dime          0       0        0               0       0   \n3    One quarter          0       0        0               0       0   \n4      Air Heads          0       1        0               0       0   \n\n   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n0                 1     0    1         0         0.732         0.860   \n1                 0     0    1         0         0.604         0.511   \n2                 0     0    0         0         0.011         0.116   \n3                 0     0    0         0         0.011         0.511   \n4                 0     0    0         0         0.906         0.511   \n\n   winpercent  \n0   66.971725  \n1   67.602936  \n2   32.261086  \n3   46.116505  \n4   52.341465  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>competitorname</th>\n      <th>chocolate</th>\n      <th>fruity</th>\n      <th>caramel</th>\n      <th>peanutyalmondy</th>\n      <th>nougat</th>\n      <th>crispedricewafer</th>\n      <th>hard</th>\n      <th>bar</th>\n      <th>pluribus</th>\n      <th>sugarpercent</th>\n      <th>pricepercent</th>\n      <th>winpercent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100 Grand</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.732</td>\n      <td>0.860</td>\n      <td>66.971725</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3 Musketeers</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.604</td>\n      <td>0.511</td>\n      <td>67.602936</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One dime</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.011</td>\n      <td>0.116</td>\n      <td>32.261086</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>One quarter</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.011</td>\n      <td>0.511</td>\n      <td>46.116505</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Air Heads</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.906</td>\n      <td>0.511</td>\n      <td>52.341465</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy = pd.read_csv('dataset/candy-data.csv')\n",
    "candy.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X = candy.drop(['competitorname', 'winpercent'], axis=1).to_numpy()\n",
    "y = candy['winpercent'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "\n",
      "This dataset has 85 rows. You have created five splits - each containing 68 training and 17 validation indices. You can use these indices to complete 5-fold cross-validation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Use KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
    "\n",
    "# Create splits\n",
    "splits = kf.split(X)\n",
    "\n",
    "# Print the number of indices\n",
    "for train_index, val_index in splits:\n",
    "    print(\"Number of training indices: %s\" % len(train_index))\n",
    "    print(\"Number of validation indices: %s\" % len(val_index))\n",
    "\n",
    "print(\"\\nThis dataset has 85 rows. You have created five splits - each containing 68 training and 17 validation indices. You can use these indices to complete 5-fold cross-validation.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using KFold indices\n",
    "\n",
    "You have already created splits, which contains indices for the candy-data dataset to complete 5-fold cross-validation. To get a better estimate for how well a colleague's random forest model will perform on a new data, you want to run this model on the five different training and validation indices you just created."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object _BaseKFold.split at 0x0000023AF545D190>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = kf.split(X)\n",
    "splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split accuracy: 150.99298148707666\n",
      "Split accuracy: 171.22206240542593\n",
      "Split accuracy: 131.72569156195593\n",
      "Split accuracy: 80.61940183841385\n",
      "Split accuracy: 221.63020627476214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "\n",
    "# Access the training and validation indices of splits\n",
    "for train_index, val_index in splits:\n",
    "    # Setup the training and validation data\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "    # Fit the random forest model\n",
    "    rfc.fit(X_train, y_train)\n",
    "    # Make predictions, and print the accuracy\n",
    "    predictions = rfc.predict(X_val)\n",
    "    print(\"Split accuracy: \" + str(mean_squared_error(y_val, predictions)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KFold() is a great method for accessing individual indices when completing cross-validation. One drawback is needing a for loop to work through the indices though. In the next lesson, you will look at an automated method for cross-validation using sklearn.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKFold() is a great method for accessing individual indices when completing cross-validation. One drawback is needing a for loop to work through the indices though. In the next lesson, you will look at an automated method for cross-validation using sklearn.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## scikit-learn's methods\n",
    "\n",
    "You have decided to build a regression model to predict the number of new employees your company will successfully hire next month. You open up a new Python script to get started, but you quickly realize that sklearn has a lot of different modules. Let's make sure you understand the names of the modules, the methods, and which module contains which method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mplement cross_val_score()\n",
    "\n",
    "Your company has created several new candies to sell, but they are not sure if they should release all five of them. To predict the popularity of these new candies, you have been asked to build a regression model using the candy dataset. Remember that the response value is a head-to-head win-percentage against other candies.\n",
    "\n",
    "Before you begin trying different regression models, you have decided to run cross-validation on a simple random forest model to get a baseline error to compare with any future results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.30323056938693\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Set up cross_val_score\n",
    "cv = cross_val_score(estimator=rfc,\n",
    "                     X=X_train,\n",
    "                     y=y_train,\n",
    "                     cv=10,\n",
    "                     scoring=mse)\n",
    "\n",
    "# Print the mean error\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " You now have a baseline score to build on. If you decide to build additional models or try new techniques, you should try to get an error lower than 155.56. Lower errors indicate that your popularity predictions are improving.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n You now have a baseline score to build on. If you decide to build additional models or try new techniques, you should try to get an error lower than 155.56. Lower errors indicate that your popularity predictions are improving.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Leave-one-out-cross-validation (LOOCV)\n",
    "\n",
    "![](crossValidation-1.png)\n",
    "\n",
    "When to use LOOCV?\n",
    "\n",
    "    The amount of training data is limited\n",
    "    You want the absolute best error estimate for new data\n",
    "\n",
    "Be cautious when:\n",
    "\n",
    "    Computation resources are limited\n",
    "    You have a lot of data\n",
    "    You have a lot of parameters to test\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's assume your favorite candy is not in the candy dataset, and that you are interested in the popularity of this candy. Using 5-fold cross-validation will train on only 80% of the data at a time. The candy dataset only has 85 rows though, and leaving out 20% of the data could hinder our model. However, using leave-one-out-cross-validation allows us to make the most out of our limited dataset and will give you the best estimate for your favorite candy's popularity!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the errors is: 9.52044832324183.\n",
      "The standard deviation of the errors is: 7.349020637882744.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "# Create scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=15, random_state=1111)\n",
    "\n",
    "# Implement LOOCV\n",
    "scores = cross_val_score(rfr, X=X, y=y, cv=85, scoring=mae_scorer)\n",
    "\n",
    "# Print the mean and standard deviation\n",
    "print(\"The mean of the errors is: %s.\" % np.mean(scores))\n",
    "print(\"The standard deviation of the errors is: %s.\" % np.std(scores))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
