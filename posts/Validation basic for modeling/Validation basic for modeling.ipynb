{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Validation basic for modeling\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "author: \"kakamana\"\n",
    "date: \"2023-03-22\"\n",
    "categories: [python, datacamp, machine learning, models]\n",
    "image: \"validationBasic.png\"\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation Basics\n",
    "\n",
    "In this section, we will focus on the basics of model validation. To build the foundation for the techniques of K-Fold and Leave-One-Out validation practiced in chapter three, we split the data into training, validation, and testing datasets, as well as develop an understanding of the bias-variance tradeoff.\n",
    "\n",
    "This **Validation Basics** is part of [Datacamp course: Model Validation in Python] which describe about model validation as t has never been easier to implement machine learning models than it is today. The results of running new data through a model may not be as accurate as expected without proper validation. Validation of models allows analysts to answer confidently the question, \"How good is your model?\". This question will be addressed for classification models using the complete set of tic-tac-toe endgame scenarios, and for regression models using fivethirtyeight's ultimate Halloween candy power ranking dataset. The purpose of this course is to introduce the basics of model validation, to discuss various validation techniques, and to begin to develop tools for creating high-performance and validated models.\n",
    "\n",
    "This is my learning experience of data science through DataCamp. These repository contributions are part of my learning journey through my graduate program masters of applied data sciences (MADS) at University Of Michigan, [DeepLearning.AI], [Coursera] & [DataCamp]. You can find my similar articles & more stories at my [medium] & [LinkedIn] profile. I am available at [kaggle] & [github blogs] & [github repos]. Thank you for your motivation, support & valuable feedback.\n",
    "\n",
    "These include projects, coursework & notebook which I learned through my data science journey. They are created for reproducible & future reference purpose only. All source code, slides or screenshot are intellactual property of respective content authors. If you find these contents beneficial, kindly consider learning subscription from [DeepLearning.AI Subscription], [Coursera], [DataCamp]\n",
    "\n",
    "\n",
    "\n",
    "[DeepLearning.AI]: https://www.deeplearning.ai\n",
    "[DeepLearning.AI Subscription]: https://www.deeplearning.ai\n",
    "[Coursera]: https://www.coursera.org\n",
    "[DataCamp]: https://www.datacamp.com\n",
    "[medium]: https://medium.com/@kamig4u\n",
    "[LinkedIn]: https://www.linkedin.com/in/asadenterprisearchitect\n",
    "[kaggle]: https://www.kaggle.com/kakamana\n",
    "[github blogs]: https://kakamana.github.io\n",
    "[github repos]: https://github.com/kakamana\n",
    "[Datacamp course: Model Validation in Python]: (https://app.datacamp.com/learn/courses/model-validation-in-python)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating train,test, and validation datasets\n",
    "\n",
    "    Traditional train/test split\n",
    "        Seen data (used for training)\n",
    "        Unseen data (unavailable for training)\n",
    "\n",
    "![](validation-1.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create one holdout set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n0        x          x         x           x             o            o   \n1        x          x         x           x             o            o   \n2        x          x         x           x             o            o   \n3        x          x         x           x             o            o   \n4        x          x         x           x             o            o   \n\n  Bottom-Left Bottom-Middle Bottom-Right     Class  \n0           x             o            o  positive  \n1           o             x            o  positive  \n2           o             o            x  positive  \n3           o             b            b  positive  \n4           b             o            b  positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Top-Left</th>\n      <th>Top-Middle</th>\n      <th>Top-Right</th>\n      <th>Middle-Left</th>\n      <th>Middle-Middle</th>\n      <th>Middle-Right</th>\n      <th>Bottom-Left</th>\n      <th>Bottom-Middle</th>\n      <th>Bottom-Right</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>o</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>x</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>o</td>\n      <td>b</td>\n      <td>b</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>x</td>\n      <td>o</td>\n      <td>o</td>\n      <td>b</td>\n      <td>o</td>\n      <td>b</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_tac_toe = pd.read_csv('dataset/tic-tac-toe.csv')\n",
    "tic_tac_toe.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Create dummy variables using pandas\n",
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
    "y = tic_tac_toe.iloc[:, 9]\n",
    "\n",
    "# Create training and testing datasets, Use 10% for the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1111)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create two holdout sets\n",
    "\n",
    "Before you start testing different models and parameter sets, you will need to split the data into training, validation, and testing datasets. Remember that after splitting the data into training and testing datasets, the validation dataset is created by splitting the training dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Create temporary training and final testing datasets\n",
    "X_temp, X_test, y_temp, y_test  =\\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "X_train, X_val, y_train, y_val =\\\n",
    "    train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy metrics: regression models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](validation-2.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean absolute error\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41, 37, 36, 31, 29, 28, 20, 67, 61,\n",
    "       55, 51, 51, 47, 43, 41, 40, 34, 33, 32, 31, 26, 24])\n",
    "\n",
    "predictions = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44, 35, 30, 30, 35, 40, 15, 72, 58,\n",
    "       60, 40, 42, 45, 46, 40, 35, 25, 40, 20, 34, 25, 24])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a manual calculation, the error is 5.9\n",
      "Using scikit-learn, the error is 5.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Manually calculate the MAE\n",
    "n = len(predictions)\n",
    "mae_one = sum(abs(y_test - predictions)) / n\n",
    "print('With a manual calculation, the error is {}'.format(mae_one))\n",
    "\n",
    "# Use scikit-learn to calculate the MAE\n",
    "mae_two = mean_absolute_error(y_test, predictions)\n",
    "print('Using scikit-learn, the error is {}'.format(mae_two))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean squared error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a manual calculation, the error is 49.1\n",
      "Using scikit-learn, the error is 49.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "n = len(predictions)\n",
    "# Finish the manual calculation of the MSE\n",
    "mse_one = sum((y_test - predictions) ** 2) / n\n",
    "print('With a manual calculation, the error is {}'.format(mse_one))\n",
    "\n",
    "# Use the scikit-learn function to calculate MSE\n",
    "mse_two = mean_squared_error(y_test, predictions)\n",
    "print('Using scikit-learn, the error is {}'.format(mse_two))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance on data subsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "labels= np.array(['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
    "       'E', 'E', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W',\n",
    "       'W', 'W', 'W', 'W'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE for East teams is 6.733333333333333\n",
      "The MAE for West teams is 5.066666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# Find the East conference teams\n",
    "east_teams = labels == 'E'\n",
    "\n",
    "# Create arrays for the true and predicted values\n",
    "true_east = y_test[east_teams]\n",
    "preds_east = predictions[east_teams]\n",
    "\n",
    "west_teams = labels == 'W'\n",
    "true_west = y_test[west_teams]\n",
    "preds_west = predictions[west_teams]\n",
    "\n",
    "# Print the accuracy metrics\n",
    "print('The MAE for East teams is {}'.format(mae(true_east, preds_east)))\n",
    "\n",
    "# Print the west accuracy\n",
    "print('The MAE for West teams is {}'.format(mae(true_west, preds_west)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification metrics\n",
    "\n",
    "\n",
    "    Types:\n",
    "        Precision\n",
    "        Recall (also called sensitivity)\n",
    "        Accuracy\n",
    "        Specificity\n",
    "        F1-score and its variations\n",
    "    Confusion Matrix\n",
    "        True Positive: Predict/Actual are both 1\n",
    "        True Negative: Predict/Actual are both 0\n",
    "        False Positive: Predicted 1, actual 0\n",
    "        False Negative: Predicted 0, actual 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrices\n",
    "\n",
    "Confusion matrices are a great way to start exploring your model's accuracy. They provide the values needed to calculate a wide range of metrics, including sensitivity, specificity, and the F1-score.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is  0.86\n",
      "The precision is  0.97\n",
      "The recall is  0.80\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the accuracy\n",
    "accuracy = (324 + 491) / (953)\n",
    "print(\"The overall accuracy is {0: 0.2f}\".format(accuracy))\n",
    "\n",
    "# Calculate and print the precision\n",
    "precision = (491) / (491 + 15)\n",
    "print(\"The precision is {0: 0.2f}\".format(precision))\n",
    "\n",
    "# Calculate and print the recall\n",
    "recall = (491) / (491 + 123)\n",
    "print(\"The recall is {0: 0.2f}\".format(recall))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrices, again\n",
    "\n",
    "Creating a confusion matrix in Python is simple. The biggest challenge will be making sure you understand the orientation of the matrix. This exercise makes sure you understand the sklearn implementation of confusion matrices."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tic_tac_toe = pd.read_csv('dataset/tic-tac-toe.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Create dummy variables using pandas\n",
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
    "y = tic_tac_toe.iloc[:, 9]\n",
    "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Create training and testing datasets, Use 10% for the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1111)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(n_estimators=500, random_state=1111)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=1111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, random_state=1111)</pre></div></div></div></div></div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=500, random_state=1111)\n",
    "rfc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  2]\n",
      " [ 0 66]]\n",
      "The number of true positives is: 66\n",
      "\n",
      "Row 1, column 1 represents the number of actual 1s that were predicted 1s (the true positives). Always make sure you understand the orientation of the confusion matrix before you start using it!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create predictions\n",
    "test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "print(cm)\n",
    "\n",
    "# Print the true positives (actual 1s that were predicted 1s)\n",
    "print(\"The number of true positives is: {}\".format(cm[1, 1]))\n",
    "print(\"\\nRow 1, column 1 represents the number of actual 1s that were predicted 1s (the true positives). Always make sure you understand the orientation of the confusion matrix before you start using it!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Precision vs. recall\n",
    "\n",
    "The accuracy metrics you use to evaluate your model should always be based on the specific application. For this example, let's assume you are a really sore loser when it comes to playing Tic-Tac-Toe, but only when you are certain that you are going to win.\n",
    "\n",
    "Choose the most appropriate accuracy metric, either precision or recall, to complete this example. But remember, if you think you are going to win, you better win!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision value is 0.97, The recall value is 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create precision score based on the metric\n",
    "p_score = precision_score(y_test, test_predictions)\n",
    "r_score = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Print the final result\n",
    "print('The precision value is {0:.2f}, The recall value is {1:.2f}'.format(p_score, r_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The bias-variance tradeoff\n",
    "\n",
    "\n",
    "    Variance\n",
    "        Following the training data too closely\n",
    "        Fails to generalize to the test data\n",
    "        Low training error but high test error\n",
    "        Occurs when models are overfit and have high complexity\n",
    "        High variance makes over-fitting\n",
    "    Bias\n",
    "        Failing to find the relationship between the data and the response\n",
    "        High training/test error\n",
    "        Occurs when models are underfit\n",
    "        High bias makes under-fitting\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Error due to under/over-fitting\n",
    "\n",
    "The candy dataset is prime for overfitting. With only 85 observations, if you use 20% for the testing dataset, you are losing a lot of vital data that could be used for modeling. Imagine the scenario where most of the chocolate candies ended up in the training data and very few in the holdout sample. Our model might only see that chocolate is a vital factor, but fail to find that other attributes are also important. In this exercise, you'll explore how using too many features (columns) in a random forest model can lead to overfitting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "candy = pd.read_csv('dataset/candy-data.csv')\n",
    "\n",
    "X = candy.drop(['competitorname', 'winpercent'], axis=1)\n",
    "y = candy['winpercent']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.90\n",
      "The testing error is 9.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=2)\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and test accuracy\n",
    "print('The training error is {0:.2f}'.format(mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(mae(y_test, rfr.predict(X_test))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.59\n",
      "The testing error is 10.00\n"
     ]
    }
   ],
   "source": [
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25,\n",
    "                            random_state=1111,\n",
    "                            max_features=11)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing accuracies\n",
    "print('The training error is {0:.2f}'.format(\n",
    "  mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(\n",
    "  mae(y_test, rfr.predict(X_test))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.60\n",
      "The testing error is 8.79\n"
     ]
    }
   ],
   "source": [
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25,\n",
    "                            random_state=1111,\n",
    "                            max_features=4)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing accuracies\n",
    "print('The training error is {0:.2f}'.format(\n",
    "  mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(\n",
    "  mae(y_test, rfr.predict(X_test))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Am I underfitting?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
    "y = tic_tac_toe.iloc[:, 9]\n",
    "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Create training and testing datasets, Use 10% for the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training scores were: [0.94, 0.93, 0.98, 0.97, 0.99, 1.0, 1.0, 1.0]\n",
      "The testing scores were: [0.83, 0.79, 0.89, 0.91, 0.91, 0.93, 0.97, 0.98]\n",
      "\n",
      "Notice that with only one tree, both the train and test scores are low. As you add more trees, both errors improve. Even at 50 trees, this still might not be enough. Every time you use more trees, you achieve higher accuracy. At some point though, more trees increase training time, but do not decrease testing error.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_scores, train_scores = [], []\n",
    "for i in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
    "    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    # Create predictions for the X_train and X_test datasets.\n",
    "    train_predictions = rfc.predict(X_train)\n",
    "    test_predictions = rfc.predict(X_test)\n",
    "    # Append the accuracy score for the test and train predictions.\n",
    "    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
    "    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n",
    "# Print the train and test scores.\n",
    "print(\"The training scores were: {}\".format(train_scores))\n",
    "print(\"The testing scores were: {}\".format(test_scores))\n",
    "print(\"\\nNotice that with only one tree, both the train and test scores are low. As you add more trees, both errors improve. Even at 50 trees, this still might not be enough. Every time you use more trees, you achieve higher accuracy. At some point though, more trees increase training time, but do not decrease testing error.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5, 10, 20, 50]\n",
    "tmp = pd.DataFrame({'x':x, 'training':train_scores, 'test':test_scores})\n",
    "tmp.set_index('x', inplace=True)\n",
    "tmp.plot(title='train/test score for n_estimators');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
