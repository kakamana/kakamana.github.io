{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Going Deeper\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "author: \"kakamana\"\n",
    "date: \"2023-04-05\"\n",
    "categories: [python, datacamp, machine learning, deep learning, tensorflow, keras, neural network]\n",
    "image: \"GoingDeeper-5.png\"\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Going Deeper\n",
    "\n",
    "Upon completion of this chapter, you will be able to solve binary, multi-class, and multi-label problems using neural networks. All of this can be accomplished by solving problems such as detecting fake dollar bills, determining who threw which dart at a board, and building an intelligent system to water your farm. Aside from plotting model training metrics, you will also be able to stop training and save your models when they no longer improve.\n",
    "\n",
    "This **Going Deeper** is part of [Datacamp course: Introduction to Deep Learning with Keras] There is no denying that deep learning is here to stay! A powerful innovation tool, it is used to solve complex problems arising from unstructured data. It is among the frameworks that make it easier to develop deep learning models, and it is versatile enough to build industry-ready models quickly. In this course, you will learn regression and save the earth by predicting asteroid trajectory, apply binary classification to distinguish real and fake dollar bills, learn to apply multiclass classification to decide who threw which dart at a dart board, and use neural networks to reconstruct noisy images. Additionally, you will learn how to tune your models to enhance their performance during training.\n",
    "\n",
    "This is my learning experience of data science through DataCamp. These repository contributions are part of my learning journey through my graduate program masters of applied data sciences (MADS) at University Of Michigan, [DeepLearning.AI], [Coursera] & [DataCamp]. You can find my similar articles & more stories at my [medium] & [LinkedIn] profile. I am available at [kaggle] & [github blogs] & [github repos]. Thank you for your motivation, support & valuable feedback.\n",
    "\n",
    "These include projects, coursework & notebook which I learned through my data science journey. They are created for reproducible & future reference purpose only. All source code, slides or screenshot are intellactual property of respective content authors. If you find these contents beneficial, kindly consider learning subscription from [DeepLearning.AI Subscription], [Coursera], [DataCamp]\n",
    "\n",
    "\n",
    "\n",
    "[DeepLearning.AI]: https://www.deeplearning.ai\n",
    "[DeepLearning.AI Subscription]: https://www.deeplearning.ai\n",
    "[Coursera]: https://www.coursera.org\n",
    "[DataCamp]: https://www.datacamp.com\n",
    "[medium]: https://medium.com/@kamig4u\n",
    "[LinkedIn]: https://www.linkedin.com/in/asadenterprisearchitect\n",
    "[kaggle]: https://www.kaggle.com/kakamana\n",
    "[github blogs]: https://kakamana.github.io\n",
    "[github repos]: https://github.com/kakamana\n",
    "[Datacamp course: Introduction to Natural Language Processing in Python]: (https://app.datacamp.com/learn/courses/introduction-to-deep-learning-with-keras)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](GoingDeeper-1.png)\n",
    "![](GoingDeeper-2.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Classification\n",
    "\n",
    "Exploring dollar bills\n",
    "You will practice building classification models in Keras with the Banknote Authentication dataset.\n",
    "\n",
    "Your goal is to distinguish between real and fake dollar bills. In order to do this, the dataset comes with 4 features: variance,skewness,curtosis and entropy. These features are calculated by applying mathematical operations over the dollar bill images. The labels are found in the dataframe's class column.\n",
    "\n",
    "![](GoingDeeper-3.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "   variace  skewness  curtosis  entropy  class\n0  3.62160    8.6661   -2.8073 -0.44699      0\n1  4.54590    8.1674   -2.4586 -1.46210      0\n2  3.86600   -2.6383    1.9242  0.10645      0\n3  3.45660    9.5228   -4.0112 -3.59440      0\n4  0.32924   -4.4552    4.5718 -0.98880      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variace</th>\n      <th>skewness</th>\n      <th>curtosis</th>\n      <th>entropy</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.62160</td>\n      <td>8.6661</td>\n      <td>-2.8073</td>\n      <td>-0.44699</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.54590</td>\n      <td>8.1674</td>\n      <td>-2.4586</td>\n      <td>-1.46210</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.86600</td>\n      <td>-2.6383</td>\n      <td>1.9242</td>\n      <td>0.10645</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.45660</td>\n      <td>9.5228</td>\n      <td>-4.0112</td>\n      <td>-3.59440</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.32924</td>\n      <td>-4.4552</td>\n      <td>4.5718</td>\n      <td>-0.98880</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banknotes = pd.read_csv('dataset/banknotes.csv')\n",
    "banknotes.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "X = banknotes.iloc[:, :4]\n",
    "X = ((X - X.mean()) / X.std()).to_numpy()\n",
    "y = banknotes['class'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "sns.pairplot(banknotes, hue='class');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset stats: \n",
      "            variace     skewness     curtosis      entropy        class\n",
      "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
      "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
      "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
      "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
      "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
      "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
      "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
      "max       6.824800    12.951600    17.927400     2.449500     1.000000\n",
      "Observations per class: \n",
      " 0    762\n",
      "1    610\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Dataset stats: \\n', banknotes.describe())\n",
    "\n",
    "# Count the number of observations per class\n",
    "print('Observations per class: \\n', banknotes['class'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pairplot shows that there are features for which the classes spread out noticeably. This gives us an intuition about our classes being easily separable.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\npairplot shows that there are features for which the classes spread out noticeably. This gives us an intuition about our classes being easily separable.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A binary classification model\n",
    "\n",
    "Now that you know what the Banknote Authentication dataset looks like, we'll build a simple model to distinguish between real and fake bills.\n",
    "\n",
    "You will perform binary classification by using a single neuron as an output. The input layer will have 4 neurons since we have 4 features in our dataset. The model's output will be a value constrained between 0 and 1.\n",
    "\n",
    "We will interpret this output number as the probability of our input variables coming from a fake dollar bill, with 1 meaning we are certain it's a fake bill.\n",
    "\n",
    "![](GoingDeeper-4.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import the sequential model and dense layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a dense layer\n",
    "model.add(Dense(1, input_shape=(4,), activation='sigmoid'))\n",
    "\n",
    "# Compile your model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Display a summary of your model\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Is this dollar bill fake ?\n",
    "You are now ready to train your model and check how well it performs when classifying new bills!\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.1475 - accuracy: 0.4742\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.9825 - accuracy: 0.4976\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.5326\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7281 - accuracy: 0.5889\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6589\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7153\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7862\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.8639\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.9086\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.9242\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.9184\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.9213\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.9232\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.9252\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.9174\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.9145\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.9184\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.9203\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.9213\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.9232\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3004 - accuracy: 0.9417\n",
      "Accuracy:  0.941690981388092\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "# Evaluate your model accuracy on the test set\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy: ', accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-class classification\n",
    "\n",
    "A multi-class model\n",
    "\n",
    "You're going to build a model that predicts who threw which dart only based on where that dart landed! (That is the dart's x and y coordinates on the board.)\n",
    "\n",
    "This problem is a multi-class classification problem since each dart can only be thrown by one of 4 competitors. So classes/labels are mutually exclusive, and therefore we can build a neuron with as many output as competitors and use the softmax activation function to achieve a total sum of probabilities of 1 over all competitors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "     xCoord    yCoord competitor\n0  0.196451 -0.520341      Steve\n1  0.476027 -0.306763      Susan\n2  0.003175 -0.980736    Michael\n3  0.294078  0.267566       Kate\n4 -0.051120  0.598946      Steve",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xCoord</th>\n      <th>yCoord</th>\n      <th>competitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.196451</td>\n      <td>-0.520341</td>\n      <td>Steve</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.476027</td>\n      <td>-0.306763</td>\n      <td>Susan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003175</td>\n      <td>-0.980736</td>\n      <td>Michael</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.294078</td>\n      <td>0.267566</td>\n      <td>Kate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.051120</td>\n      <td>0.598946</td>\n      <td>Steve</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darts = pd.read_csv('dataset/darts.csv')\n",
    "darts.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "sns.pairplot(darts, hue='competitor');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Instantiate a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add 3 dense layers of 128, 64 and 32 neurons each\n",
    "model.add(Dense(128, input_shape=(2,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add a dense layer with as many neurons as competitors\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile your model using categorical_crossentropy loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare your dataset\n",
    "In the console you can check that your labels, darts.competitor are not yet in a format to be understood by your network. They contain the names of the competitors as strings. You will first turn these competitors into unique numbers,then use the to_categorical() function from tf.keras.utils to turn these numbers into their one-hot encoded representation.\n",
    "\n",
    "This is useful for multi-class classification problems, since there are as many output neurons as classes and for every observation in our dataset we just want one of the neurons to be activated."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoded competitors: \n",
      " 0    2\n",
      "1    3\n",
      "2    1\n",
      "3    0\n",
      "4    2\n",
      "Name: competitor, dtype: int8\n",
      "One-hot encoded competitors: \n",
      " [[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Transform into a categorical variable\n",
    "darts.competitor = pd.Categorical(darts.competitor)\n",
    "\n",
    "# Assign a number to each category (label encoding)\n",
    "darts.competitor = darts.competitor.cat.codes\n",
    "\n",
    "# Print the label encoded competitors\n",
    "print('Label encoded competitors: \\n', darts.competitor.head())\n",
    "\n",
    "coordinates = darts.drop(['competitor'], axis=1)\n",
    "\n",
    "# Use to_categorical on your labels\n",
    "competitors = to_categorical(darts.competitor)\n",
    "\n",
    "# Now print the one-hot encoded labels\n",
    "print('One-hot encoded competitors: \\n', competitors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Each competitor is now a vector of length 4, full of zeroes except for the position representing her or himself.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEach competitor is now a vector of length 4, full of zeroes except for the position representing her or himself.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training on dart throwers\n",
    "Your model is now ready, just as your dataset. It's time to train!\n",
    "\n",
    "The coordinates features and competitors labels you just transformed have been partitioned into coord_train,coord_test and competitors_train,competitors_test.\n",
    "\n",
    "Let's find out who threw which dart just by looking at the board!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "     xCoord    yCoord\n0  0.196451 -0.520341\n1  0.476027 -0.306763\n2  0.003175 -0.980736\n3  0.294078  0.267566\n4 -0.051120  0.598946",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xCoord</th>\n      <th>yCoord</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.196451</td>\n      <td>-0.520341</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.476027</td>\n      <td>-0.306763</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003175</td>\n      <td>-0.980736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.294078</td>\n      <td>0.267566</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.051120</td>\n      <td>0.598946</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = darts[['xCoord', 'yCoord']]\n",
    "coordinates.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "coord_train, coord_test, competitors_train, competitors_test = \\\n",
    "    train_test_split(coordinates, competitors, test_size=0.25, stratify=competitors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 128)               384       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,852\n",
      "Trainable params: 10,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.3599 - accuracy: 0.2450\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.3132 - accuracy: 0.3050\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.2641 - accuracy: 0.3683\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.2036 - accuracy: 0.4750\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.1331 - accuracy: 0.5267\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.0514 - accuracy: 0.5550\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.9658 - accuracy: 0.5950\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.9022 - accuracy: 0.6000\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.8625 - accuracy: 0.6517\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.8310 - accuracy: 0.6750\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.8100 - accuracy: 0.6750\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7954 - accuracy: 0.7000\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7777 - accuracy: 0.6917\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7549 - accuracy: 0.7450\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7466 - accuracy: 0.7350\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7310 - accuracy: 0.7433\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7277 - accuracy: 0.7367\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7172 - accuracy: 0.7483\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7029 - accuracy: 0.7783\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6987 - accuracy: 0.7500\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7010 - accuracy: 0.7733\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6839 - accuracy: 0.7633\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6838 - accuracy: 0.7700\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6779 - accuracy: 0.7750\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6696 - accuracy: 0.7833\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6796 - accuracy: 0.7550\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6662 - accuracy: 0.7883\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.7900\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6569 - accuracy: 0.7850\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.7917\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6500 - accuracy: 0.7900\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6364 - accuracy: 0.7917\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6423 - accuracy: 0.7800\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6388 - accuracy: 0.7900\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6392 - accuracy: 0.7917\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.7850\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6258 - accuracy: 0.8133\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6271 - accuracy: 0.7900\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.7933\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.7800\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6145 - accuracy: 0.8050\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6048 - accuracy: 0.8083\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6091 - accuracy: 0.7983\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6095 - accuracy: 0.7817\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6036 - accuracy: 0.7983\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6029 - accuracy: 0.8017\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6009 - accuracy: 0.8033\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5969 - accuracy: 0.8067\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5980 - accuracy: 0.7967\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5893 - accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.8083\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5883 - accuracy: 0.8100\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5877 - accuracy: 0.8017\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5804 - accuracy: 0.8083\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5662 - accuracy: 0.8233\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5884 - accuracy: 0.7950\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5694 - accuracy: 0.8133\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5856 - accuracy: 0.7950\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5747 - accuracy: 0.8183\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.8117\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5763 - accuracy: 0.8017\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5909 - accuracy: 0.7983\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5654 - accuracy: 0.8050\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5703 - accuracy: 0.8067\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.8233\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5604 - accuracy: 0.8017\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5515 - accuracy: 0.8133\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5470 - accuracy: 0.8267\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.8133\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5521 - accuracy: 0.8100\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.8083\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5737 - accuracy: 0.8017\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5477 - accuracy: 0.8117\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5417 - accuracy: 0.8233\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5536 - accuracy: 0.8067\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5645 - accuracy: 0.7917\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5348 - accuracy: 0.8217\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5385 - accuracy: 0.8150\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.8167\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5345 - accuracy: 0.8233\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5356 - accuracy: 0.8183\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.8200\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5303 - accuracy: 0.8150\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5346 - accuracy: 0.8150\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.8250\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.8300\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5292 - accuracy: 0.8133\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.8083\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.8167\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.8133\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.8150\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5334 - accuracy: 0.8167\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5535 - accuracy: 0.7967\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5296 - accuracy: 0.8100\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.8033\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5296 - accuracy: 0.8183\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.8250\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5164 - accuracy: 0.8117\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.8300\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.8133\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.8250\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.8250\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.8250\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.8133\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8283\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.8167\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5052 - accuracy: 0.8283\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.8167\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5040 - accuracy: 0.8167\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.8267\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.8250\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.8350\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4995 - accuracy: 0.8350\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.8083\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4971 - accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4994 - accuracy: 0.8233\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5066 - accuracy: 0.8217\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.8250\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5034 - accuracy: 0.8200\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5133 - accuracy: 0.8033\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5380 - accuracy: 0.8133\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5099 - accuracy: 0.8067\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.8267\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.8233\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.8183\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4963 - accuracy: 0.8217\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.8233\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.8300\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.8200\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.8233\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.8300\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.8300\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.8250\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.8300\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4948 - accuracy: 0.8150\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8300\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.8283\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.8217\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.8283\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4829 - accuracy: 0.8300\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.8267\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5142 - accuracy: 0.8050\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.8350\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.8267\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4880 - accuracy: 0.8300\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8183\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.8150\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.8200\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.8183\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4977 - accuracy: 0.8167\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5129 - accuracy: 0.8067\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.8350\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.8300\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.8350\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4678 - accuracy: 0.8283\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.8267\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.8167\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.8433\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4675 - accuracy: 0.8283\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4718 - accuracy: 0.8233\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.8267\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.8200\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4690 - accuracy: 0.8317\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.8400\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.8250\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.8167\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.8167\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4881 - accuracy: 0.8150\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4745 - accuracy: 0.8200\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.8250\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.8217\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.8217\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.8200\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4806 - accuracy: 0.8133\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.8133\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.8300\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4657 - accuracy: 0.8250\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4619 - accuracy: 0.8400\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.8250\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.8250\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.8317\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.8367\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.8300\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.8300\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4641 - accuracy: 0.8283\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.8150\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4632 - accuracy: 0.8317\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.8167\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.8350\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4545 - accuracy: 0.8367\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.8317\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.8317\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4639 - accuracy: 0.8333\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7568 - accuracy: 0.7400\n",
      "Accuracy: 0.7400000095367432\n"
     ]
    }
   ],
   "source": [
    "# Fit your model to the training data for 200 epochs\n",
    "model.fit(coord_train,competitors_train,epochs=200)\n",
    "\n",
    "# Evaluate your model accuracy on the test data\n",
    "accuracy = model.evaluate(coord_test, competitors_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax predictions\n",
    "This model is generalizing well!, that's why you got a high accuracy on the test set.\n",
    "\n",
    "Since you used the softmax activation function, for every input of 2 coordinates provided to your model there's an output vector of 4 numbers. Each of these numbers encodes the probability of a given dart being thrown by one of the 4 possible competitors.\n",
    "\n",
    "When computing accuracy with the model's .evaluate() method, your model takes the class with the highest probability as the prediction. np.argmax() can help you do this since it returns the index with the highest value in an array.\n",
    "\n",
    "Use the collection of test throws stored in coords_small_test and np.argmax() to check this out!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "coords_small_test = pd.DataFrame({\n",
    "    'xCoord':[0.209048, 0.082103, 0.198165, -0.348660, 0.214726],\n",
    "    'yCoord':[-0.077398, -0.721407, -0.674646, 0.035086, 0.183894]\n",
    "})\n",
    "\n",
    "competitors_small_test = np.array([[0., 0., 1., 0.], [0., 0., 0., 1.],\n",
    "                                   [0., 0., 0., 1.], [1., 0., 0., 0.],\n",
    "                                   [0., 0., 1., 0.]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "Raw Model Predictions                         | True labels\n",
      "[0.2622551  0.02379499 0.70972663 0.00422329] | [0. 0. 1. 0.]\n",
      "[0.14338753 0.0040605  0.03195374 0.82059824] | [0. 0. 0. 1.]\n",
      "[0.33725557 0.00968876 0.1857851  0.46727058] | [0. 0. 0. 1.]\n",
      "[0.91596746 0.01915123 0.04591938 0.01896184] | [1. 0. 0. 0.]\n",
      "[0.23492725 0.02038225 0.74062115 0.00406925] | [0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(coords_small_test)\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:45} | {}\".format(\"Raw Model Predictions\", \"True labels\"))\n",
    "for i, pred in enumerate(preds):\n",
    "    print(\"{} | {}\".format(pred, competitors_small_test[i]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "Raw Model Predictions                         | True labels\n",
      "[0.2622551  0.02379499 0.70972663 0.00422329] | [0. 0. 1. 0.]\n",
      "[0.14338753 0.0040605  0.03195374 0.82059824] | [0. 0. 0. 1.]\n",
      "[0.33725557 0.00968876 0.1857851  0.46727058] | [0. 0. 0. 1.]\n",
      "[0.91596746 0.01915123 0.04591938 0.01896184] | [1. 0. 0. 0.]\n",
      "[0.23492725 0.02038225 0.74062115 0.00406925] | [0. 0. 1. 0.]\n",
      "Rounded Model Predictions | True labels\n",
      "                        2 | [0. 0. 1. 0.]\n",
      "                        3 | [0. 0. 0. 1.]\n",
      "                        3 | [0. 0. 0. 1.]\n",
      "                        0 | [1. 0. 0. 0.]\n",
      "                        2 | [0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Predict on coords_small_test\n",
    "preds = model.predict(coords_small_test)\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:45} | {}\".format('Raw Model Predictions','True labels'))\n",
    "for i,pred in enumerate(preds):\n",
    "  print(\"{} | {}\".format(pred,competitors_small_test[i]))\n",
    "\n",
    "# Extract the position of highest probability from each pred vector\n",
    "preds_chosen = [np.argmax(pred) for pred in preds]\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:10} | {}\".format('Rounded Model Predictions','True labels'))\n",
    "for i,pred in enumerate(preds_chosen):\n",
    "  print(\"{:25} | {}\".format(pred,competitors_small_test[i]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As you've seen you can easily interpret the softmax output. This can also help you spot those observations where your network is less certain on which class to predict, since you can see the probability distribution among classes per prediction. Let's learn how to solve new problems with neural networks!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAs you've seen you can easily interpret the softmax output. This can also help you spot those observations where your network is less certain on which class to predict, since you can see the probability distribution among classes per prediction. Let's learn how to solve new problems with neural networks!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-label classification\n",
    "\n",
    "![](GoingDeeper-5.png)\n",
    "![](GoingDeeper-6.png)\n",
    "![](GoingDeeper-7.png)\n",
    "![](GoingDeeper-8.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## An irrigation machine\n",
    "You're going to automate the watering of farm parcels by making an intelligent irrigation machine. Multi-label classification problems differ from multi-class problems in that each observation can be labeled with zero or more classes. So classes/labels are not mutually exclusive, you could water all, none or any combination of farm parcels based on the inputs.\n",
    "\n",
    "To account for this behavior what we do is have an output layer with as many neurons as classes but this time, unlike in multi-class problems, each output neuron has a sigmoid activation function. This makes each neuron in the output layer able to output a number between 0 and 1 independently.\n",
    "\n",
    "![](GoingDeeper-9.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "   sensor_0  sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  \\\n0       1.0       2.0       1.0       7.0       0.0       1.0       1.0   \n1       5.0       1.0       3.0       5.0       2.0       2.0       1.0   \n2       3.0       1.0       4.0       3.0       4.0       0.0       1.0   \n3       2.0       2.0       4.0       3.0       5.0       0.0       3.0   \n4       4.0       3.0       3.0       2.0       5.0       1.0       3.0   \n\n   sensor_7  sensor_8  sensor_9  ...  sensor_13  sensor_14  sensor_15  \\\n0       4.0       0.0       3.0  ...        8.0        1.0        0.0   \n1       2.0       3.0       1.0  ...        4.0        5.0        5.0   \n2       6.0       0.0       2.0  ...        3.0        3.0        1.0   \n3       2.0       2.0       5.0  ...        4.0        1.0        1.0   \n4       1.0       1.0       2.0  ...        1.0        3.0        2.0   \n\n   sensor_16  sensor_17  sensor_18  sensor_19  parcel_0  parcel_1  parcel_2  \n0        2.0        1.0        9.0        2.0         0         1         0  \n1        2.0        2.0        2.0        7.0         0         0         0  \n2        0.0        3.0        1.0        0.0         1         1         0  \n3        4.0        1.0        3.0        2.0         0         0         0  \n4        2.0        1.0        1.0        0.0         1         1         0  \n\n[5 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sensor_0</th>\n      <th>sensor_1</th>\n      <th>sensor_2</th>\n      <th>sensor_3</th>\n      <th>sensor_4</th>\n      <th>sensor_5</th>\n      <th>sensor_6</th>\n      <th>sensor_7</th>\n      <th>sensor_8</th>\n      <th>sensor_9</th>\n      <th>...</th>\n      <th>sensor_13</th>\n      <th>sensor_14</th>\n      <th>sensor_15</th>\n      <th>sensor_16</th>\n      <th>sensor_17</th>\n      <th>sensor_18</th>\n      <th>sensor_19</th>\n      <th>parcel_0</th>\n      <th>parcel_1</th>\n      <th>parcel_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrigation = pd.read_csv('dataset/irrigation_machine.csv', index_col=0)\n",
    "irrigation.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                1344      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,539\n",
      "Trainable params: 1,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add a hidden layer of 64 neurons and a 20 neuron's input\n",
    "model.add(Dense(64, input_shape=(20, ), activation='relu'))\n",
    "\n",
    "# Add an output layer of 3 neurons with sigmoid activation\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "# Compile your model with binary crossentropy loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You've already built 3 models for 3 different problems! Hopefully you're starting to get a feel for how different problems can be modeled in the neural network realm\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nYou've already built 3 models for 3 different problems! Hopefully you're starting to get a feel for how different problems can be modeled in the neural network realm\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training with multiple labels\n",
    "\n",
    "An output of your multi-label model could look like this: [0.76 , 0.99 , 0.66 ]. If we round up probabilities higher than 0.5, this observation will be classified as containing all 3 possible labels [1,1,1]. For this particular problem, this would mean watering all 3 parcels in your field is the right thing to do given the input sensor measurements.\n",
    "\n",
    "You will now train and predict with the model you just built. sensors_train, parcels_train, sensors_test and parcels_test are already loaded for you to use. Let’s see how well your machine performs!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "parcels = irrigation[['parcel_0', 'parcel_1', 'parcel_2']].to_numpy()\n",
    "sensors = irrigation.drop(['parcel_0', 'parcel_1', 'parcel_2'], axis=1).to_numpy()\n",
    "\n",
    "sensors_train, sensors_test, parcels_train, parcels_test = \\\n",
    "    train_test_split(sensors, parcels, test_size=0.3, stratify=parcels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.7939 - accuracy: 0.4116 - val_loss: 0.5517 - val_accuracy: 0.3321\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.5161 - val_loss: 0.4336 - val_accuracy: 0.5964\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.6018 - val_loss: 0.3756 - val_accuracy: 0.5786\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.6241 - val_loss: 0.3399 - val_accuracy: 0.6179\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.6438 - val_loss: 0.3200 - val_accuracy: 0.6143\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.6438 - val_loss: 0.3061 - val_accuracy: 0.6286\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3060 - accuracy: 0.6295 - val_loss: 0.2950 - val_accuracy: 0.6500\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.6554 - val_loss: 0.2871 - val_accuracy: 0.5964\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2869 - accuracy: 0.6348 - val_loss: 0.2856 - val_accuracy: 0.6607\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.6500 - val_loss: 0.2765 - val_accuracy: 0.6250\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2731 - accuracy: 0.6402 - val_loss: 0.2762 - val_accuracy: 0.6250\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2671 - accuracy: 0.6411 - val_loss: 0.2680 - val_accuracy: 0.6286\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.6411 - val_loss: 0.2630 - val_accuracy: 0.6179\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2568 - accuracy: 0.6339 - val_loss: 0.2600 - val_accuracy: 0.6143\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.6393 - val_loss: 0.2573 - val_accuracy: 0.6286\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2488 - accuracy: 0.6455 - val_loss: 0.2548 - val_accuracy: 0.5929\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2443 - accuracy: 0.6375 - val_loss: 0.2529 - val_accuracy: 0.5786\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2411 - accuracy: 0.6339 - val_loss: 0.2526 - val_accuracy: 0.6107\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2382 - accuracy: 0.6313 - val_loss: 0.2488 - val_accuracy: 0.6286\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2334 - accuracy: 0.6304 - val_loss: 0.2454 - val_accuracy: 0.6357\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2279 - accuracy: 0.6384 - val_loss: 0.2438 - val_accuracy: 0.6250\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2252 - accuracy: 0.6384 - val_loss: 0.2407 - val_accuracy: 0.5964\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2222 - accuracy: 0.6384 - val_loss: 0.2404 - val_accuracy: 0.6214\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2201 - accuracy: 0.6259 - val_loss: 0.2386 - val_accuracy: 0.6036\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2185 - accuracy: 0.6304 - val_loss: 0.2384 - val_accuracy: 0.6071\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.6295 - val_loss: 0.2359 - val_accuracy: 0.6107\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2160 - accuracy: 0.6366 - val_loss: 0.2326 - val_accuracy: 0.6000\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2123 - accuracy: 0.6286 - val_loss: 0.2334 - val_accuracy: 0.5750\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2081 - accuracy: 0.6330 - val_loss: 0.2325 - val_accuracy: 0.5821\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2078 - accuracy: 0.6250 - val_loss: 0.2312 - val_accuracy: 0.6143\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2052 - accuracy: 0.6143 - val_loss: 0.2329 - val_accuracy: 0.6393\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2035 - accuracy: 0.6223 - val_loss: 0.2321 - val_accuracy: 0.6071\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2002 - accuracy: 0.6268 - val_loss: 0.2328 - val_accuracy: 0.6357\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.6268 - val_loss: 0.2296 - val_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.6214 - val_loss: 0.2323 - val_accuracy: 0.6179\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.6196 - val_loss: 0.2288 - val_accuracy: 0.5964\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1933 - accuracy: 0.6268 - val_loss: 0.2307 - val_accuracy: 0.6214\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.6143 - val_loss: 0.2287 - val_accuracy: 0.6214\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.6196 - val_loss: 0.2324 - val_accuracy: 0.6286\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1909 - accuracy: 0.6152 - val_loss: 0.2301 - val_accuracy: 0.5571\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1896 - accuracy: 0.6214 - val_loss: 0.2343 - val_accuracy: 0.6607\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.6054 - val_loss: 0.2338 - val_accuracy: 0.6464\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1861 - accuracy: 0.6232 - val_loss: 0.2273 - val_accuracy: 0.5679\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1858 - accuracy: 0.6152 - val_loss: 0.2385 - val_accuracy: 0.6107\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1822 - accuracy: 0.6143 - val_loss: 0.2301 - val_accuracy: 0.6071\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1825 - accuracy: 0.6241 - val_loss: 0.2289 - val_accuracy: 0.6143\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.6304 - val_loss: 0.2301 - val_accuracy: 0.5500\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.6107 - val_loss: 0.2303 - val_accuracy: 0.5964\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.6080 - val_loss: 0.2335 - val_accuracy: 0.6179\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1780 - accuracy: 0.6107 - val_loss: 0.2308 - val_accuracy: 0.6286\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1765 - accuracy: 0.6196 - val_loss: 0.2308 - val_accuracy: 0.5643\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.6152 - val_loss: 0.2296 - val_accuracy: 0.5607\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1730 - accuracy: 0.6062 - val_loss: 0.2311 - val_accuracy: 0.5750\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.6339 - val_loss: 0.2313 - val_accuracy: 0.5857\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.6107 - val_loss: 0.2333 - val_accuracy: 0.5750\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.6179 - val_loss: 0.2297 - val_accuracy: 0.5714\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1684 - accuracy: 0.6152 - val_loss: 0.2334 - val_accuracy: 0.6250\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1673 - accuracy: 0.6232 - val_loss: 0.2295 - val_accuracy: 0.6036\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.6259 - val_loss: 0.2307 - val_accuracy: 0.5821\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1651 - accuracy: 0.6098 - val_loss: 0.2308 - val_accuracy: 0.5821\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1642 - accuracy: 0.6241 - val_loss: 0.2318 - val_accuracy: 0.5964\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1631 - accuracy: 0.6089 - val_loss: 0.2305 - val_accuracy: 0.5929\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.6161 - val_loss: 0.2305 - val_accuracy: 0.5786\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.6179 - val_loss: 0.2335 - val_accuracy: 0.6250\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1606 - accuracy: 0.6089 - val_loss: 0.2334 - val_accuracy: 0.6536\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.6170 - val_loss: 0.2373 - val_accuracy: 0.6536\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.6161 - val_loss: 0.2352 - val_accuracy: 0.6321\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.6205 - val_loss: 0.2387 - val_accuracy: 0.5643\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1557 - accuracy: 0.6071 - val_loss: 0.2358 - val_accuracy: 0.6464\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 0.6161 - val_loss: 0.2318 - val_accuracy: 0.6250\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.6098 - val_loss: 0.2355 - val_accuracy: 0.5929\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.6268 - val_loss: 0.2358 - val_accuracy: 0.6286\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1520 - accuracy: 0.6062 - val_loss: 0.2346 - val_accuracy: 0.6464\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.6241 - val_loss: 0.2350 - val_accuracy: 0.6250\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.6000 - val_loss: 0.2364 - val_accuracy: 0.6143\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.6259 - val_loss: 0.2356 - val_accuracy: 0.6143\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.6018 - val_loss: 0.2345 - val_accuracy: 0.5786\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1474 - accuracy: 0.6098 - val_loss: 0.2368 - val_accuracy: 0.6179\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.6062 - val_loss: 0.2413 - val_accuracy: 0.6214\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1459 - accuracy: 0.6018 - val_loss: 0.2380 - val_accuracy: 0.6357\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.6143 - val_loss: 0.2399 - val_accuracy: 0.6214\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.6098 - val_loss: 0.2361 - val_accuracy: 0.6179\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.6071 - val_loss: 0.2368 - val_accuracy: 0.6071\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.6187 - val_loss: 0.2387 - val_accuracy: 0.6214\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1412 - accuracy: 0.6062 - val_loss: 0.2451 - val_accuracy: 0.6607\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 0.6009 - val_loss: 0.2404 - val_accuracy: 0.6464\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1410 - accuracy: 0.6125 - val_loss: 0.2404 - val_accuracy: 0.6357\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1370 - accuracy: 0.6152 - val_loss: 0.2447 - val_accuracy: 0.6321\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1382 - accuracy: 0.6036 - val_loss: 0.2412 - val_accuracy: 0.5750\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1393 - accuracy: 0.6036 - val_loss: 0.2391 - val_accuracy: 0.5714\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.6268 - val_loss: 0.2399 - val_accuracy: 0.6214\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.5946 - val_loss: 0.2423 - val_accuracy: 0.6250\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1343 - accuracy: 0.6036 - val_loss: 0.2414 - val_accuracy: 0.6107\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1350 - accuracy: 0.6098 - val_loss: 0.2430 - val_accuracy: 0.6357\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.6062 - val_loss: 0.2439 - val_accuracy: 0.6071\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1323 - accuracy: 0.6259 - val_loss: 0.2464 - val_accuracy: 0.5964\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1319 - accuracy: 0.5911 - val_loss: 0.2457 - val_accuracy: 0.6393\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.6089 - val_loss: 0.2481 - val_accuracy: 0.6714\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.5955 - val_loss: 0.2474 - val_accuracy: 0.6607\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.6116 - val_loss: 0.2520 - val_accuracy: 0.6679\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Rounded Predictions: \n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 0.]]\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.6550\n",
      "Accuracy: 0.6549999713897705\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs using a validation split of 0.2\n",
    "model.fit(sensors_train, parcels_train, epochs = 100, validation_split = 0.2)\n",
    "\n",
    "# Predict on sensors_test and round up the predictions\n",
    "preds = model.predict(sensors_test)\n",
    "preds_rounded = np.round(preds)\n",
    "\n",
    "# Print rounded preds\n",
    "print('Rounded Predictions: \\n', preds_rounded)\n",
    "\n",
    "# Evaluate your model's accuracy on the test data\n",
    "accuracy = model.evaluate(sensors_test, parcels_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You can see how the validation_split argument is useful for evaluating how your model performs as it trains. Let's move on and improve your model training by using callbacks!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nYou can see how the validation_split argument is useful for evaluating how your model performs as it trains. Let's move on and improve your model training by using callbacks!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Keras callbacks\n",
    "History\n",
    "EarlyStopping\n",
    "ModelCheckpoint\n",
    "The history callback\n",
    "The history callback is returned by default every time you train a model with the .fit() method. To access these metrics you can access the history dictionary parameter inside the returned h_callback object with the corresponding keys.\n",
    "\n",
    "The irrigation machine model you built in the previous lesson is loaded for you to train, along with its features and labels now loaded as X_train, y_train, X_test, y_test. This time you will store the model's history callback and use the validation_data parameter as it trains.\n",
    "\n",
    "Let's see the behind the scenes of our training!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def plot_accuracy(acc,val_acc):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure();\n",
    "    plt.plot(acc);\n",
    "    plt.plot(val_acc);\n",
    "    plt.title('Model accuracy');\n",
    "    plt.ylabel('Accuracy');\n",
    "    plt.xlabel('Epoch');\n",
    "    plt.legend(['Train', 'Test'], loc='upper left');\n",
    "\n",
    "def plot_loss(loss,val_loss):\n",
    "    plt.figure();\n",
    "    plt.plot(loss);\n",
    "    plt.plot(val_loss);\n",
    "    plt.title('Model loss');\n",
    "    plt.ylabel('Loss');\n",
    "    plt.xlabel('Epoch');\n",
    "    plt.legend(['Train', 'Test'], loc='upper right');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "X_train, y_train = sensors_train, parcels_train\n",
    "X_test, y_test = sensors_test, parcels_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 1s 8ms/step - loss: 0.1578 - accuracy: 0.6136 - val_loss: 0.2384 - val_accuracy: 0.6133\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1524 - accuracy: 0.5950 - val_loss: 0.2345 - val_accuracy: 0.6483\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 0.6407 - val_loss: 0.2459 - val_accuracy: 0.6133\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1485 - accuracy: 0.6014 - val_loss: 0.2327 - val_accuracy: 0.5850\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1459 - accuracy: 0.6143 - val_loss: 0.2406 - val_accuracy: 0.6083\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1449 - accuracy: 0.6064 - val_loss: 0.2363 - val_accuracy: 0.6533\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1443 - accuracy: 0.6164 - val_loss: 0.2390 - val_accuracy: 0.6417\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1448 - accuracy: 0.6071 - val_loss: 0.2356 - val_accuracy: 0.5900\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.6064 - val_loss: 0.2375 - val_accuracy: 0.5900\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1400 - accuracy: 0.6107 - val_loss: 0.2380 - val_accuracy: 0.5700\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1415 - accuracy: 0.6071 - val_loss: 0.2446 - val_accuracy: 0.5850\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1412 - accuracy: 0.5929 - val_loss: 0.2361 - val_accuracy: 0.5817\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1390 - accuracy: 0.5986 - val_loss: 0.2386 - val_accuracy: 0.5517\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1397 - accuracy: 0.6043 - val_loss: 0.2456 - val_accuracy: 0.6417\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.6057 - val_loss: 0.2421 - val_accuracy: 0.6217\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1350 - accuracy: 0.5950 - val_loss: 0.2440 - val_accuracy: 0.5983\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1356 - accuracy: 0.6107 - val_loss: 0.2399 - val_accuracy: 0.6167\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.6043 - val_loss: 0.2436 - val_accuracy: 0.5967\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1340 - accuracy: 0.6114 - val_loss: 0.2413 - val_accuracy: 0.5950\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.5879 - val_loss: 0.2498 - val_accuracy: 0.6217\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1325 - accuracy: 0.6157 - val_loss: 0.2434 - val_accuracy: 0.6183\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1305 - accuracy: 0.6043 - val_loss: 0.2470 - val_accuracy: 0.6367\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1308 - accuracy: 0.6021 - val_loss: 0.2518 - val_accuracy: 0.6150\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.6021 - val_loss: 0.2425 - val_accuracy: 0.5433\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.5900 - val_loss: 0.2450 - val_accuracy: 0.6300\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.6029 - val_loss: 0.2505 - val_accuracy: 0.6350\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.5993 - val_loss: 0.2532 - val_accuracy: 0.6583\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1269 - accuracy: 0.6086 - val_loss: 0.2482 - val_accuracy: 0.6067\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.5979 - val_loss: 0.2447 - val_accuracy: 0.5650\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.6007 - val_loss: 0.2456 - val_accuracy: 0.5817\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.5850 - val_loss: 0.2487 - val_accuracy: 0.5817\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.6007 - val_loss: 0.2488 - val_accuracy: 0.6000\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.6071 - val_loss: 0.2502 - val_accuracy: 0.5350\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1217 - accuracy: 0.5829 - val_loss: 0.2500 - val_accuracy: 0.5900\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1226 - accuracy: 0.6093 - val_loss: 0.2521 - val_accuracy: 0.5917\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.5986 - val_loss: 0.2532 - val_accuracy: 0.6267\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.5714 - val_loss: 0.2529 - val_accuracy: 0.6517\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.6186 - val_loss: 0.2551 - val_accuracy: 0.6200\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.5929 - val_loss: 0.2499 - val_accuracy: 0.5883\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.5936 - val_loss: 0.2532 - val_accuracy: 0.6167\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.6086 - val_loss: 0.2544 - val_accuracy: 0.6133\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.5929 - val_loss: 0.2622 - val_accuracy: 0.6250\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.5971 - val_loss: 0.2545 - val_accuracy: 0.6000\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.5921 - val_loss: 0.2676 - val_accuracy: 0.5567\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.6057 - val_loss: 0.2600 - val_accuracy: 0.5950\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.5907 - val_loss: 0.2559 - val_accuracy: 0.5817\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.5921 - val_loss: 0.2591 - val_accuracy: 0.6350\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1148 - accuracy: 0.5929 - val_loss: 0.2577 - val_accuracy: 0.5933\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.5943 - val_loss: 0.2586 - val_accuracy: 0.5517\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.5964 - val_loss: 0.2620 - val_accuracy: 0.6150\n"
     ]
    }
   ],
   "source": [
    "h_callback = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "plot_loss(h_callback.history['loss'], h_callback.history['val_loss'])\n",
    "\n",
    "# Plot train vs test accuracy during training\n",
    "#\n",
    "plot_accuracy(h_callback.history['accuracy'], h_callback.history['val_accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Early stopping your model\n",
    "The early stopping callback is useful since it allows for you to stop the model training if it no longer improves after a given number of epochs. To make use of this functionality you need to pass the callback inside a list to the model's callback parameter in the .fit() method.\n",
    "\n",
    "The model you built to detect fake dollar bills is loaded for you to train, this time with early stopping. X_train, y_train, X_test and y_test are also available for you to use."
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "X = banknotes.iloc[:, :4]\n",
    "X = ((X - X.mean()) / X.std()).to_numpy()\n",
    "y = banknotes['class'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add a dense layer\n",
    "model.add(Dense(1, input_shape=(4, ), activation='sigmoid'))\n",
    "\n",
    "# Compile your model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 1.5896 - accuracy: 0.2624 - val_loss: 1.5037 - val_accuracy: 0.2741\n",
      "Epoch 2/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.3869 - accuracy: 0.2779 - val_loss: 1.3122 - val_accuracy: 0.2828\n",
      "Epoch 3/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2060 - accuracy: 0.2974 - val_loss: 1.1436 - val_accuracy: 0.3120\n",
      "Epoch 4/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0495 - accuracy: 0.3120 - val_loss: 0.9972 - val_accuracy: 0.3411\n",
      "Epoch 5/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.9165 - accuracy: 0.3537 - val_loss: 0.8734 - val_accuracy: 0.3936\n",
      "Epoch 6/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.8060 - accuracy: 0.4344 - val_loss: 0.7715 - val_accuracy: 0.5102\n",
      "Epoch 7/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.7162 - accuracy: 0.5355 - val_loss: 0.6890 - val_accuracy: 0.6093\n",
      "Epoch 8/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6647 - val_loss: 0.6231 - val_accuracy: 0.7289\n",
      "Epoch 9/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.8154 - val_loss: 0.5720 - val_accuracy: 0.8484\n",
      "Epoch 10/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.8785 - val_loss: 0.5312 - val_accuracy: 0.9009\n",
      "Epoch 11/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.9223 - val_loss: 0.4972 - val_accuracy: 0.9242\n",
      "Epoch 12/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.9339 - val_loss: 0.4699 - val_accuracy: 0.9504\n",
      "Epoch 13/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.9368 - val_loss: 0.4468 - val_accuracy: 0.9534\n",
      "Epoch 14/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.9368 - val_loss: 0.4271 - val_accuracy: 0.9417\n",
      "Epoch 15/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.9339 - val_loss: 0.4098 - val_accuracy: 0.9417\n",
      "Epoch 16/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.9291 - val_loss: 0.3951 - val_accuracy: 0.9388\n",
      "Epoch 17/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.9291 - val_loss: 0.3822 - val_accuracy: 0.9388\n",
      "Epoch 18/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.9291 - val_loss: 0.3706 - val_accuracy: 0.9359\n"
     ]
    }
   ],
   "source": [
    "# Import the early stopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define a callback to monitor val_accuracy\n",
    "monitor_val_acc = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "\n",
    "# Train your model using the early stopping callback\n",
    "model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test),\n",
    "          callbacks=[monitor_val_acc]);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A combination of callbacks\n",
    "Deep learning models can take a long time to train, especially when you move to deeper architectures and bigger datasets. Saving your model every time it improves as well as stopping it when it no longer does allows you to worry less about choosing the number of epochs to train for. You can also restore a saved model anytime and resume training where you left it.\n",
    "\n",
    "Use the EarlyStopping() and the ModelCheckpoint() callbacks so that you can go eat a jar of cookies while you leave your computer to work!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000000000000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3041 - accuracy: 0.9242 - val_loss: 0.3002 - val_accuracy: 0.9388\n",
      "Epoch 2/1000000000000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.9232 - val_loss: 0.2946 - val_accuracy: 0.9388\n",
      "Epoch 3/1000000000000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.9261 - val_loss: 0.2894 - val_accuracy: 0.9359\n",
      "Epoch 4/1000000000000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.9252 - val_loss: 0.2844 - val_accuracy: 0.9388\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Early stop on validation accuracy\n",
    "monitor_val_acc = EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "# Save the best model as best_banknote_model.hdf5\n",
    "modelCheckpoint = ModelCheckpoint('./best_banknote_model.hdf5', save_best_only=True)\n",
    "\n",
    "# Fit your model for a stupid amount of epochs\n",
    "h_callback = model.fit(X_train, y_train,\n",
    "                       epochs=1000000000000,\n",
    "                       callbacks=[monitor_val_acc, modelCheckpoint],\n",
    "                       validation_data=(X_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_banknote_model.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep best_banknote*"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
