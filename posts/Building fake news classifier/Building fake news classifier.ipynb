{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Building fake news classifier\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "author: \"kakamana\"\n",
    "date: \"2023-03-24\"\n",
    "categories: [python, datacamp, machine learning, nlp, supervised machine learning]\n",
    "image: \"buildingFakeNewsClassifier.png\"\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building a \"fake news\" classifier\n",
    "\n",
    "To build a \"fake news\" detector, you will combine what you have learned with some supervised machine learning. The first step will be to learn the basics of supervised machine learning, and the next step will be to select a few important features and test ideas for identifying and classifying fake news articles.\n",
    "\n",
    "This **Building a \"fake news\" classifier** is part of [Datacamp course: Introduction to Natural Language Processing in Python] You will learn the basics of natural language processing (NLP), such as how to identify and separate words, how to extract topics from a text, and how to construct your own fake news classifier. As part of this course, you will also learn how to use basic libraries such as NLTK as well as libraries that utilize deep learning to solve common NLP problems. The purpose of this course is to provide you with the foundation for processing and parsing text as you progress through your Python learning journey.\n",
    "\n",
    "This is my learning experience of data science through DataCamp. These repository contributions are part of my learning journey through my graduate program masters of applied data sciences (MADS) at University Of Michigan, [DeepLearning.AI], [Coursera] & [DataCamp]. You can find my similar articles & more stories at my [medium] & [LinkedIn] profile. I am available at [kaggle] & [github blogs] & [github repos]. Thank you for your motivation, support & valuable feedback.\n",
    "\n",
    "These include projects, coursework & notebook which I learned through my data science journey. They are created for reproducible & future reference purpose only. All source code, slides or screenshot are intellactual property of respective content authors. If you find these contents beneficial, kindly consider learning subscription from [DeepLearning.AI Subscription], [Coursera], [DataCamp]\n",
    "\n",
    "\n",
    "\n",
    "[DeepLearning.AI]: https://www.deeplearning.ai\n",
    "[DeepLearning.AI Subscription]: https://www.deeplearning.ai\n",
    "[Coursera]: https://www.coursera.org\n",
    "[DataCamp]: https://www.datacamp.com\n",
    "[medium]: https://medium.com/@kamig4u\n",
    "[LinkedIn]: https://www.linkedin.com/in/asadenterprisearchitect\n",
    "[kaggle]: https://www.kaggle.com/kakamana\n",
    "[github blogs]: https://kakamana.github.io\n",
    "[github repos]: https://github.com/kakamana\n",
    "[Datacamp course: Introduction to Natural Language Processing in Python]: (https://app.datacamp.com/learn/courses/introduction-to-natural-language-processing-in-python)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifying fake news using supervised learning with NLP\n",
    "\n",
    "    Supervised learning with NLP\n",
    "        Need to use language instead of geometric features\n",
    "        Use bag-of-words models or tf-idf features\n",
    "    Supervised learning steps\n",
    "        Collect and preprocess our data\n",
    "        Determine a label\n",
    "        Split data into training and test sets\n",
    "        Extract features from the text to help predict the label\n",
    "        Evaluate trained model using test set\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building word count vectors with scikit-learn\n",
    "CountVectorizer for text classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                              title  \\\n0        8476                       You Can Smell Hillary’s Fear   \n1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n2        3608        Kerry to go to Paris in gesture of sympathy   \n3       10142  Bernie supporters on Twitter erupt in anger ag...   \n4         875   The Battle of New York: Why This Primary Matters   \n\n                                                text label  \n0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n4  It's primary day in New York and front-runners...  REAL  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8476</td>\n      <td>You Can Smell Hillary’s Fear</td>\n      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10294</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3608</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10142</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>REAL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/fake_or_real_news.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              title  \\\n",
      "0        8476                       You Can Smell Hillary’s Fear   \n",
      "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4         875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n",
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dghr201\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df.label\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'],y,test_size=0.33, random_state=53)\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using only the 'text' column values: count_test\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TfidfVectorizer for text classification\n",
    "\n",
    "Similar to the sparse CountVectorizer created in the previous exercise, you'll work on creating tf-idf vectors for your documents. You'll set up a TfidfVectorizer and investigate some of its features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dghr201\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data: tfidf_test\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inspecting the vectors\n",
    "\n",
    "To get a better idea of how the vectors work, you'll investigate them by converting them into pandas DataFrames."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dghr201\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
      "0   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "1   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "2   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "3   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "4   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "\n",
      "   حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
      "0    0     0   0   0   0        0   0    0        0      0  \n",
      "1    0     0   0   0   0        0   0    0        0      0  \n",
      "2    0     0   0   0   0        0   0    0        0      0  \n",
      "3    0     0   0   0   0        0   0    0        0      0  \n",
      "4    0     0   0   0   0        0   0    0        0      0  \n",
      "\n",
      "[5 rows x 56922 columns]\n",
      "    00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
      "0  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "1  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "2  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "3  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "4  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "\n",
      "   حلب  عربي   عن   لم   ما  محاولات   من  هذا  والمرضى  ยงade  \n",
      "0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "1  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "2  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "3  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "4  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "\n",
      "[5 rows x 56922 columns]\n",
      "set()\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dghr201\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df =  pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "# Print the head of count_df\n",
    "print(count_df.head())\n",
    "\n",
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training and testing a classification model with scikit-learn\n",
    "\n",
    "* Naive Bayes Model\n",
    "    * Commonly used for testing NLP classi,cation problems\n",
    "    * Basis in probability\n",
    "* Given a particular piece of data, how likely is a particular outcome?\n",
    "* Examples:\n",
    "    * If the plot has a spaceship, how likely is it to be sci-,?\n",
    "    * Given a spaceship and an alien, how likely now is it sci-,?\n",
    "* Each word from CountVectorizer acts as a feature\n",
    "* Naive Bayes: Simple and e(ective"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and testing the \"fake news\" model with CountVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893352462936394\n",
      "[[ 865  143]\n",
      " [  80 1003]]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train,y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test,pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "print(cm)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and testing the \"fake news\" model with TfidfVectorizer\n",
    "\n",
    "Now that you have evaluated the model using the CountVectorizer, you'll do the same using the TfidfVectorizer with a Naive Bayes model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8565279770444764\n",
      "[[ 739  269]\n",
      " [  31 1052]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train,y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(tfidf_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test,pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "print(cm)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple NLP, complex problems\n",
    "\n",
    "What are possible next steps you could take to improve the model?\n",
    "\n",
    "    Tweaking alpha levels.\n",
    "    Trying a new classification model.\n",
    "    Training on a larger dataset.\n",
    "    Improving text preprocessing.\n",
    "\n",
    "Your job in this exercise is to test a few different alpha levels using the Tfidf vectors to determine if there is a better performing combination."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.8813964610234337\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.8976566236250598\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.8938307030129125\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.8900047824007652\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.8857006217120995\n",
      "\n",
      "Alpha:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dghr201\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8842659014825442\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.874701099952176\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.8703969392635102\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8660927785748446\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8589191774270684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0, 1, 0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred =  nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inspecting your model\n",
    "\n",
    "Now that you have built a \"fake news\" classifier, you'll investigate what it has learned. You can map the important vector weights back to actual words using some simple inspection techniques."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dghr201\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultinomialNB' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m feature_names \u001B[38;5;241m=\u001B[39m tfidf_vectorizer\u001B[38;5;241m.\u001B[39mget_feature_names()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m feat_with_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[43mnb_classifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef_\u001B[49m[\u001B[38;5;241m0\u001B[39m], feature_names))\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Print the first class label and the top 20 feat_with_weights entries\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(class_labels[\u001B[38;5;241m0\u001B[39m], feat_with_weights[:\u001B[38;5;241m20\u001B[39m])\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'MultinomialNB' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20])\n",
    "\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
